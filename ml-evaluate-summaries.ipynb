{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":53482,"databundleVersionId":6201832,"sourceType":"competition"},{"sourceId":2977194,"sourceType":"datasetVersion","datasetId":1825054},{"sourceId":6258399,"sourceType":"datasetVersion","datasetId":3596984},{"sourceId":8139549,"sourceType":"datasetVersion","datasetId":4812209},{"sourceId":8139552,"sourceType":"datasetVersion","datasetId":4812212},{"sourceId":8146152,"sourceType":"datasetVersion","datasetId":4817190},{"sourceId":8469314,"sourceType":"datasetVersion","datasetId":5049859},{"sourceId":8507789,"sourceType":"datasetVersion","datasetId":5078374},{"sourceId":8558953,"sourceType":"datasetVersion","datasetId":5115575},{"sourceId":8565128,"sourceType":"datasetVersion","datasetId":5120491},{"sourceId":8579511,"sourceType":"datasetVersion","datasetId":5130807},{"sourceId":8583556,"sourceType":"datasetVersion","datasetId":5133543},{"sourceId":8642912,"sourceType":"datasetVersion","datasetId":5176303},{"sourceId":8642927,"sourceType":"datasetVersion","datasetId":5118268},{"sourceId":8656067,"sourceType":"datasetVersion","datasetId":5013476},{"sourceId":8141507,"sourceType":"datasetVersion","datasetId":4813598}],"dockerImageVersionId":30665,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":109.119668,"end_time":"2024-05-16T15:40:29.014408","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-05-16T15:38:39.894740","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"059a11eda62448da981f7b2667b94637":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d4e90cc3beb40b890ffd3978dfb22d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"150f7c2a80124dad8408945c7c4a0fce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15104f9159d1410eb85b6379bc0756c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff9e6813dd3d499f8c44902f3806b49c","IPY_MODEL_588ef8f9110e4ba8897785a7816b52a6","IPY_MODEL_afa499e764d4423fbc616d6a8de52fd0"],"layout":"IPY_MODEL_deefef886f9c43cf88f6f162100f2e3e"}},"1982a9459b644ddf93b0670b17ed6427":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b2c1961d94c4a07b162c8e1f1f4ea8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e281edfb4944800b70ca3e7b078cd13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f7d29516b7a46dcb0fa01415173e1df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"25126573d458497987981721450a08ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c8166010478471ebcfeaff488254cc3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ed7fd040a494b91bcb6b11bf17446a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c55a6f3b2d6453d92734e1c2c6ccf3d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f8ee3fcf5ed47f08eb3eeaff0647d5e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42cdc6d0d53e4ab298128b8581bf4c3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c8166010478471ebcfeaff488254cc3","placeholder":"​","style":"IPY_MODEL_059a11eda62448da981f7b2667b94637","value":" 2.46M/2.46M [00:00&lt;00:00, 3.68MB/s]"}},"464d8379cbd842b6b0c919aa12c237ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1982a9459b644ddf93b0670b17ed6427","placeholder":"​","style":"IPY_MODEL_a0ed8c5740e846b7912490fe3541991c","value":"spm.model: 100%"}},"57d07143c3b54fb2baad23f96e0874aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"588ef8f9110e4ba8897785a7816b52a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d4e90cc3beb40b890ffd3978dfb22d8","max":1736592160,"min":0,"orientation":"horizontal","style":"IPY_MODEL_150f7c2a80124dad8408945c7c4a0fce","value":1736592160}},"640eb7d806d7408ba3ba560fa99b9142":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73ed4c4fc9104779b8fdb3fc52e64f4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa4f2028d4be4adfb1389b240b2c7ee0","placeholder":"​","style":"IPY_MODEL_cd53dfa32e15440aadac97ed88dbec02","value":" 580/580 [00:00&lt;00:00, 52.0kB/s]"}},"76c12b9e7502419da6c5d8afae0b45ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eb63820b62d49ea9bc8059798aabfb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_464d8379cbd842b6b0c919aa12c237ad","IPY_MODEL_d006714a85f746a2a1485b6e1faf7003","IPY_MODEL_42cdc6d0d53e4ab298128b8581bf4c3a"],"layout":"IPY_MODEL_25126573d458497987981721450a08ae"}},"999bd4cca8c94c3a8c59da5cb58d8c2e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ae4657f98844aa686e0a73f6bb69972":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_efc7d8e9f3cc457f93faf7367ab86cd3","IPY_MODEL_f37802e035ff44d181776f86eabe948d","IPY_MODEL_a915e75f5ed847a7b44823aadb68b8e3"],"layout":"IPY_MODEL_9cc123d4a6da4ac9bf37029593171ca6"}},"9cc123d4a6da4ac9bf37029593171ca6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d8022fde15349cf92f52a24eac326ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0ed8c5740e846b7912490fe3541991c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a915e75f5ed847a7b44823aadb68b8e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_640eb7d806d7408ba3ba560fa99b9142","placeholder":"​","style":"IPY_MODEL_1e281edfb4944800b70ca3e7b078cd13","value":" 52.0/52.0 [00:00&lt;00:00, 4.37kB/s]"}},"aa1ceb8e11cc412ea3062b14dcb51319":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3852559827e4748844d3b2927447926","max":580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b2c1961d94c4a07b162c8e1f1f4ea8f","value":580}},"aa4f2028d4be4adfb1389b240b2c7ee0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad398d8a95ab459abdfa03879da117ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afa499e764d4423fbc616d6a8de52fd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8b1ba7cf2354528ab658faf56c8985f","placeholder":"​","style":"IPY_MODEL_c4ef64c1429c4d049c4b952e1906bf5e","value":" 1.74G/1.74G [00:41&lt;00:00, 42.6MB/s]"}},"b3852559827e4748844d3b2927447926":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba8f192523cf4f3d81fe72f0c6b16060":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4ef64c1429c4d049c4b952e1906bf5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cae13970055a44a09fbe31e19911087a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76c12b9e7502419da6c5d8afae0b45ab","placeholder":"​","style":"IPY_MODEL_2ed7fd040a494b91bcb6b11bf17446a7","value":"config.json: 100%"}},"cd53dfa32e15440aadac97ed88dbec02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cde68addf7004559a03c89e3c5cd5070":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d006714a85f746a2a1485b6e1faf7003":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba8f192523cf4f3d81fe72f0c6b16060","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57d07143c3b54fb2baad23f96e0874aa","value":2464616}},"deefef886f9c43cf88f6f162100f2e3e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8b1ba7cf2354528ab658faf56c8985f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efc7d8e9f3cc457f93faf7367ab86cd3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f8ee3fcf5ed47f08eb3eeaff0647d5e","placeholder":"​","style":"IPY_MODEL_cde68addf7004559a03c89e3c5cd5070","value":"tokenizer_config.json: 100%"}},"f37802e035ff44d181776f86eabe948d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c55a6f3b2d6453d92734e1c2c6ccf3d","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f7d29516b7a46dcb0fa01415173e1df","value":52}},"f37f807ded5e4af5a607d3a76b4de99f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cae13970055a44a09fbe31e19911087a","IPY_MODEL_aa1ceb8e11cc412ea3062b14dcb51319","IPY_MODEL_73ed4c4fc9104779b8fdb3fc52e64f4e"],"layout":"IPY_MODEL_9d8022fde15349cf92f52a24eac326ed"}},"ff9e6813dd3d499f8c44902f3806b49c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_999bd4cca8c94c3a8c59da5cb58d8c2e","placeholder":"​","style":"IPY_MODEL_ad398d8a95ab459abdfa03879da117ba","value":"tf_model.h5: 100%"}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nimport warnings\nimport logging\nimport pickle\nimport inspect\nimport os\nimport gc\n\n# disabling unnecceseray warnings\nwarnings.simplefilter(\"ignore\")\nlogging.disable(logging.ERROR)\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nimport tensorflow as tf\nfrom transformers import TFAutoModel, AutoTokenizer\nfrom tensorflow import keras\nfrom keras import layers\nimport datetime\nfrom keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold, GroupKFold\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom typing import List\nimport shutil\nimport json\nfrom tqdm import tqdm\nimport nltk\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nimport spacy\nimport re\nimport lightgbm \nfrom lightgbm import LGBMRegressor, log_evaluation, early_stopping\ntqdm.pandas()\n\n\nkeras.mixed_precision.set_global_policy(\"mixed_float16\")\n\n# Limit the GPU memory growth using TensorFlow\n# physical_devices = tf.config.list_physical_devices('GPU')\n# if len(physical_devices) > 0:\n#     tf.config.experimental.set_memory_growth(physical_devices[0], True)\n    # tf.config.experimental.set_memory_growth(physical_devices[1], True)\n\nimport random\n# Set random seeds\nrandom_seed = 42\nnp.random.seed(random_seed)\ntf.random.set_seed(random_seed)\nrandom.seed(random_seed)\nkeras.utils.set_random_seed(random_seed)\n\n# !pip install /kaggle/input/autocorrect/autocorrect-2.6.1.tar\n# from autocorrect import Speller\n# spell = Speller(lang='en', fast=True)\n\n# !pip install /kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\n# from spellchecker import SpellChecker","metadata":{"papermill":{"duration":33.079441,"end_time":"2024-05-16T15:39:15.664457","exception":false,"start_time":"2024-05-16T15:38:42.585016","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-12T10:40:56.034080Z","iopub.execute_input":"2024-06-12T10:40:56.034394Z","iopub.status.idle":"2024-06-12T10:41:19.681799Z","shell.execute_reply.started":"2024-06-12T10:40:56.034362Z","shell.execute_reply":"2024-06-12T10:41:19.681077Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-06-12 10:40:58.913961: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-12 10:40:58.914088: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-12 10:40:59.048737: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"data_path = '/kaggle/input/commonlit-evaluate-student-summaries/'\n\n# prompts train\ntrain_pro = pd.read_csv(data_path + 'prompts_train.csv')\ntrain_pro.head(1)\n\n# summaries train\ntrain_sum = pd.read_csv(data_path + 'summaries_train.csv')\ntrain_sum.head(1)\n\ntrain = train_pro.merge(train_sum , on = \"prompt_id\")\ntrain.head(1)\n\n# prompts test\ntest_pro = pd.read_csv(data_path + 'prompts_test.csv')\ntest_pro.head(1)\n\n# summaries test\ntest_sum = pd.read_csv(data_path + 'summaries_test.csv')\ntest_sum.head(1)\ntest = test_pro.merge(test_sum , on = \"prompt_id\")\ntest.head()","metadata":{"papermill":{"duration":0.175105,"end_time":"2024-05-16T15:39:15.917548","exception":false,"start_time":"2024-05-16T15:39:15.742443","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-12T10:41:19.683531Z","iopub.execute_input":"2024-06-12T10:41:19.683721Z","iopub.status.idle":"2024-06-12T10:41:19.832795Z","shell.execute_reply.started":"2024-06-12T10:41:19.683699Z","shell.execute_reply":"2024-06-12T10:41:19.831996Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"  prompt_id prompt_question     prompt_title       prompt_text    student_id  \\\n0    abc123    Summarize...  Example Title 1  Heading\\nText...  000000ffffff   \n1    abc123    Summarize...  Example Title 1  Heading\\nText...  222222cccccc   \n2    def789    Summarize...  Example Title 2  Heading\\nText...  111111eeeeee   \n3    def789    Summarize...  Example Title 2  Heading\\nText...  333333dddddd   \n\n             text  \n0  Example text 1  \n1  Example text 3  \n2  Example text 2  \n3  Example text 4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>student_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abc123</td>\n      <td>Summarize...</td>\n      <td>Example Title 1</td>\n      <td>Heading\\nText...</td>\n      <td>000000ffffff</td>\n      <td>Example text 1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abc123</td>\n      <td>Summarize...</td>\n      <td>Example Title 1</td>\n      <td>Heading\\nText...</td>\n      <td>222222cccccc</td>\n      <td>Example text 3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>def789</td>\n      <td>Summarize...</td>\n      <td>Example Title 2</td>\n      <td>Heading\\nText...</td>\n      <td>111111eeeeee</td>\n      <td>Example text 2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>def789</td>\n      <td>Summarize...</td>\n      <td>Example Title 2</td>\n      <td>Heading\\nText...</td>\n      <td>333333dddddd</td>\n      <td>Example text 4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load DeBERTa\nmodel_path = \"/kaggle/input/deberta-v3-large/deberta_v3_large/model\"\ntokenizer_path = \"/kaggle/input/deberta-v3-large/deberta_v3_large/tokenizer\"\n\npre_trained_model = TFAutoModel.from_pretrained(model_path) \ntokenizer = AutoTokenizer.from_pretrained(tokenizer_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:41:19.833971Z","iopub.execute_input":"2024-06-12T10:41:19.834181Z","iopub.status.idle":"2024-06-12T10:41:46.157704Z","shell.execute_reply.started":"2024-06-12T10:41:19.834157Z","shell.execute_reply":"2024-06-12T10:41:46.156938Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing (Head only model)","metadata":{}},{"cell_type":"code","source":"# Auto correcting spellings of all summaries\nsep = f\" {tokenizer.sep_token} \"\n\nprefix1 = \"Think through this step by step: \"\nprefix2 = \"Pay attention to the content and wording: \"\n\ntrain[\"text\"] = train[\"text\"].apply(lambda x: spell(x))\ntrain['input'] = prefix1 + train['prompt_question'] + sep + prefix2 + train['text']\nprint(train['input'][0])\n\n# Tokenize text data\nMAX_SUMMARY_LENGTH = 1500 + len(prefix1) + len(prefix2)\n\ntokenized_summaries = tokenizer.batch_encode_plus(train['input'].tolist(),\n                                              add_special_tokens=False,\n                                              truncation=True,\n                                              padding='max_length',\n                                              return_tensors='tf',\n                                              max_length=MAX_SUMMARY_LENGTH,\n                                              return_attention_mask=True)\ndel tokenized_summaries['token_type_ids']\n\n# Create head mask that excludes anything but sep + prefix2 + train['text']\nhead_mask = np.zeros(tokenized_summaries['input_ids'].shape)\nfor i, summary in enumerate(tokenized_summaries['input_ids'].numpy()):\n    use_full = False\n    for j, token in enumerate(summary):\n        if token == tokenizer.sep_token_id:\n            use_full = not use_full  \n        head_mask[i][j] = (1 if use_full else 0) \nhead_mask = tf.constant(head_mask)\nhead_mask","metadata":{"papermill":{"duration":6.221924,"end_time":"2024-05-16T15:40:23.962893","exception":false,"start_time":"2024-05-16T15:40:17.740969","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-11T11:37:15.337909Z","iopub.execute_input":"2024-06-11T11:37:15.338156Z","iopub.status.idle":"2024-06-11T11:38:41.868414Z","shell.execute_reply.started":"2024-06-11T11:37:15.338126Z","shell.execute_reply":"2024-06-11T11:38:41.867504Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Think through this step by step: Summarize at least 3 elements of an ideal tragedy, as described by Aristotle. [SEP] Pay attention to the content and wording: 1 element of an ideal tragedy is that it should be arranged on a complex plan.  Another element of an ideal tragedy is that it should only have one main issue. The last element of an ideal tragedy is that it should have a double thread plot and an opposite catastrophe for both good and bad.\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(7165, 1575), dtype=float64, numpy=\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Load Masked Embeddings (Head only Model)","metadata":{}},{"cell_type":"code","source":"# DeBERTa \nfile_path = '/kaggle/input/pooled-deberta-embeddings/pooled_deberta_embeddings.csv'# from input folder\n\n# Load masked pooled Deberta embeddings\nwith open('/kaggle/input/masked-pooled-deberta-embeddings/masked_pooled_deberta_embeddings_no_title.pkl', 'rb') as f:\n    loaded_array = pickle.load(f)\n# Load embeddings\nX_train_preprocessed = pd.read_csv(file_path)\n\n\nX_train_preprocessed['embeddings'] = X_train_preprocessed['embeddings'].apply(lambda x: list(map(float, x.split(','))))\nX_train_preprocessed['masked_embeddings'] = loaded_array.tolist()\n# Save a csv file\n# df_to_save = df_with_embeddings['pooled_roberta_embedding'].apply(lambda x: ','.join(map(str, x)))\n# df_to_save.to_csv(file_path, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-11T09:37:14.275314Z","iopub.execute_input":"2024-06-11T09:37:14.275893Z","iopub.status.idle":"2024-06-11T09:37:18.199295Z","shell.execute_reply.started":"2024-06-11T09:37:14.275858Z","shell.execute_reply":"2024-06-11T09:37:18.198599Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Define Head Only Model","metadata":{}},{"cell_type":"code","source":"Y_train = tf.constant(train[['content', 'wording']].values, dtype=tf.float32)\nY_train_np = Y_train.numpy()\nX_train_input = np.array(X_train_preprocessed['masked_embeddings'].tolist())\n\n# The loss function\ndef mcrmse(y_true, y_pred):\n    columnwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=0)\n    return tf.reduce_mean(tf.sqrt(columnwise_mse), axis=-1)\n\ninit_lr = 0.00015\nlr_schedule = tf.keras.optimizers.schedules.CosineDecay(init_lr, decay_steps=100000)","metadata":{"execution":{"iopub.status.busy":"2024-06-11T09:37:35.967033Z","iopub.execute_input":"2024-06-11T09:37:35.967804Z","iopub.status.idle":"2024-06-11T09:37:36.499813Z","shell.execute_reply.started":"2024-06-11T09:37:35.967773Z","shell.execute_reply":"2024-06-11T09:37:36.499088Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# def concat_embedding(x):\n#     expanded_text_embedding = tf.expand_dims(prefix_embed, axis=0)\n#     tiled_text_embedding = tf.tile(expanded_text_embedding, [tf.shape(x)[0], 1, 1])\n#     expanded_input_tensor = tf.expand_dims(x, axis=1)\n#     return tf.concat([tiled_text_embedding, expanded_input_tensor], axis=1)\n\n# # Use prefix2 embed\n#\n# prefix_tensor = tokenizer.encode(prefix, add_special_tokens=False, return_tensors='tf')\n# tokenized_prefix = tokenizer.encode(prefix2, add_special_tokens=False, return_tensors='tf')\n# prefix_len = len(tokenized_prefix)\n# prefix_embed = pre_trained_model(tokenized_prefix)[0]\n# prefix_embed = tf.cast(tf.reduce_mean(prefix_embed, axis=1), dtype=tf.float16)\n\n# NN with embeddings preprocessed\ndef create_model_preprocessed():\n    input_shape = len(X_train_preprocessed['masked_embeddings'][0])\n    input_layer = keras.Input(shape=(input_shape, ), dtype='float32')\n    \n    x = layers.LayerNormalization(name='layer_norm1')(input_layer)\n    x = layers.Reshape((1,input_shape,), name='reshape_layer')(x)\n    x = layers.LSTM(128, return_sequences=True, name='LSTM_layer1', activation='linear')(x)\n    x = layers.LayerNormalization(name='layer_norm2')(x)\n    x = layers.Activation(keras.activations.tanh, name='tanh1')(x)\n    \n    x = layers.LSTM(32, return_sequences=True, name='LSTM_layer2', activation='linear')(x)\n    x = layers.LayerNormalization(name='layer_norm3')(x)\n    x = layers.Activation(keras.activations.tanh, name='tanh2')(x)\n    x = layers.Dropout(0.4, name='dropout_layer')(x)\n    x = layers.GlobalAveragePooling1D()(x)\n    \n#     x = layers.Dense(16, activation='linear', name='dense_layer')(x)\n#     x = layers.Dropout(0.5, name='dropout_layer3')(x)\n\n    output_layer = layers.Dense(2, activation='linear', name='output_layer')(x)\n    \n    model = keras.Model(inputs=input_layer, outputs=output_layer)\n\n    for layer in model.layers:\n        layer.trainable = True\n\n    opt = keras.optimizers.Adam(learning_rate=lr_schedule, use_ema=True)\n    model.compile(loss=mcrmse, optimizer=opt)\n    \n    return model\n\nmodel = create_model_preprocessed()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-11T09:39:35.770931Z","iopub.execute_input":"2024-06-11T09:39:35.771202Z","iopub.status.idle":"2024-06-11T09:39:35.858028Z","shell.execute_reply.started":"2024-06-11T09:39:35.771161Z","shell.execute_reply":"2024-06-11T09:39:35.857281Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_7\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_norm1                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m2,048\u001b[0m │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reshape_layer (\u001b[38;5;33mReshape\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ LSTM_layer1 (\u001b[38;5;33mLSTM\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m590,336\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_norm2                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ tanh1 (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ LSTM_layer2 (\u001b[38;5;33mLSTM\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │        \u001b[38;5;34m20,608\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_norm3                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │            \u001b[38;5;34m64\u001b[0m │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ tanh2 (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_layer (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling1d_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m66\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_norm1                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reshape_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ LSTM_layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,336</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_norm2                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ tanh1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ LSTM_layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_norm3                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ tanh2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling1d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m613,378\u001b[0m (2.34 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">613,378</span> (2.34 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m613,378\u001b[0m (2.34 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">613,378</span> (2.34 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# Train Head Only Model","metadata":{}},{"cell_type":"code","source":"# Train head only model\nval_losses = []\nhistories = []\ngkf = GroupKFold(n_splits=4)\nfolds = gkf.split(X_train_input, Y_train_np, groups=train['prompt_id'])\n\nfor i, (train_index, val_index) in enumerate(folds):\n    print(f\"Fold {i + 1}\")\n    \n    # Split data into training and validation sets\n    X_train_fold, X_val_fold = X_train_input[train_index], X_train_input[val_index]\n    Y_train_fold, Y_val_fold = Y_train_np[train_index], Y_train_np[val_index]\n    \n    # Create and compile your model\n    model = create_model_preprocessed()\n    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n    ema = keras.callbacks.SwapEMAWeights(swap_on_epoch=True)\n    # Checkpoint callback\n#     ckptcb = keras.callbacks.ModelCheckpoint(\n#         f\"model_fold_{i}\" + \".weights.h5\",\n#         monitor=\"val_loss\",\n#         save_best_only=True,\n#         save_weights_only=True,\n#         mode=\"min\",\n#     )    \n\n    # Train the model\n    history = model.fit(x=X_train_fold,\n                        y=Y_train_fold,\n                        epochs=100,\n                        batch_size=4,\n                        validation_data=(X_val_fold, Y_val_fold),\n                        callbacks=[ema, early_stopping],\n                        verbose=2)\n    \n    # Get the validation loss from the last epoch\n    val_loss = min(history.history['val_loss'])\n    val_losses.append(val_loss)\n    histories.append(history)\n    print()\n\n# Calculate the mean validation loss\nmean_val_loss = np.mean(val_losses)\nprint(\"Mean Validation Loss:\", mean_val_loss)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# **Results**\n\n# REAL RESULTS\n\n# baseline no grouped KFolds: 0.4437254548072815\n# baseline with grouped KFolds: 0.5310284495353699\n# From now on everything will be with grouped KFolds\n# EMA: 0.5303183048963547\n# EMA + lr_decay_steps=100000 + LSTM1=128 + LSTM2=64 + Dropout_after_LSTM2=0.6: 0.5258100032806396\n# EMA + lr_decay_steps=100000 + LSTM1=128 + LSTM2=32 + Dropout_after_LSTM2=0.4: 0.5223950520157814\n\n\n# FAKE RESULTS:\n# group: 0.421 | 0.41956\n# with regularization everywhere: 0.6671039313077927\n# with reg=0.0001: 0.48\n# with reg=1e-5: 0.4328196793794632\n# without Dense layers of 16: 0.4203761890530586\n# reduce Dropout to 0.2: 0.415641151368618\n# dropout: 0.5, dense: relu +32, LSTM: 64: 0.44807666540145874 (large gap :> ) \n# With EMA: 0.4412180408835411 (keeped the large gaps)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing (Full Model)","metadata":{}},{"cell_type":"code","source":"sep = f\" {tokenizer.sep_token} \"\nprefix1 = \"Think through this step by step: \"\nprefix2 = \"Pay attention to the content and wording: \"\nMAX_SUMMARY_LENGTH = 1500 + len(prefix1) + len(prefix2)\n\ndef preprocess(summary, prompt_question, prompt_text):\n\n    summary = prefix1 + prompt_question + sep + prefix2 + summary + sep + prompt_text\n    tokenized = tokenizer.batch_encode_plus(summary.tolist(),\n                                              add_special_tokens=False,\n                                              truncation=True,\n                                              padding='max_length',\n                                              return_tensors='tf',\n                                              max_length=MAX_SUMMARY_LENGTH,\n                                              return_attention_mask=True)\n    \n    input_ids = tokenized['input_ids']\n    attention_mask = tokenized['attention_mask']\n\n    # Create head mask\n    head_mask = np.zeros(input_ids.shape)\n    for i, summ in enumerate(input_ids.numpy()):\n        use_full = False\n        for j, token in enumerate(summ):\n            if token == tokenizer.sep_token_id:\n                use_full = not use_full  \n            head_mask[i][j] = (1. if use_full else 0.) \n    head_mask = tf.constant(head_mask)\n    \n    return input_ids, attention_mask, head_mask\n    \ndef build_dataset(summaries, prompt_questions, prompt_texts):\n    \n    # Perform augmentation here before tokenization\n    #TODO\n    \n    # Tokenization\n    input_ids, attention_mask, head_mask = preprocess(summaries, prompt_questions, prompt_texts)\n    return [input_ids.numpy(), attention_mask.numpy(), head_mask.numpy()]","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:41:46.159662Z","iopub.execute_input":"2024-06-12T10:41:46.159873Z","iopub.status.idle":"2024-06-12T10:41:46.169301Z","shell.execute_reply.started":"2024-06-12T10:41:46.159848Z","shell.execute_reply":"2024-06-12T10:41:46.168404Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Check head mask of first prompt (for debug)\n# ids, mask, head = build_dataset(train['text'], train['prompt_question'], train['prompt_text'])\n# train['input'] = prefix1 + train['prompt_question'] + sep + prefix2 + train['text'] + sep + train['prompt_text']\n# first = tokenizer.tokenize(train['input'][0],                                               \n#           add_special_tokens=False,\n#           truncation=True,\n#           padding='max_length',\n#           return_tensors='tf',\n#           max_length=MAX_SUMMARY_LENGTH,\n#           return_attention_mask=False)\n\n# def find_indexes(array):\n#     return [index for index, value in enumerate(array) if value == 1]\n# np.array(first)[find_indexes(head[0])]","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:36:07.161843Z","iopub.execute_input":"2024-06-12T10:36:07.162631Z","iopub.status.idle":"2024-06-12T10:37:19.251828Z","shell.execute_reply.started":"2024-06-12T10:36:07.162583Z","shell.execute_reply":"2024-06-12T10:37:19.250797Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# Define Full Model","metadata":{}},{"cell_type":"code","source":"# build our NN on top of Deberta\n\n# Create a layer that wraps the pre trained model to support Keras library\nclass PreTrainedModel(keras.Model):\n    def __init__(self, pre_trained_model, trainable=True, num_layers_to_freeze=8, name=None, **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.pre_trained_model = pre_trained_model\n        self.pre_trained_model.config.hidden_dropout_prob = 0.0\n        self.pre_trained_model.config.attention_probs_dropout_prob = 0.0\n        self.trainable = trainable\n        self.num_layers_to_freeze = num_layers_to_freeze\n        self.pre_trained_model.trainable = self.trainable\n\n        if self.trainable:\n            self.pre_trained_model.trainable = self.trainable\n            if self.trainable:\n                for layer in self.pre_trained_model.layers[0].encoder.layer[:self.num_layers_to_freeze]:\n                    layer.trainable = False\n\n        # Dynamically create properties from pre-trained model\n        # for prop_name, prop in inspect.getmembers(self.pre_trained_model):\n        #    if not prop_name.startswith('_') and not inspect.ismethod(prop):\n        #        setattr(self.__class__, prop_name, prop)\n\n    def call(self, input_ids, attention_mask):\n        # Call the pre trained model and get the last hidden state\n        output = self.pre_trained_model(input_ids=tf.cast(input_ids, tf.int32), attention_mask=tf.cast(attention_mask, tf.int32), output_hidden_states=True)\n        return output.hidden_states","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:41:46.170489Z","iopub.execute_input":"2024-06-12T10:41:46.170689Z","iopub.status.idle":"2024-06-12T10:41:46.186244Z","shell.execute_reply.started":"2024-06-12T10:41:46.170658Z","shell.execute_reply":"2024-06-12T10:41:46.185501Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# The loss function\ndef mcrmse(y_true, y_pred):\n    columnwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=0)\n    return tf.reduce_mean(tf.sqrt(columnwise_mse), axis=-1)\n\ninit_lr = 0.00015\nlr_schedule = tf.keras.optimizers.schedules.CosineDecay(init_lr, decay_steps=10000)","metadata":{"papermill":{"duration":0.032128,"end_time":"2024-05-16T15:40:24.400490","exception":false,"start_time":"2024-05-16T15:40:24.368362","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-12T10:41:46.187370Z","iopub.execute_input":"2024-06-12T10:41:46.187602Z","iopub.status.idle":"2024-06-12T10:41:46.201078Z","shell.execute_reply.started":"2024-06-12T10:41:46.187574Z","shell.execute_reply":"2024-06-12T10:41:46.200239Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def create_model(input_shape=(1575,), embeddings_len=1024):\n    \n    # Instances\n    pre_trained_model_instance = PreTrainedModel(pre_trained_model, name=\"deberta_layer\")\n    expand_dims_instance = layers.Lambda(lambda x: tf.expand_dims(tf.cast(x, dtype=tf.float32), axis=-1), name=f'expand_dims')\n    mask_instance = layers.Lambda(lambda x: tf.multiply(x[0], x[1]), output_shape=(1575, embeddings_len,), name='masked_embeddings')\n    avg_pooling_instance = layers.GlobalAveragePooling1D()\n    reshape_instance = layers.Reshape((1, -1), name='reshape_layer')\n    \n    # The NN starts from here\n    \n    # Input layers\n    input_ids = keras.Input(shape=input_shape, dtype='int32', name='input_ids')\n    attention_mask = keras.Input(shape=input_shape, dtype='int32', name='attention_mask')\n    head_mask = keras.Input(shape=input_shape, dtype='float32', name='head_mask')\n    \n    # Create embeddings and mask pool them\n    deberta = pre_trained_model_instance(input_ids, attention_mask)\n    \n    # mask pooling all hidden states of pre-trained model\n    pooled_hidden_states = []\n    for i in range(len(deberta)):\n        h_mask = expand_dims_instance(head_mask)\n        masked_outputs = mask_instance([deberta[-i], h_mask])\n        avg_pooling_layer = avg_pooling_instance(masked_outputs)\n        reshape_layer = reshape_instance(avg_pooling_layer)\n        pooled_hidden_states.append(reshape_layer)\n        \n    # concatenate all the hidden states an forward pass through LSTM\n    x = layers.Concatenate(axis=1)(pooled_hidden_states)\n    x = layers.LSTM(embeddings_len, return_sequences=False)(x)\n    \n    output_layer = layers.Dense(2, activation='linear', name='output_layer')(x)\n    \n    \n    model = keras.Model(inputs=[input_ids, attention_mask, head_mask], outputs=output_layer)\n    for layer in model.layers:\n        layer.trainable = True\n    \n    opt = keras.optimizers.Adam(learning_rate=lr_schedule, use_ema=True)\n    model.compile(loss=mcrmse, optimizer=opt)\n    return model, pre_trained_model_instance\n\nmodel, deberta_model = create_model()\nmodel.summary()\n\n# model.load_weights(\"/kaggle/input/no-aug-model-weights/no_augmentation_model.weights.h5\")\n# deberta_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:41:49.133408Z","iopub.execute_input":"2024-06-12T10:41:49.133673Z","iopub.status.idle":"2024-06-12T10:42:26.061532Z","shell.execute_reply.started":"2024-06-12T10:41:49.133644Z","shell.execute_reply":"2024-06-12T10:42:26.060705Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_ids           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_mask      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ head_mask           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ deberta_layer       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│ (\u001b[38;5;33mPreTrainedModel\u001b[0m)   │ \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │ attention_mask[\u001b[38;5;34m0\u001b[0m… │\n│                     │ \u001b[38;5;34m1575\u001b[0m, \u001b[38;5;34m1024\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m,      │            │                   │\n│                     │ \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │                   │\n│                     │ \u001b[38;5;34m1575\u001b[0m, \u001b[38;5;34m1024\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m,      │            │                   │\n│                     │ \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │                   │\n│                     │ \u001b[38;5;34m1575\u001b[0m, \u001b[38;5;34m1024\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m,      │            │                   │\n│                     │ \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │                   │\n│                     │ \u001b[38;5;34m1575\u001b[0m, \u001b[38;5;34m1024\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m,      │            │                   │\n│                     │ \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │                   │\n│                     │ \u001b[38;5;34m1575\u001b[0m, \u001b[38;5;34m1024\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m,      │            │                   │\n│                     │ \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │                   │\n│                     │ \u001b[38;5;34m1575\u001b[0m, \u001b[38;5;34m1024\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m,      │            │                   │\n│                     │ \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │                   │\n│                     │ \u001b[38;5;34m1575\u001b[0m, \u001b[38;5;34m1024\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m,      │            │                   │\n│                     │ \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │                   │\n│                     │ \u001b[38;5;34m1575\u001b[0m, \u001b[38;5;34m1024\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m,      │            │                   │\n│                     │ \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │                   │\n│                     │ \u001b[38;5;34m1575\u001b[0m, \u001b[38;5;34m1024\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m,      │            │                   │\n│                     │ \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │                   │\n│                     │ \u001b[38;5;34m1575\u001b[0m, \u001b[38;5;34m1024\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m,      │            │                   │\n│                     │ \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │                   │\n│                     │ \u001b[38;5;34m1575\u001b[0m, \u001b[38;5;34m1024\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m,      │            │                   │\n│                     │ \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │                   │\n│                     │ \u001b[38;5;34m1575\u001b[0m, \u001b[38;5;34m1024\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m,      │            │                   │\n│                     │ \u001b[38;5;34m1024\u001b[0m)]            │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ expand_dims         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│ (\u001b[38;5;33mLambda\u001b[0m)            │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ masked_embeddings   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mLambda\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │ expand_dims[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m9\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m10\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m11\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m12\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m13\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m14\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m15\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m16\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m17\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m18\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m19\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m20\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m21\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m22\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m23\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │                   │            │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ expand_dims[\u001b[38;5;34m24\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ masked_embedding… │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_layer       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ reshape_layer[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ reshape_layer[\u001b[38;5;34m1\u001b[0m]… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m2\u001b[0m]… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m3\u001b[0m]… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m4\u001b[0m]… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m5\u001b[0m]… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m6\u001b[0m]… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m7\u001b[0m]… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m8\u001b[0m]… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m9\u001b[0m]… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m10\u001b[0m… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m11\u001b[0m… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m12\u001b[0m… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m13\u001b[0m… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m14\u001b[0m… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m15\u001b[0m… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m16\u001b[0m… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m17\u001b[0m… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m18\u001b[0m… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m19\u001b[0m… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m20\u001b[0m… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m21\u001b[0m… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m22\u001b[0m… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m23\u001b[0m… │\n│                     │                   │            │ reshape_layer[\u001b[38;5;34m24\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │  \u001b[38;5;34m8,392,704\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ output_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │      \u001b[38;5;34m2,050\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_ids           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_mask      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ head_mask           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ deberta_layer       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PreTrainedModel</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │ attention_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>,      │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>,      │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>,      │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>,      │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>,      │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>,      │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>,      │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>,      │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>,      │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>,      │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>,      │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>,      │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)]            │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ expand_dims         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ masked_embeddings   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │                   │            │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ masked_embedding… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n│                     │                   │            │ masked_embedding… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_layer       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n│                     │                   │            │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>]… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>]… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>]… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>]… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>]… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>]… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>]… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>… │\n│                     │                   │            │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">8,392,704</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ output_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,050</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,394,754\u001b[0m (32.02 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,394,754</span> (32.02 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,394,754\u001b[0m (32.02 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,394,754</span> (32.02 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# Train Full Model","metadata":{}},{"cell_type":"code","source":"# GroupKFolds Train\n\nX = train[['text', 'prompt_question', 'prompt_text']]\ny = train[['content', 'wording']]\n\ngkf = GroupKFold(n_splits=4)\nfolds = gkf.split(X, y, groups=train['prompt_id'])\n\nval_losses = []\nhistories = []\n\nfor i, (train_index, val_index) in enumerate(folds):\n    print(f\"Fold {i}\")\n    if i != 1:\n        continue\n    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n    \n    X_train_fold = build_dataset(X_train_fold['text'], X_train_fold['prompt_question'], X_train_fold['prompt_text'])\n    X_val_fold = build_dataset(X_val_fold['text'], X_val_fold['prompt_question'], X_val_fold['prompt_text'])\n    model, _ = create_model()\n    \n    early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n    ema = keras.callbacks.SwapEMAWeights(swap_on_epoch=True)\n    \n    # Checkpoint callback\n    ckptcb = keras.callbacks.ModelCheckpoint(\n        f\"full_model_fold_{i}\" + \".weights.h5\",\n        monitor=\"val_loss\",\n        save_best_only=True,\n        save_weights_only=True,\n        mode=\"min\",\n    ) \n    \n    history = model.fit(x=X_train_fold,\n                        y=y_train_fold.values,\n                        validation_data=(X_val_fold, y_val_fold.values),\n                        epochs=3,\n                        batch_size=8,\n                        callbacks=[ema, early_stopping, ckptcb],\n                        verbose=1)\n    \n    # Get the validation loss from the last epoch\n    val_loss = min(history.history['val_loss'])\n    val_losses.append(val_loss)\n    histories.append(history)\n    print()\n    \n# Calculate the mean validation loss\nmean_val_loss = np.mean(val_losses)\nprint(\"Mean Validation Loss:\", mean_val_loss)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:42:26.063300Z","iopub.execute_input":"2024-06-12T10:42:26.063506Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Fold 0\nFold 1\nEpoch 1/3\n\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4050s\u001b[0m 6s/step - loss: 0.6690 - val_loss: 0.5663\nEpoch 2/3\n\u001b[1m392/645\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m18:44\u001b[0m 4s/step - loss: 0.4972","output_type":"stream"}]},{"cell_type":"markdown","source":"# Meta Psuedo Labels Training loop","metadata":{}},{"cell_type":"code","source":"# # loading augmented data\n# augmented_data = pd.read_excel('/kaggle/input/llm-generate-test/LLM_Generate_Test.xlsx')\n# augmented_data.columns = ['student_id', 'prompt_text', 'prompt_question', 'text']\n\n# augmented_data[\"text\"] = augmented_data[\"text\"].apply(lambda x: spell(x))\n# augmented_data['input'] = prefix1 + augmented_data['prompt_question'] + sep + prefix2 + augmented_data['text']","metadata":{"execution":{"iopub.status.busy":"2024-06-07T21:36:06.894676Z","iopub.execute_input":"2024-06-07T21:36:06.894939Z","iopub.status.idle":"2024-06-07T21:36:25.304372Z","shell.execute_reply.started":"2024-06-07T21:36:06.894916Z","shell.execute_reply":"2024-06-07T21:36:25.303663Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def generate_predictions(model, data):\n    contents = []\n    wordings = []\n    ids = []\n    predictions = model.predict(x=[data['input_ids'], data['attention_mask'], data['head_mask']],\n                                batch_size=4)\n\n    for idx, output in enumerate(predictions):\n        contents.append(output[0])\n        wordings.append(output[1])\n        ids.append(data['student_id'][idx])\n    return ids, contents, wordings","metadata":{"execution":{"iopub.status.busy":"2024-06-08T21:52:08.176730Z","iopub.execute_input":"2024-06-08T21:52:08.176941Z","iopub.status.idle":"2024-06-08T21:52:08.187449Z","shell.execute_reply.started":"2024-06-08T21:52:08.176918Z","shell.execute_reply":"2024-06-08T21:52:08.186735Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# # Tokenizing augmented data\n# tokenized_summaries_aug = tokenizer.batch_encode_plus(augmented_data['input'].tolist(),\n#                                               add_special_tokens=True,\n#                                               truncation=True,\n#                                               padding='max_length',\n#                                               return_tensors='tf',\n#                                               max_length=MAX_SUMMARY_LENGTH,\n#                                               return_attention_mask = True)\n# del tokenized_summaries_aug['token_type_ids']\n\n# # Create head mask that excludes anything but sep + prefix2 + train['text']\n# head_mask_aug = np.zeros(tokenized_summaries_aug['input_ids'].shape)\n# for i, summary in enumerate(tokenized_summaries_aug['input_ids'].numpy()):\n#     use_full = False\n#     for j, token in enumerate(summary):\n#         if token == tokenizer.sep_token_id:\n#             use_full = not use_full\n#         head_mask_aug[i][j] = (1 if use_full else 0) \n# head_mask_aug = tf.constant(head_mask_aug)\n\n# aug_input = {\n#     'input_ids': tokenized_summaries_aug['input_ids'],\n#     'attention_mask': tokenized_summaries_aug['attention_mask'],\n#     'head_mask': head_mask_aug,\n#     'student_id': augmented_data['student_id']\n# }","metadata":{"execution":{"iopub.status.busy":"2024-06-07T21:36:25.314476Z","iopub.execute_input":"2024-06-07T21:36:25.314661Z","iopub.status.idle":"2024-06-07T21:39:50.714377Z","shell.execute_reply.started":"2024-06-07T21:36:25.314637Z","shell.execute_reply":"2024-06-07T21:39:50.713567Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"ROUNDS = 3\nSAVED_DATASETS_INDEXES = [0, 1, 2]\nSAVED_WEIGHTS_INDEXES = [0, 1, 2]\n\n# the initial model\nmodel, _ = create_model()\n\nif SAVED_WEIGHTS_INDEXES[-1] == 0:\n    model.load_weights('/kaggle/input/no-aug-model-weights/no_augmentation_model.weights.h5')\nelse:\n    print(f\"Loading weights: meta_model_{SAVED_WEIGHTS_INDEXES[-1]}\")\n    model.load_weights(f'/kaggle/input/meta-model-weights/meta_model_{SAVED_WEIGHTS_INDEXES[-1]}.weights.h5')\n\nY_train = tf.constant(train[['content', 'wording']].values, dtype=tf.float32)\nY_train = Y_train.numpy()\n\nfor i in range(ROUNDS):\n            \n    print(f\"Round {i + 1}/{ROUNDS}\")\n    \n    if i < SAVED_WEIGHTS_INDEXES[-1]:\n        continue\n    \n    # predict meta psuedo labels\n    \n    if i in SAVED_DATASETS_INDEXES:\n        # predictions already generated\n        if i == 0:\n            augmented_labeled_data = pd.read_csv('/kaggle/input/augmented-labeled-data/augmented_labeled_data.csv')\n        else:\n            augmented_labeled_data = pd.read_csv(f'/kaggle/input/augmented-labeled-data/augmented_labeled_data_round_{i + 1}.csv')\n    else:\n        print()\n        print(f\"Generateing predictions...\")\n        ids, contents, wordings = generate_predictions(model, aug_input)\n        augmented_data['content'] = contents\n        augmented_data['wording'] = wordings\n        augmented_data.to_csv(f\"augmented_labeled_data_round_{i + 1}.csv\")\n        augmented_labeled_data = augmented_data\n        \n    # update the labels    \n    Y_train_aug = tf.constant(augmented_labeled_data[['content', 'wording']].values, dtype=tf.float32)\n    Y_train_aug = Y_train_aug.numpy()\n\n    # checkpoint callback\n    ckptcb = keras.callbacks.ModelCheckpoint(\n        f\"meta_model_{i + 1}\" + \".weights.h5\",\n        monitor=\"loss\",\n        save_best_only=True,\n        save_weights_only=True,\n        mode=\"min\",\n    )\n    \n    print()\n    print(f\"Training on unlabeled data...\")\n    model.fit(x=[tokenized_summaries_aug['input_ids'], tokenized_summaries_aug['attention_mask'], head_mask_aug],\n                      y=Y_train_aug,\n                      epochs=2,\n                      batch_size=4,\n                      validation_data=([tokenized_summaries['input_ids'], tokenized_summaries['attention_mask'], head_mask], Y_train),\n                      verbose=1)\n    \n    # Fine tune the pre-trained model only on the labeled data\n    print()\n    print(f\"Training on labeled data...\")\n    model.fit(x=[tokenized_summaries['input_ids'], tokenized_summaries['attention_mask'], head_mask],\n                      y=Y_train,\n                      epochs=3,\n                      batch_size=4,\n                      callbacks=[ckptcb],\n                      verbose=1)\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-06-07T21:55:43.444684Z","iopub.execute_input":"2024-06-07T21:55:43.444956Z","iopub.status.idle":"2024-06-08T09:06:36.886494Z","shell.execute_reply.started":"2024-06-07T21:55:43.444926Z","shell.execute_reply":"2024-06-08T09:06:36.885217Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Loading weights: meta_model_1\nRound 1/3\nRound 2/3\n\nGenerateing predictions...\n\u001b[1m   1/5000\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48:40:10\u001b[0m 35s/step","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1717797400.180685     116 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1717797400.232535     116 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5529s\u001b[0m 1s/step\n\nTraining on unlabeled data...\nEpoch 1/2\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1717802965.185144     116 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.1885","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1717808521.972703     117 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1717810520.321222     116 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7620s\u001b[0m 2s/step - loss: 0.1885 - val_loss: 0.4478\nEpoch 2/2\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7500s\u001b[0m 2s/step - loss: 0.1660 - val_loss: 0.4378\n\nTraining on labeled data...\nEpoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1717818085.708646     115 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1791/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4596","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1717820098.837005     116 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2078s\u001b[0m 1s/step - loss: 0.4596\nEpoch 2/3\n\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1982s\u001b[0m 1s/step - loss: 0.4573\nEpoch 3/3\n\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1982s\u001b[0m 1s/step - loss: 0.4561\n\nRound 3/3\n\nGenerateing predictions...\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5494s\u001b[0m 1s/step\n\nTraining on unlabeled data...\nEpoch 1/2\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7502s\u001b[0m 2s/step - loss: 0.1541 - val_loss: 0.4378\nEpoch 2/2\n\u001b[1m 480/5000\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:14\u001b[0m 1s/step - loss: 0.1568","output_type":"stream"},{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# LGBM Model","metadata":{}},{"cell_type":"code","source":"# TODO","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"test[\"text\"] = test[\"text\"].apply(lambda x: spell(x))\ntest['input'] = test['prompt_title'] + sep + prefix1 + test['prompt_question'] + sep + prefix2 + test['text']\n\n# Tokenize summaries\ntokenized_summaries_test = tokenizer.batch_encode_plus(test['input'].tolist(),\n                                              add_special_tokens=True,\n                                              truncation=True,\n                                              padding='max_length',\n                                              return_tensors='tf',\n                                              max_length=MAX_SUMMARY_LENGTH,\n                                              return_attention_mask = True)\ndel tokenized_summaries_test['token_type_ids']\n\n# Create head mask that excludes anything but sep + prefix2 + train['text']\nhead_mask_test = np.zeros(tokenized_summaries_test['input_ids'].shape)\nfor i, summary in enumerate(tokenized_summaries_test['input_ids'].numpy()):\n    use_full = False\n    first_sep_flag = True\n    for j, token in enumerate(summary):\n        if token == tokenizer.sep_token_id:\n            if first_sep_flag:\n                first_sep_flag = False\n            else:\n                use_full = not use_full\n        head_mask_test[i][j] = (1 if use_full else 0) \nhead_mask_test = tf.constant(head_mask_test)\n\ntest_data = {\n    'input_ids': tokenized_summaries_test['input_ids'],\n    'attention_mask': tokenized_summaries_test['attention_mask'],\n    'head_mask': head_mask_test,\n    'student_id': test['student_id'],\n}\n\nweights_to_submit_path = '/kaggle/input/meta-model-weights/meta_model_3.weights.h5'\nmodel, _ = create_model()\nmodel.load_weights(weights_to_submit_path)\nids, contents, wordings = generate_predictions(model, test_data)\n\n# preds = []\n# for i in range(1,6):\n#     model, _ = create_model()\n#     model.load_weights(f'/kaggle/input/no-aug-model-folds-weights/no-aug-model-folds-weights/full_model_fold_{i}.weights.h5')\n    \n#     ids, contents, wordings = generate_predictions(model, test_data)\n#     preds.append([ids, contents, wordings])\n\n# # Calculate mean predictions\n# contents = np.stack([pred[1] for pred in preds]).mean(axis=0)\n# wordings = np.stack([pred[2] for pred in preds]).mean(axis=0)\n\nsubmission_df = pd.DataFrame({'student_id': ids,\n                              'content': contents,\n                              'wording': wordings})\n\nsubmission_df.to_csv(\"submission.csv\", index=False)\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-08T21:52:15.889864Z","iopub.execute_input":"2024-06-08T21:52:15.890154Z","iopub.status.idle":"2024-06-08T21:53:27.457291Z","shell.execute_reply.started":"2024-06-08T21:52:15.890122Z","shell.execute_reply":"2024-06-08T21:53:27.456399Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35s/step\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1717883606.275766      76 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1717883606.328375      76 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"     student_id   content   wording\n0  000000ffffff -1.656250 -1.487305\n1  222222cccccc -1.630859 -1.490234\n2  111111eeeeee -1.650391 -1.486328\n3  333333dddddd -1.634766 -1.495117","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000ffffff</td>\n      <td>-1.656250</td>\n      <td>-1.487305</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>222222cccccc</td>\n      <td>-1.630859</td>\n      <td>-1.490234</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>111111eeeeee</td>\n      <td>-1.650391</td>\n      <td>-1.486328</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>333333dddddd</td>\n      <td>-1.634766</td>\n      <td>-1.495117</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Leftovers","metadata":{}},{"cell_type":"code","source":"\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n\n# log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n\n\n# Model name to load\n# model_name =  \"microsoft/deberta-v3-large\"\n\n# # Load DeBERTa / RoBERTa model and tokenizer\n# tokenizer = AutoTokenizer.from_pretrained(model_name)\n# pre_trained_model = TFAutoModel.from_pretrained(model_name)\n\n\n# tokenizer.save_pretrained(\"deberta_v3_large_tokenizer\")\n# pre_trained_model.save_pretrained(\"deberta_v3_large_model\")\n\n\n\n# def get_embeddings(input_ids, attention_mask, model_name):\n    \n#     # Forward pass through pre trained model\n#     outputs = pre_trained_model(input_ids=input_ids, attention_mask=attention_mask)\n    \n#     if model_name == 'roberta-large':\n#         return outputs['pooler_output']\n#     else:\n#         return outputs[0]\n\n# # Save roberta/deberta embeddings in the training set\n\n# batch_size = 10 # ten is the biggest batch possible (can try maybe 11)\n# num_samples = len(X_train['input_ids'])\n# num_batches = (num_samples + batch_size - 1) // batch_size\n# averaged_embeddings = []\n\n# for i in range(num_batches):\n#     start_idx = i * batch_size\n#     end_idx = min((i + 1) * batch_size, num_samples)\n#     inputs = X_train['input_ids'][start_idx: end_idx]\n#     masks = X_train['attention_mask'][start_idx: end_idx]\n    \n#     embeddings = get_embeddings(input_ids=inputs, attention_mask=masks, model_name=model_name)\n#     h_mask = tf.expand_dims(tf.cast(head_mask[start_idx: end_idx], dtype=tf.float32), axis=-1)\n#     masked_outputs = tf.multiply(embeddings, h_mask)\n#     pooled = (tf.reduce_mean(masked_outputs, axis=1)).numpy()\n#     averaged_embeddings.append(pooled)\n    \n#     if i % int(num_batches * 0.1) == 0:\n#         print(f\"Batch {i}/{num_batches}\")\n        \n#     del embeddings\n#     del masked_outputs\n#     del pooled\n#     del h_mask\n#     gc.collect()\n#     tf.keras.backend.clear_session()\n# # Write to a file    \n# concatenated_embeddings = np.concatenate(averaged_embeddings, axis=0)\n# with open('masked_pooled_deberta_embeddings.pkl', 'wb') as f:\n#     pickle.dump(concatenated_embeddings, f)\n\n\n# Save file to output folder\n\n# # DeBERTa \n# file_path = '/kaggle/input/pooled-deberta-embeddings/pooled_deberta_embeddings.csv'# from input folder\n\n# # Load masked pooled Deberta embeddings\n# with open('/kaggle/input/masked-pooled-deberta-embeddings/mask_pooled_deberta_embeddings.pkl', 'rb') as f:\n#     loaded_array = pickle.load(f)\n# # Load embeddings\n# X_train_preprocessed = pd.read_csv(file_path)\n\n\n# X_train_preprocessed['embeddings'] = X_train_preprocessed['embeddings'].apply(lambda x: list(map(float, x.split(','))))\n# X_train_preprocessed['masked_embeddings'] = loaded_array.tolist()\n# Save a csv file\n# df_to_save = df_with_embeddings['pooled_roberta_embedding'].apply(lambda x: ','.join(map(str, x)))\n# df_to_save.to_csv(file_path, index=False)\n\n\n\n\n# # NN with embeddings preprocessed\n# def create_model_preprocessed():\n#     input_shape = len(X_train_preprocessed['masked_embeddings'][0])\n\n#     input_layer = keras.Input(shape=(input_shape, ), dtype='float32')\n    \n#     layer_norm = layers.LayerNormalization(name='layer_norm1')(input_layer)\n    \n#     reshape_input_layer = layers.Reshape((1,input_shape), name='reshape_layer')(layer_norm)\n    \n#     LSTM_layer = layers.LSTM(512, return_sequences=True, name='LSTM_layer1', activation='linear')(reshape_input_layer)\n    \n#     layer_norm = layers.LayerNormalization(name='layer_norm2')(LSTM_layer)\n    \n#     act = layers.Activation(keras.activations.tanh, name='tanh1')(layer_norm)\n    \n#     LSTM_layer = layers.LSTM(32, return_sequences=False, name='LSTM_layer2', activation='linear',)(act)\n    \n#     layer_norm = layers.LayerNormalization(name='layer_norm3')(LSTM_layer)\n    \n#     act = layers.Activation(keras.activations.tanh, name='tanh2')(layer_norm)\n    \n#     hidden_layer = layers.Dense(16, activation='linear', name='dense_layer')(act)\n    \n#     dropout = layers.Dropout(0.3, name='dropout_layer')(hidden_layer)\n    \n#     # batch_norm = layers.BatchNormalization(name='batch_norm')(dropout)\n\n#     output_layer = layers.Dense(2, activation='linear', name='output_layer')(dropout)\n    \n#     model = keras.Model(inputs=input_layer, outputs=output_layer)\n\n#     for layer in model.layers:\n#         layer.trainable = True\n        \n    \n#     opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n#     model.compile(loss=mcrmse, optimizer=opt)\n    \n#     return model\n\n# model = create_model_preprocessed()\n# model.summary()\n\n\n\n# Train prepocessed model (head only) without validation\n\n# Checkpoint callback\n# ckptcb = keras.callbacks.ModelCheckpoint(\n#     \"best_model\" + \".weights.h5\",\n#     monitor=\"loss\",\n#     save_best_only=True,\n#     save_weights_only=True,\n#     mode=\"min\",\n# )    \n\n# history = model.fit(x=X_train_input,\n#                     y=Y_train_np,\n#                     epochs=25,\n#                     batch_size=4,\n#                     callbacks=[ckptcb],\n#                     verbose=2)\n\n\n\n# Train prepocessed model (head only) with K folds\n\n# X_train_input = np.array(X_train_preprocessed['masked_embeddings'].tolist())\n# Y_train = tf.constant(train[['content', 'wording']].values, dtype=tf.float32)\n\n# # Initialize the KFold object\n# kf = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n\n# # Initialize an empty list to store the validation losses\n# val_losses = []\n# histories = []\n\n# Y_train_np = Y_train.numpy()\n\n# # Iterate over each fold\n# i = 0\n# for train_index, val_index in kf.split(X_train_input, Y_train_np):\n    \n#     print(f\"Fold {i + 1}\")\n#     i += 1\n    \n#     # Split data into training and validation sets\n#     X_train_fold, X_val_fold = X_train_input[train_index], X_train_input[val_index]\n#     Y_train_fold, Y_val_fold = Y_train_np[train_index], Y_train_np[val_index]\n    \n#     # Create and compile your model\n#     model = create_model()\n    \n#     early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    \n#     # Train the model\n    \n#     # Get the validation loss from the last epoch\n#     val_loss = min(history.history['val_loss'])\n#     val_losses.append(val_loss)\n#     histories.append(history)\n#     print()\n\n# # Calculate the mean validation loss\n# mean_val_loss = np.mean(val_losses)\n# print(\"Mean Validation Loss:\", mean_val_loss)\n\n# # Plot training and val losses across folds\n# for i, history in enumerate(histories):\n#     train_losses = history.history['loss']\n#     val_losses = history.history['val_loss']\n#     epochs = range(1, len(train_losses) + 1)\n\n#     # Plotting losses\n#     plt.figure(figsize=(12, 5))\n#     plt.subplot(1, 2, 1)\n#     plt.plot(epochs, train_losses, 'b', label='Training loss')\n#     plt.plot(epochs, val_losses, 'r', label='Validation loss')\n#     plt.title(f'Training and Validation Loss Fold {i + 1}')\n#     plt.xlabel('Epochs')\n#     plt.ylabel('Loss')\n#     plt.legend()\n\n#     plt.tight_layout()\n#     plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # NN with embeddings preprocessed (head only)\n# def create_model_preprocessed():\n#     input_shape = 1024 \n\n#     input_layer = keras.Input(shape=(input_shape, ), dtype='float32')\n\n#     x = layers.LayerNormalization(name='layer_norm1')(input_layer)\n#     x = layers.Reshape((1,input_shape), name='reshape_layer')(x)\n    \n#     x = layers.LSTM(512, return_sequences=True, name='LSTM_layer1', activation='linear')(x)\n#     x = layers.LayerNormalization(name='layer_norm2')(x)\n#     x = layers.Activation(keras.activations.tanh, name='tanh1')(x)\n#     x = layers.LSTM(32, return_sequences=False, name='LSTM_layer2', activation='linear',)(x)\n#     x = layers.LayerNormalization(name='layer_norm3')(x)\n    \n#     x = layers.Activation(keras.activations.tanh, name='tanh2')(x)\n#     x = layers.Dense(16, activation='linear', name='dense_layer')(x)\n#     x = layers.Dropout(0.3, name='dropout_layer')(x)\n\n#     output_layer = layers.Dense(2, activation='linear', name='output_layer')(x)\n    \n#     model = keras.Model(inputs=input_layer, outputs=output_layer)\n\n#     for layer in model.layers:\n#         layer.trainable = True\n        \n    \n#     opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n#     model.compile(loss=mcrmse, optimizer=opt)\n    \n#     return model\n\n# # model_preprocessed = create_model_preprocessed()\n# # model_preprocessed.load_weights(\"/kaggle/input/model-weights-1/best_model.weights.h5\")\n# # model_preprocessed.summary()\n\n\n\n\n# Save file to output folder\n\n# DeBERTa \n# file_path = '/kaggle/input/pooled-deberta-embeddings/pooled_deberta_embeddings.csv'\n\n# # Load masked pooled Deberta embeddings\n# with open('/kaggle/input/masked-pooled-deberta-embeddings/mask_pooled_deberta_embeddings.pkl', 'rb') as f:\n#     loaded_array = pickle.load(f)\n# # Load embeddings\n# X_train_preprocessed = pd.read_csv(file_path)\n\n# X_train_preprocessed['embeddings'] = X_train_preprocessed['embeddings'].apply(lambda x: list(map(float, x.split(','))))\n# X_train_preprocessed['masked_embeddings'] = loaded_array.tolist()\n\n# # Save a csv file\n# df_to_save = df_with_embeddings['pooled_roberta_embedding'].apply(lambda x: ','.join(map(str, x)))\n# df_to_save.to_csv(file_path, index=False)\n\n\n\n# # Train prepocessed model (head only) with K folds\n\n# X_train_input = np.array(X_train_preprocessed['masked_embeddings'].tolist())\n# Y_train = tf.constant(train[['content', 'wording']].values, dtype=tf.float32)\n# Y_train_np = Y_train.numpy()\n\n# # Initialize the KFold object\n# kf = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n# folds = kf.split(X_train_input, Y_train_np)\n\n# # Initialize an empty list to store the validation losses\n# val_losses = []\n# histories = []\n\n# # Iterate over each fold\n# i = 0\n# for train_index, val_index in folds:\n    \n#     print(f\"Fold {i + 1}\")\n#     i += 1\n    \n#     # Split data into training and validation sets\n#     X_train_fold, X_val_fold = X_train_input[train_index], X_train_input[val_index]\n#     Y_train_fold, Y_val_fold = Y_train_np[train_index], Y_train_np[val_index]\n    \n#     # Create and compile your model\n#     model = create_model_preprocessed()\n#     early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n    \n#     # Checkpoint callback\n#     ckptcb = keras.callbacks.ModelCheckpoint(\n#         f\"model_fold_{i}\" + \".weights.h5\",\n#         monitor=\"val_loss\",\n#         save_best_only=True,\n#         save_weights_only=True,\n#         mode=\"min\",\n#     )    \n\n#     # Train the model\n#     history = model.fit(x=X_train_fold,\n#                         y=Y_train_fold,\n#                         epochs=100,\n#                         batch_size=4,\n#                         validation_data=(X_val_fold, Y_val_fold),\n#                         callbacks=[ckptcb, early_stopping],\n#                         verbose=2)\n    \n#     # Get the validation loss from the last epoch\n#     val_loss = min(history.history['val_loss'])\n#     val_losses.append(val_loss)\n#     histories.append(history)\n#     print()\n\n# # Calculate the mean validation loss\n# mean_val_loss = np.mean(val_losses)\n# print(\"Mean Validation Loss:\", mean_val_loss)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Training full model 5 folds\n\n# # Transferring weights \n# def transfer_weights(model_preprocessed, model):\n#     for layer in model.layers:\n#         origin_name = layer.name\n#         new_name = f\"{layer.name}_full\"\n#         layer.name = new_name    # Change the internal name attribute\n\n#         if any(origin_name == preprocessed_layer.name for preprocessed_layer in model_preprocessed.layers):\n#             layer.set_weights(model_preprocessed.get_layer(name=origin_name).get_weights())\n#             layer.trainable = True\n#     return model\n# #     model.summary() \n# #     model_preprocessed.summary()\n\n\n# # Train prepocessed model with K folds\n# tokenized_summaries_np = {\n#     'input_ids': tokenized_summaries['input_ids'].numpy(),\n#     'attention_mask': tokenized_summaries['attention_mask'].numpy(),\n#     'head_mask': head_mask.numpy(),\n# }\n\n# Y_train = tf.constant(train[['content', 'wording']].values, dtype=tf.float32)\n# Y_train_np = Y_train.numpy()\n\n# # Initialize the KFold object\n# kf = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n# folds = kf.split(X_train_input, Y_train_np)\n\n# # Initialize an empty list to store the validation losses\n# val_losses = []\n# histories = []\n\n# # Iterate over each fold\n# i = 0\n# for train_index, val_index in folds:\n            \n#     print(f\"Fold {i + 1}\")\n#     i += 1\n    \n#     # Split data into training and validation sets\n#     train_input_ids_fold, train_attention_mask_fold, train_head_mask_fold = tokenized_summaries_np['input_ids'][train_index], tokenized_summaries_np['attention_mask'][train_index], tokenized_summaries_np['head_mask'][train_index]\n#     val_input_ids_fold, val_attention_mask_fold, val_head_mask_fold = tokenized_summaries_np['input_ids'][val_index], tokenized_summaries_np['attention_mask'][val_index], tokenized_summaries_np['head_mask'][val_index]\n#     Y_train_fold, Y_val_fold = Y_train_np[train_index], Y_train_np[val_index]\n    \n#     # Create and compile your model\n#     model_preprocessed = create_model_preprocessed()\n#     model_preprocessed.load_weights(f'/kaggle/input/head-model-weights-folds/head_model_weights/model_fold_{i}.weights.h5')\n#     model, _ = create_model()\n#     model = transfer_weights(model_preprocessed, model)\n    \n#     early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n#     # Checkpoint callback\n#     ckptcb = keras.callbacks.ModelCheckpoint(\n#         f\"full_model_fold_{i}\" + \".weights.h5\",\n#         monitor=\"val_loss\",\n#         save_best_only=True,\n#         save_weights_only=True,\n#         mode=\"min\",\n#     )    \n\n#     # Train the model\n#     history = model.fit(x=[train_input_ids_fold, train_attention_mask_fold, train_head_mask_fold],\n#                         y=Y_train_fold,\n#                         epochs=100,\n#                         batch_size=4,\n#                         validation_data=([val_input_ids_fold, val_attention_mask_fold, val_head_mask_fold], Y_val_fold),\n#                         callbacks=[ckptcb, early_stopping],\n#                         verbose=1)\n    \n#     # Get the validation loss from the last epoch\n#     val_loss = min(history.history['val_loss'])\n#     val_losses.append(val_loss)\n#     histories.append(history)\n#     print()\n\n# # Calculate the mean validation loss\n# mean_val_loss = np.mean(val_losses)\n# print(\"Mean Validation Loss:\", mean_val_loss)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train full model no folds all data\n\n\n# Y_train = tf.constant(train[['content', 'wording']].values, dtype=tf.float32)\n# Y_train_np = Y_train.numpy()\n\n# Checkpoint callback\n# ckptcb = keras.callbacks.ModelCheckpoint(\n#     \"best_model\" + \".weights.h5\",\n#     monitor=\"loss\",\n#     save_best_only=True,\n#     save_weights_only=True,\n#     mode=\"min\",\n# )    \n\n# history = model.fit(x=[tokenized_summaries['input_ids'], tokenized_summaries['attention_mask'], head_mask],\n#                     y=Y_train_np,\n#                     epochs=6,\n#                     batch_size=4,\n#                     callbacks=[ckptcb],\n#                     verbose=1)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model with augmentation folds\n\n\n# tokenized_summaries_aug = tokenizer.batch_encode_plus(augmented_labeled_data['input'].tolist(),\n#                                               add_special_tokens=True,\n#                                               truncation=True,\n#                                               padding='max_length',\n#                                               return_tensors='tf',\n#                                               max_length=MAX_SUMMARY_LENGTH,\n#                                               return_attention_mask = True)\n# del tokenized_summaries_aug['token_type_ids']\n\n# # Create head mask that excludes anything but sep + prefix2 + train['text']\n# head_mask_aug = np.zeros(tokenized_summaries_aug['input_ids'].shape)\n# for i, summary in enumerate(tokenized_summaries_aug['input_ids'].numpy()):\n#     use_full = False\n#     for j, token in enumerate(summary):\n#         if token == tokenizer.sep_token_id:\n#             use_full = not use_full\n#         head_mask_aug[i][j] = (1 if use_full else 0) \n# head_mask_aug = tf.constant(head_mask_aug)\n\n# # Train prepocessed model with K folds\n# tokenized_summaries_np = {\n#     'input_ids': tokenized_summaries_aug['input_ids'].numpy(),\n#     'attention_mask': tokenized_summaries_aug['attention_mask'].numpy(),\n#     'head_mask': head_mask_aug.numpy(),\n# }\n\n# Y_train = tf.constant(augmented_labeled_data[['content', 'wording']].values, dtype=tf.float32)\n# Y_train_np = Y_train.numpy()\n\n# # Initialize the KFold object\n# kf = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n# folds = kf.split(tokenized_summaries_np['input_ids'], Y_train_np)\n\n# # Initialize an empty list to store the validation losses\n# val_losses = []\n# histories = []\n\n# # Iterate over each fold\n# i = 0\n# for train_index, val_index in folds:\n            \n#     print(f\"Fold {i + 1}\")\n#     i += 1\n    \n#     # Split data into training and validation sets\n#     train_input_ids_fold, train_attention_mask_fold, train_head_mask_fold = tokenized_summaries_np['input_ids'][train_index], tokenized_summaries_np['attention_mask'][train_index], tokenized_summaries_np['head_mask'][train_index]\n#     val_input_ids_fold, val_attention_mask_fold, val_head_mask_fold = tokenized_summaries_np['input_ids'][val_index], tokenized_summaries_np['attention_mask'][val_index], tokenized_summaries_np['head_mask'][val_index]\n#     Y_train_fold, Y_val_fold = Y_train_np[train_index], Y_train_np[val_index]\n    \n#     # Create and compile your model\n#     model, _ = create_model()\n#     model.load_weights(f'/kaggle/input/no-aug-model-folds-weights/no-aug-model-folds-weights/full_model_fold_{i}.weights.h5')\n#     early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n    \n#     # Checkpoint callback\n#     ckptcb = keras.callbacks.ModelCheckpoint(\n#         f\"aug_full_model_fold_{i}\" + \".weights.h5\",\n#         monitor=\"val_loss\",\n#         save_best_only=True,\n#         save_weights_only=True,\n#         mode=\"min\",\n#     )    \n\n#     # Train the model\n#     history = model.fit(x=[train_input_ids_fold, train_attention_mask_fold, train_head_mask_fold],\n#                         y=Y_train_fold,\n#                         epochs=100,\n#                         batch_size=4,\n#                         validation_data=([val_input_ids_fold, val_attention_mask_fold, val_head_mask_fold], Y_val_fold),\n#                         callbacks=[ckptcb, early_stopping],\n#                         verbose=1)\n    \n#     # Get the validation loss from the last epoch\n#     val_loss = min(history.history['val_loss'])\n#     val_losses.append(val_loss)\n#     histories.append(history)\n    \n#     del model \n#     gc.collect()\n#     print()\n\n# # Calculate the mean validation loss\n# mean_val_loss = np.mean(val_losses)\n# print(\"Mean Validation Loss:\", mean_val_loss)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting Meta Psuedo Labels\n\n# augmented_data[\"text\"] = augmented_data[\"text\"].apply(lambda x: spell(x))\n# augmented_data['input'] = prefix1 + augmented_data['prompt_question'] + sep + prefix2 + augmented_data['text']\n# augmented_data['input'][0]\n\n# tokenized_summaries_aug = tokenizer.batch_encode_plus(augmented_data['input'].tolist(),\n#                                               add_special_tokens=True,\n#                                               truncation=True,\n#                                               padding='max_length',\n#                                               return_tensors='tf',\n#                                               max_length=MAX_SUMMARY_LENGTH,\n#                                               return_attention_mask = True)\n# del tokenized_summaries_aug['token_type_ids']\n\n# # Create head mask that excludes anything but sep + prefix2 + train['text']\n# head_mask_aug = np.zeros(tokenized_summaries_aug['input_ids'].shape)\n# for i, summary in enumerate(tokenized_summaries_aug['input_ids'].numpy()):\n#     use_full = False\n#     for j, token in enumerate(summary):\n#         if token == tokenizer.sep_token_id:\n#             use_full = not use_full\n#         head_mask_aug[i][j] = (1 if use_full else 0) \n# head_mask_aug = tf.constant(head_mask_aug)\n\n# aug_input = {\n#     'input_ids': tokenized_summaries_aug['input_ids'],\n#     'attention_mask': tokenized_summaries_aug['attention_mask'],\n#     'head_mask': head_mask_aug,\n#     'student_id': augmented_data['student_id']\n# }\n\n# # ids, contents, wordings = generate_predictions(model, aug_input) # uncomment if not using folds\n\n# preds = []\n# for i in range(1,6):\n#     model, _ = create_model()\n#     model.load_weights(f'/kaggle/input/no-aug-model-folds-weights/no-aug-model-folds-weights/full_model_fold_{i}.weights.h5')\n    \n#     ids, contents, wordings = generate_predictions(model, aug_input)\n#     preds.append([ids, contents, wordings])\n#     del model\n#     gc.collect()\n    \n# # Calculate mean predictions\n# contents = np.stack([pred[1] for pred in preds]).mean(axis=0)\n# wordings = np.stack([pred[2] for pred in preds]).mean(axis=0)\n\n# augmented_data['content'] = contents\n# augmented_data['wording'] = wordings\n# augmented_data.to_csv(\"augmented_labeled_data.csv\")\n\n# augmented_labeled_data = pd.read_csv('/kaggle/input/augmented-labeled-data-folds/augmented_labeled_data.csv')\n# augmented_labeled_data['input'] = prefix1 + augmented_labeled_data['prompt_question'] + sep + prefix2 + augmented_labeled_data['text']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Pre-processing from winner notebook\n\n# DATA_DIR = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\n\n# prompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n# prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\n# summaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\n# summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\n# sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")\n\n# # From winner\n# class Preprocessor:\n#     def __init__(self, \n#                 model_name: str,\n#                 ) -> None:\n#         self.STOP_WORDS = set(stopwords.words('english'))\n        \n#         self.tokenizer = tokenizer\n#         self.spacy_ner_model = spacy.load('en_core_web_sm',)\n#         self.speller = SpellChecker() #Speller(lang='en')\n        \n#     def count_text_length(self, df: pd.DataFrame, col:str) -> pd.Series:\n#         \"\"\" text length \"\"\"\n#         tokenizer=self.tokenizer\n#         return df[col].progress_apply(lambda x: len(tokenizer.encode(x)))\n\n#     def word_overlap_count(self, row):\n#         \"\"\" intersection(prompt_text, text) \"\"\"        \n#         def check_is_stop_word(word):\n#             return word in self.STOP_WORDS\n        \n#         prompt_words = row['prompt_tokens']\n#         summary_words = row['summary_tokens']\n#         if self.STOP_WORDS:\n#             prompt_words = list(filter(check_is_stop_word, prompt_words))\n#             summary_words = list(filter(check_is_stop_word, summary_words))\n#         return len(set(prompt_words).intersection(set(summary_words)))\n            \n#     def ngrams(self, token, n):\n#         # Use the zip function to help us generate n-grams\n#         # Concatentate the tokens into ngrams and return\n#         ngrams = zip(*[token[i:] for i in range(n)])\n#         return [\" \".join(ngram) for ngram in ngrams]\n\n#     def ngram_co_occurrence(self, row, n: int):\n#         # Tokenize the original text and summary into words\n#         original_tokens = row['prompt_tokens']\n#         summary_tokens = row['summary_tokens']\n\n#         # Generate n-grams for the original text and summary\n#         original_ngrams = set(self.ngrams(original_tokens, n))\n#         summary_ngrams = set(self.ngrams(summary_tokens, n))\n\n#         # Calculate the number of common n-grams\n#         common_ngrams = original_ngrams.intersection(summary_ngrams)\n\n#         # # Optionally, you can get the frequency of common n-grams for a more nuanced analysis\n#         # original_ngram_freq = Counter(ngrams(original_words, n))\n#         # summary_ngram_freq = Counter(ngrams(summary_words, n))\n#         # common_ngram_freq = {ngram: min(original_ngram_freq[ngram], summary_ngram_freq[ngram]) for ngram in common_ngrams}\n\n#         return len(common_ngrams)\n    \n#     def ner_overlap_count(self, row, mode:str):\n#         model = self.spacy_ner_model\n#         def clean_ners(ner_list):\n#             return set([(ner[0].lower(), ner[1]) for ner in ner_list])\n#         prompt = model(row['prompt_text'])\n#         summary = model(row['text'])\n\n#         if \"spacy\" in str(model):\n#             prompt_ner = set([(token.text, token.label_) for token in prompt.ents])\n#             summary_ner = set([(token.text, token.label_) for token in summary.ents])\n#         elif \"stanza\" in str(model):\n#             prompt_ner = set([(token.text, token.type) for token in prompt.ents])\n#             summary_ner = set([(token.text, token.type) for token in summary.ents])\n#         else:\n#             raise Exception(\"Model not supported\")\n\n#         prompt_ner = clean_ners(prompt_ner)\n#         summary_ner = clean_ners(summary_ner)\n\n#         intersecting_ners = prompt_ner.intersection(summary_ner)\n        \n#         ner_dict = dict(Counter([ner[1] for ner in intersecting_ners]))\n        \n#         if mode == \"train\":\n#             return ner_dict\n#         elif mode == \"test\":\n#             return {key: ner_dict.get(key) for key in self.ner_keys}\n\n    \n#     def quotes_count(self, row):\n#         summary = row['text']\n#         text = row['prompt_text']\n#         quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n#         if len(quotes_from_summary)>0:\n#             return [quote in text for quote in quotes_from_summary].count(True)\n#         else:\n#             return 0\n\n#     def spelling(self, text):\n        \n#         wordlist=text.split()\n#         amount_miss = len(list(self.speller.unknown(wordlist)))\n\n#         return amount_miss\n    \n#     def run(self, \n#             prompts: pd.DataFrame,\n#             summaries:pd.DataFrame,\n#             mode:str\n#         ) -> pd.DataFrame:\n        \n#         # before merge preprocess\n#         prompts[\"prompt_length\"] = prompts[\"prompt_text\"].apply(\n#             lambda x: len(self.tokenizer.encode(x))\n#         )\n#         prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].apply(\n#             lambda x: self.tokenizer.convert_ids_to_tokens(\n#                 self.tokenizer.encode(x), \n#                 skip_special_tokens=True\n#             )\n#         )\n\n#         summaries[\"summary_length\"] = summaries[\"text\"].apply(\n#             lambda x: len(self.tokenizer.encode(x))\n#         )\n#         summaries[\"summary_tokens\"] = summaries[\"text\"].apply(\n#             lambda x: self.tokenizer.convert_ids_to_tokens(\n#                 self.tokenizer.encode(x), \n#                 skip_special_tokens=True\n#             )\n\n#         )\n#         summaries[\"splling_err_num\"] = summaries[\"text\"].progress_apply(self.spelling)\n\n#         # merge prompts and summaries\n#         input_df = summaries.merge(prompts, how=\"left\", on=\"prompt_id\")\n\n#         # after merge preprocess\n#         input_df['length_ratio'] = input_df['summary_length'] / input_df['prompt_length']\n        \n#         input_df['word_overlap_count'] = input_df.progress_apply(self.word_overlap_count, axis=1)\n#         input_df['bigram_overlap_count'] = input_df.progress_apply(\n#             self.ngram_co_occurrence,args=(2,), axis=1 \n#         )\n#         input_df['trigram_overlap_count'] = input_df.progress_apply(\n#             self.ngram_co_occurrence, args=(3,), axis=1\n#         )\n        \n#         # Crate dataframe with count of each category NERs overlap for all the summaries\n#         # Because it spends too much time for this feature, I don't use this time.\n# #         ners_count_df  = input_df.progress_apply(\n# #             lambda row: pd.Series(self.ner_overlap_count(row, mode=mode), dtype='float64'), axis=1\n# #         ).fillna(0)\n# #         self.ner_keys = ners_count_df.columns\n# #         ners_count_df['sum'] = ners_count_df.sum(axis=1)\n# #         ners_count_df.columns = ['NER_' + col for col in ners_count_df.columns]\n# #         # join ner count dataframe with train dataframe\n# #         input_df = pd.concat([input_df, ners_count_df], axis=1)\n        \n#         input_df['quotes_count'] = input_df.progress_apply(self.quotes_count, axis=1)\n        \n#         return input_df.drop(columns=[\"summary_tokens\", \"prompt_tokens\"])\n    \n# preprocessor = Preprocessor(model_name=model_path)\n# train = preprocessor.run(prompts_train, summaries_train, mode=\"train\")\n# test = preprocessor.run(prompts_test, summaries_test, mode=\"test\")\n# test['length'] = test['summary_length'] + test['prompt_length']\n# test = test.sort_values('length', ascending=True).reset_index(drop=True)\n# test.head()\n\n# # 'input' column is not in this list\n# features = train.drop(columns=['student_id', 'prompt_id','text', 'content', 'wording', 'prompt_question', 'prompt_title', 'prompt_text'])\n# features","metadata":{"execution":{"iopub.status.busy":"2024-06-11T02:01:02.853645Z","iopub.execute_input":"2024-06-11T02:01:02.853972Z","iopub.status.idle":"2024-06-11T02:01:38.168990Z","shell.execute_reply.started":"2024-06-11T02:01:02.853940Z","shell.execute_reply":"2024-06-11T02:01:38.167748Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"100%|██████████| 7165/7165 [00:01<00:00, 3912.58it/s]\n100%|██████████| 7165/7165 [00:01<00:00, 6347.96it/s]\n100%|██████████| 7165/7165 [00:02<00:00, 2715.76it/s]\n100%|██████████| 7165/7165 [00:03<00:00, 2344.82it/s]\n100%|██████████| 7165/7165 [00:00<00:00, 36042.36it/s]\n100%|██████████| 4/4 [00:00<00:00, 9451.95it/s]\n100%|██████████| 4/4 [00:00<00:00, 2761.68it/s]\n100%|██████████| 4/4 [00:00<00:00, 3638.52it/s]\n100%|██████████| 4/4 [00:00<00:00, 3247.62it/s]\n100%|██████████| 4/4 [00:00<00:00, 3695.42it/s]\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"      summary_length  splling_err_num  prompt_length  length_ratio  \\\n0                 69                5            671      0.102832   \n1                 56                2           1137      0.049252   \n2                285               32            651      0.437788   \n3                 43                5            651      0.066052   \n4                253               29            671      0.377049   \n...              ...              ...            ...           ...   \n7160              78                9           1137      0.068602   \n7161              56                7            651      0.086022   \n7162              66               10            651      0.101382   \n7163              66                5            721      0.091540   \n7164             118               10           1137      0.103782   \n\n      word_overlap_count  bigram_overlap_count  trigram_overlap_count  \\\n0                      0                     5                      0   \n1                      0                    22                     10   \n2                      1                    56                     26   \n3                      1                    10                      6   \n4                      1                    27                      5   \n...                  ...                   ...                    ...   \n7160                   0                    40                     34   \n7161                   1                     6                      1   \n7162                   1                     7                      1   \n7163                   0                     4                      0   \n7164                   1                    30                     11   \n\n      quotes_count  \n0                0  \n1                0  \n2                2  \n3                0  \n4                4  \n...            ...  \n7160             1  \n7161             0  \n7162             0  \n7163             0  \n7164             2  \n\n[7165 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>summary_length</th>\n      <th>splling_err_num</th>\n      <th>prompt_length</th>\n      <th>length_ratio</th>\n      <th>word_overlap_count</th>\n      <th>bigram_overlap_count</th>\n      <th>trigram_overlap_count</th>\n      <th>quotes_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>69</td>\n      <td>5</td>\n      <td>671</td>\n      <td>0.102832</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>56</td>\n      <td>2</td>\n      <td>1137</td>\n      <td>0.049252</td>\n      <td>0</td>\n      <td>22</td>\n      <td>10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>285</td>\n      <td>32</td>\n      <td>651</td>\n      <td>0.437788</td>\n      <td>1</td>\n      <td>56</td>\n      <td>26</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>43</td>\n      <td>5</td>\n      <td>651</td>\n      <td>0.066052</td>\n      <td>1</td>\n      <td>10</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>253</td>\n      <td>29</td>\n      <td>671</td>\n      <td>0.377049</td>\n      <td>1</td>\n      <td>27</td>\n      <td>5</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7160</th>\n      <td>78</td>\n      <td>9</td>\n      <td>1137</td>\n      <td>0.068602</td>\n      <td>0</td>\n      <td>40</td>\n      <td>34</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7161</th>\n      <td>56</td>\n      <td>7</td>\n      <td>651</td>\n      <td>0.086022</td>\n      <td>1</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7162</th>\n      <td>66</td>\n      <td>10</td>\n      <td>651</td>\n      <td>0.101382</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7163</th>\n      <td>66</td>\n      <td>5</td>\n      <td>721</td>\n      <td>0.091540</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7164</th>\n      <td>118</td>\n      <td>10</td>\n      <td>1137</td>\n      <td>0.103782</td>\n      <td>1</td>\n      <td>30</td>\n      <td>11</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>7165 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# # NN full model\n# def create_model(input_shape=(1575,), embeddings_len=1024):\n#     pre_trained_model_instance = PreTrainedModel(pre_trained_model, name=\"deberta_layer\")\n\n#     # Input layers\n#     input_ids = keras.Input(shape=input_shape, dtype='int32', name='input_ids')\n#     attention_mask = keras.Input(shape=input_shape, dtype='int32', name='attention_mask')\n#     head_mask = keras.Input(shape=input_shape, dtype='float32', name='head_mask')\n    \n#     # Create embeddings and mask pool them\n#     deberta = pre_trained_model_instance(input_ids, attention_mask)\n#     h_mask = layers.Lambda(lambda x: tf.expand_dims(tf.cast(x, dtype=tf.float32), axis=-1), name='expand_dims')(head_mask)\n#     masked_outputs = layers.Lambda(lambda x: tf.multiply(x[0], x[1]), output_shape=(1575, 1024,), name='masked_embeddings')([deberta, h_mask])\n#     avg_pooling = layers.GlobalAveragePooling1D()(masked_outputs)\n    \n#     # Head of NN\n#     x = layers.LayerNormalization(name='layer_norm1')(avg_pooling)\n#     x = layers.Reshape((1, embeddings_len), name='reshape_layer')(x)\n    \n#     x = layers.LSTM(512, return_sequences=True, name='LSTM_layer1', activation='linear')(x)\n#     x = layers.LayerNormalization(name='layer_norm2')(x)\n#     x = layers.Activation(keras.activations.tanh, name='tanh1')(x)\n#     x = layers.LSTM(32, return_sequences=False, name='LSTM_layer2', activation='linear',)(x)\n#     x = layers.LayerNormalization(name='layer_norm3')(x)\n#     x = layers.Activation(keras.activations.tanh, name='tanh2')(x)\n    \n#     x = layers.Dense(16, activation='linear', name='dense_layer')(x)\n#     x = layers.Dropout(0.3, name='dropout_layer')(x)\n#     output_layer = layers.Dense(2, activation='linear', name='output_layer')(x)\n    \n#     model = keras.Model(inputs=[input_ids, attention_mask, head_mask], outputs=output_layer)\n\n#     for layer in model.layers:\n#         layer.trainable = True\n    \n#     opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n#     model.compile(loss=mcrmse, optimizer=opt)\n    \n#     return model, pre_trained_model_instance\n\n# # model, deberta_model = create_model()\n# # model.summary()\n\n# # model.load_weights(\"/kaggle/input/no-aug-model-weights/no_augmentation_model.weights.h5\")\n# # deberta_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sep = f\" {tokenizer.sep_token} \"\n# prefix1 = \"Think through this step by step: \"\n# prefix2 = \"Pay attention to the content and wording: \"\n# MAX_SUMMARY_LENGTH = 1500 + len(prefix1) + len(prefix2)\n\n# # Tokenization + Head Mask creation\n# def preprocess_summary(data, label=None):\n    \n#     print(data.shape)\n#     summary, prompt_question = data\n#     summary = summary.numpy().decode()\n#     prompt_question= prompt_question.numpy().decode()\n    \n#     summary = spell(summary)\n#     summary = prefix1 + prompt_question + sep + prefix2 + summary\n#     # Tokenize the summary\n#     tokenized = tokenizer(summary,\n#                           truncation=True,\n#                           padding='max_length',\n#                           return_tensors='tf',\n#                           max_length=MAX_SUMMARY_LENGTH,\n#                           return_attention_mask=True)\n    \n#     input_ids = tokenized['input_ids']\n#     attention_mask = tokenized['attention_mask']\n\n#     # Create head mask\n#     head_mask = np.zeros_like(input_ids)\n#     use_full = False\n#     for j, token in enumerate(input_ids[0]):\n#         if token == tokenizer.sep_token_id:\n#             use_full = not use_full\n#         head_mask[0][j] = 1 if use_full else 0\n#     head_mask = tf.constant(head_mask, dtype=tf.int32)\n      \n#     if label is None:\n#         return input_ids[0], attention_mask[0], head_mask[0]\n#     else:\n#         return (input_ids[0], attention_mask[0], head_mask[0]), label\n\n# # wrapper function to work with keras dataloader\n# def preprocess_summary_wrapper(data, label=None):\n#     if label is None:\n#         output = tf.py_function(preprocess_summary, [data], [tf.int32])\n#     else:\n#         output = tf.py_function(preprocess_summary, [data, label], [tf.int32, tf.float64])\n#         output[1].set_shape([2])\n        \n#     output[0][0].set_shape([MAX_SUMMARY_LENGTH])\n#     output[0][1].set_shape([MAX_SUMMARY_LENGTH])\n#     output[0][2].set_shape([MAX_SUMMARY_LENGTH])\n#     output[0].set_shape([3])\n#     return output[0], output[1]\n\n# # split in NN to inout ids, attention mask and head mask\n# def split_input(inputs):\n#     split_tensors = tf.split(inputs, num_or_size_splits=3, axis=1)\n#     # Remove the redundant dimension\n#     input_ids = tf.cast(tf.squeeze(split_tensors[0], axis=1), tf.int32)\n#     attention_mask = tf.cast(tf.squeeze(split_tensors[1], axis=1), tf.int32)\n#     head_mask = tf.cast(tf.squeeze(split_tensors[2], axis=1), tf.float32)\n#     return input_ids, attention_mask, head_mask\n\n# Data Loader\n\n# def build_dataset(data, labels=None, batch_size=4, cache=True, shuffle=True):\n#     AUTOTUNE = tf.data.AUTOTUNE\n\n#     dataset = tf.data.Dataset.from_tensor_slices(data) if labels is None else tf.data.Dataset.from_tensor_slices((data, labels))    \n#     dataset = dataset.cache() if cache else dataset\n    \n#     # tokenize + preprocess summaries\n#     if labels is None:\n#         dataset = dataset.map(lambda x: preprocess_summary_wrapper(x), num_parallel_calls=2)\n#     else:\n#         dataset = dataset.map(lambda x, y: preprocess_summary_wrapper(x, y), num_parallel_calls=2)\n        \n#     dataset = dataset.shuffle(buffer_size=len(data), seed=random_seed) if shuffle else dataset\n        \n#     # CAN ADD AUGMENTATION PREPROCESS HERE\n    \n#     # Batch and prefetch the dataset\n#     dataset = dataset.batch(batch_size, drop_remainder=True)\n#     dataset = dataset.prefetch(AUTOTUNE)\n    \n#     return dataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    # Head of NN\n#     x = layers.LayerNormalization(name='layer_norm1')(avg_pooling)\n#     x = layers.Reshape((1, embeddings_len), name='reshape_layer')(x)\n    \n#     x = layers.LSTM(64, return_sequences=True, name='LSTM_layer1', activation='linear')(x)\n#     x = layers.LayerNormalization(name='layer_norm2')(x)\n#     x = layers.Activation(keras.activations.tanh, name='tanh1')(x)\n#     x = layers.LSTM(16, return_sequences=False, name='LSTM_layer2', activation='linear',)(x)\n#     x = layers.LayerNormalization(name='layer_norm3')(x)\n#     x = layers.Activation(keras.activations.tanh, name='tanh2')(x)\n#     x = layers.Dropout(0.3, name='dropout_layer')(x)\n    \n#     x = layers.Dense(16, activation='linear', name='dense_layer')(x)","metadata":{},"execution_count":null,"outputs":[]}]}