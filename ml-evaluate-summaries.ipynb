{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":53482,"databundleVersionId":6201832,"sourceType":"competition"},{"sourceId":2977194,"sourceType":"datasetVersion","datasetId":1825054},{"sourceId":8558953,"sourceType":"datasetVersion","datasetId":5115575},{"sourceId":8838741,"sourceType":"datasetVersion","datasetId":5307916},{"sourceId":8146152,"sourceType":"datasetVersion","datasetId":4817190}],"dockerImageVersionId":30665,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":109.119668,"end_time":"2024-05-16T15:40:29.014408","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-05-16T15:38:39.894740","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"059a11eda62448da981f7b2667b94637":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d4e90cc3beb40b890ffd3978dfb22d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"150f7c2a80124dad8408945c7c4a0fce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15104f9159d1410eb85b6379bc0756c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff9e6813dd3d499f8c44902f3806b49c","IPY_MODEL_588ef8f9110e4ba8897785a7816b52a6","IPY_MODEL_afa499e764d4423fbc616d6a8de52fd0"],"layout":"IPY_MODEL_deefef886f9c43cf88f6f162100f2e3e"}},"1982a9459b644ddf93b0670b17ed6427":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b2c1961d94c4a07b162c8e1f1f4ea8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e281edfb4944800b70ca3e7b078cd13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f7d29516b7a46dcb0fa01415173e1df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"25126573d458497987981721450a08ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c8166010478471ebcfeaff488254cc3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ed7fd040a494b91bcb6b11bf17446a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c55a6f3b2d6453d92734e1c2c6ccf3d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f8ee3fcf5ed47f08eb3eeaff0647d5e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42cdc6d0d53e4ab298128b8581bf4c3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c8166010478471ebcfeaff488254cc3","placeholder":"​","style":"IPY_MODEL_059a11eda62448da981f7b2667b94637","value":" 2.46M/2.46M [00:00&lt;00:00, 3.68MB/s]"}},"464d8379cbd842b6b0c919aa12c237ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1982a9459b644ddf93b0670b17ed6427","placeholder":"​","style":"IPY_MODEL_a0ed8c5740e846b7912490fe3541991c","value":"spm.model: 100%"}},"57d07143c3b54fb2baad23f96e0874aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"588ef8f9110e4ba8897785a7816b52a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d4e90cc3beb40b890ffd3978dfb22d8","max":1736592160,"min":0,"orientation":"horizontal","style":"IPY_MODEL_150f7c2a80124dad8408945c7c4a0fce","value":1736592160}},"640eb7d806d7408ba3ba560fa99b9142":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73ed4c4fc9104779b8fdb3fc52e64f4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa4f2028d4be4adfb1389b240b2c7ee0","placeholder":"​","style":"IPY_MODEL_cd53dfa32e15440aadac97ed88dbec02","value":" 580/580 [00:00&lt;00:00, 52.0kB/s]"}},"76c12b9e7502419da6c5d8afae0b45ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eb63820b62d49ea9bc8059798aabfb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_464d8379cbd842b6b0c919aa12c237ad","IPY_MODEL_d006714a85f746a2a1485b6e1faf7003","IPY_MODEL_42cdc6d0d53e4ab298128b8581bf4c3a"],"layout":"IPY_MODEL_25126573d458497987981721450a08ae"}},"999bd4cca8c94c3a8c59da5cb58d8c2e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ae4657f98844aa686e0a73f6bb69972":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_efc7d8e9f3cc457f93faf7367ab86cd3","IPY_MODEL_f37802e035ff44d181776f86eabe948d","IPY_MODEL_a915e75f5ed847a7b44823aadb68b8e3"],"layout":"IPY_MODEL_9cc123d4a6da4ac9bf37029593171ca6"}},"9cc123d4a6da4ac9bf37029593171ca6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d8022fde15349cf92f52a24eac326ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0ed8c5740e846b7912490fe3541991c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a915e75f5ed847a7b44823aadb68b8e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_640eb7d806d7408ba3ba560fa99b9142","placeholder":"​","style":"IPY_MODEL_1e281edfb4944800b70ca3e7b078cd13","value":" 52.0/52.0 [00:00&lt;00:00, 4.37kB/s]"}},"aa1ceb8e11cc412ea3062b14dcb51319":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3852559827e4748844d3b2927447926","max":580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b2c1961d94c4a07b162c8e1f1f4ea8f","value":580}},"aa4f2028d4be4adfb1389b240b2c7ee0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad398d8a95ab459abdfa03879da117ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afa499e764d4423fbc616d6a8de52fd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8b1ba7cf2354528ab658faf56c8985f","placeholder":"​","style":"IPY_MODEL_c4ef64c1429c4d049c4b952e1906bf5e","value":" 1.74G/1.74G [00:41&lt;00:00, 42.6MB/s]"}},"b3852559827e4748844d3b2927447926":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba8f192523cf4f3d81fe72f0c6b16060":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4ef64c1429c4d049c4b952e1906bf5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cae13970055a44a09fbe31e19911087a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76c12b9e7502419da6c5d8afae0b45ab","placeholder":"​","style":"IPY_MODEL_2ed7fd040a494b91bcb6b11bf17446a7","value":"config.json: 100%"}},"cd53dfa32e15440aadac97ed88dbec02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cde68addf7004559a03c89e3c5cd5070":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d006714a85f746a2a1485b6e1faf7003":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba8f192523cf4f3d81fe72f0c6b16060","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57d07143c3b54fb2baad23f96e0874aa","value":2464616}},"deefef886f9c43cf88f6f162100f2e3e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8b1ba7cf2354528ab658faf56c8985f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efc7d8e9f3cc457f93faf7367ab86cd3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f8ee3fcf5ed47f08eb3eeaff0647d5e","placeholder":"​","style":"IPY_MODEL_cde68addf7004559a03c89e3c5cd5070","value":"tokenizer_config.json: 100%"}},"f37802e035ff44d181776f86eabe948d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c55a6f3b2d6453d92734e1c2c6ccf3d","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f7d29516b7a46dcb0fa01415173e1df","value":52}},"f37f807ded5e4af5a607d3a76b4de99f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cae13970055a44a09fbe31e19911087a","IPY_MODEL_aa1ceb8e11cc412ea3062b14dcb51319","IPY_MODEL_73ed4c4fc9104779b8fdb3fc52e64f4e"],"layout":"IPY_MODEL_9d8022fde15349cf92f52a24eac326ed"}},"ff9e6813dd3d499f8c44902f3806b49c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_999bd4cca8c94c3a8c59da5cb58d8c2e","placeholder":"​","style":"IPY_MODEL_ad398d8a95ab459abdfa03879da117ba","value":"tf_model.h5: 100%"}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"# General imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\nimport warnings\nimport logging\nimport random\nimport shutil\nimport os\nimport gc\nimport math\n\n# Neural network imports\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import layers\nfrom keras.callbacks import EarlyStopping\nfrom transformers import TFAutoModel, AutoTokenizer\nfrom sklearn.model_selection import GroupKFold\n!pip install /kaggle/input/autocorrect/autocorrect-2.6.1.tar\nfrom autocorrect import Speller\n\n# Disabling unnecceseray warnings\nwarnings.simplefilter(\"ignore\")\nlogging.disable(logging.ERROR)\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n# Initializing autocorrect and using mixed percision\nspell = Speller(lang='en', fast=True)\nkeras.mixed_precision.set_global_policy(\"mixed_float16\")","metadata":{"papermill":{"duration":33.079441,"end_time":"2024-05-16T15:39:15.664457","exception":false,"start_time":"2024-05-16T15:38:42.585016","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-07-02T20:31:54.135472Z","iopub.execute_input":"2024-07-02T20:31:54.136336Z","iopub.status.idle":"2024-07-02T20:32:30.158493Z","shell.execute_reply.started":"2024-07-02T20:31:54.136298Z","shell.execute_reply":"2024-07-02T20:32:30.157649Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/autocorrect/autocorrect-2.6.1.tar\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: autocorrect\n  Building wheel for autocorrect (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622364 sha256=72f35e33241acf1808e1e6d9f7dc2c076302d79f09b647c2db1a787032e38d0a\n  Stored in directory: /root/.cache/pip/wheels/db/69/42/0fb0421d2fe70d195a04665edc760cfe5fd341d7bb8d8e0aaa\nSuccessfully built autocorrect\nInstalling collected packages: autocorrect\n  Attempting uninstall: autocorrect\n    Found existing installation: autocorrect 2.6.1\n    Uninstalling autocorrect-2.6.1:\n      Successfully uninstalled autocorrect-2.6.1\nSuccessfully installed autocorrect-2.6.1\n","output_type":"stream"}]},{"cell_type":"code","source":"class CFG:\n    epochs=9\n    pre_trained_model_name=\"/kaggle/input/deberta-v3-large/deberta_v3_large/\"\n    final_model_path = f'full_model_scaled-{epochs}.keras'\n    learning_rate=0.00015\n    weight_decay=1e-4\n    warmup_steps=100\n    hidden_dropout_prob=0.\n    attention_probs_dropout_prob=0.\n    n_splits=4\n    batch_size=4\n    random_seed=42\n    max_length=1575\n    embeddings_len=1024","metadata":{"execution":{"iopub.status.busy":"2024-07-02T20:33:56.900684Z","iopub.execute_input":"2024-07-02T20:33:56.901407Z","iopub.status.idle":"2024-07-02T20:33:56.907656Z","shell.execute_reply.started":"2024-07-02T20:33:56.901371Z","shell.execute_reply":"2024-07-02T20:33:56.906814Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def seed_everything(random_seed):\n    \n    os.environ['PYTHONHASHSEED'] = str(random_seed)\n    np.random.seed(random_seed)\n    tf.random.set_seed(random_seed)\n    random.seed(random_seed)\n    keras.utils.set_random_seed(random_seed)\n    \nseed_everything(random_seed=CFG.random_seed)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T20:34:01.193233Z","iopub.execute_input":"2024-07-02T20:34:01.193508Z","iopub.status.idle":"2024-07-02T20:34:01.200111Z","shell.execute_reply.started":"2024-07-02T20:34:01.193479Z","shell.execute_reply":"2024-07-02T20:34:01.199175Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def move_to_working_folder(source_path, destination_path):\n    shutil.copy(source_path, destination_path)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T20:34:05.219299Z","iopub.execute_input":"2024-07-02T20:34:05.219587Z","iopub.status.idle":"2024-07-02T20:34:05.227151Z","shell.execute_reply.started":"2024-07-02T20:34:05.219556Z","shell.execute_reply":"2024-07-02T20:34:05.226083Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"data_path = '/kaggle/input/commonlit-evaluate-student-summaries/'\n\n# prompts train\ntrain_pro = pd.read_csv(data_path + 'prompts_train.csv')\n\n# summaries train\ntrain_sum = pd.read_csv(data_path + 'summaries_train.csv')\ntrain = train_pro.merge(train_sum , on = \"prompt_id\")\n\n# prompts test\ntest_pro = pd.read_csv(data_path + 'prompts_test.csv')\n\n# summaries test\ntest_sum = pd.read_csv(data_path + 'summaries_test.csv')\ntest = test_pro.merge(test_sum , on = \"prompt_id\")\ntest.head()","metadata":{"papermill":{"duration":0.175105,"end_time":"2024-05-16T15:39:15.917548","exception":false,"start_time":"2024-05-16T15:39:15.742443","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-07-02T20:34:09.636263Z","iopub.execute_input":"2024-07-02T20:34:09.636554Z","iopub.status.idle":"2024-07-02T20:34:09.818544Z","shell.execute_reply.started":"2024-07-02T20:34:09.636524Z","shell.execute_reply":"2024-07-02T20:34:09.817434Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"  prompt_id prompt_question     prompt_title       prompt_text    student_id  \\\n0    abc123    Summarize...  Example Title 1  Heading\\nText...  000000ffffff   \n1    abc123    Summarize...  Example Title 1  Heading\\nText...  222222cccccc   \n2    def789    Summarize...  Example Title 2  Heading\\nText...  111111eeeeee   \n3    def789    Summarize...  Example Title 2  Heading\\nText...  333333dddddd   \n\n             text  \n0  Example text 1  \n1  Example text 3  \n2  Example text 2  \n3  Example text 4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>student_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abc123</td>\n      <td>Summarize...</td>\n      <td>Example Title 1</td>\n      <td>Heading\\nText...</td>\n      <td>000000ffffff</td>\n      <td>Example text 1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abc123</td>\n      <td>Summarize...</td>\n      <td>Example Title 1</td>\n      <td>Heading\\nText...</td>\n      <td>222222cccccc</td>\n      <td>Example text 3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>def789</td>\n      <td>Summarize...</td>\n      <td>Example Title 2</td>\n      <td>Heading\\nText...</td>\n      <td>111111eeeeee</td>\n      <td>Example text 2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>def789</td>\n      <td>Summarize...</td>\n      <td>Example Title 2</td>\n      <td>Heading\\nText...</td>\n      <td>333333dddddd</td>\n      <td>Example text 4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"markdown","source":"### Content and Wording Histograms and Boxplots","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize=(12, 8))\nfor i in range (2):\n    target = 'Content' if i == 0 else 'Wording'\n    for j in range(2):\n        if j % 2 == 0:\n            train[target.lower()].hist(ax=axes[i][j], bins=15)\n            axes[i][j].set_title(f'{target} Histogram')\n            axes[i][j].set_xlabel(target)\n            axes[i][j].set_ylabel('Frequency')\n        else:\n            train.boxplot(target.lower(), ax=axes[i][j])\n            axes[i][j].set_title(f'{target} Boxplot')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-02T20:08:39.058892Z","iopub.status.idle":"2024-07-02T20:08:39.059371Z","shell.execute_reply.started":"2024-07-02T20:08:39.059131Z","shell.execute_reply":"2024-07-02T20:08:39.059150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Content and Wording Histograms and Boxplots After Log Transformation","metadata":{}},{"cell_type":"code","source":"# apply transformations to the content and wording\ntrain['content_transformed'] = (train['content'] + 3).apply(np.log)\ntrain['wording_transformed'] = (train['wording'] + 3).apply(np.log)\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\nfor i in range (2):\n    target = 'Content' if i == 0 else 'Wording'\n    for j in range(2):\n        if j % 2 == 0:\n            train[f'{target.lower()}_transformed'].hist(ax=axes[i][j], bins=15)\n            axes[i][j].set_title(f'{target} Histogram')\n            axes[i][j].set_xlabel(target)\n            axes[i][j].set_ylabel('Frequency')\n        else:\n            train.boxplot(f'{target.lower()}_transformed', ax=axes[i][j])\n            axes[i][j].set_title(f'{target} Boxplot')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-02T20:08:39.060379Z","iopub.status.idle":"2024-07-02T20:08:39.060722Z","shell.execute_reply.started":"2024-07-02T20:08:39.060549Z","shell.execute_reply":"2024-07-02T20:08:39.060564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Statistics","metadata":{}},{"cell_type":"code","source":"train['text_length'] = train['text'].apply(len)\ntrain['text_plus_prompt_text_lengths'] = train['text_length'] + train['prompt_text'].apply(len)\ntrain.describe()","metadata":{"execution":{"iopub.status.busy":"2024-07-01T19:22:14.060128Z","iopub.execute_input":"2024-07-01T19:22:14.060415Z","iopub.status.idle":"2024-07-01T19:22:14.099097Z","shell.execute_reply.started":"2024-07-01T19:22:14.060383Z","shell.execute_reply":"2024-07-01T19:22:14.098190Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"           content      wording  content_transformed  wording_transformed  \\\ncount  7165.000000  7165.000000          7165.000000          7165.000000   \nmean     -0.014853    -0.063072             1.033240             1.012884   \nstd       1.043569     1.036048             0.350223             0.366330   \nmin      -1.729859    -1.962614             0.239128             0.036704   \n25%      -0.799545    -0.872720             0.788664             0.754844   \n50%      -0.093814    -0.081769             1.066842             1.070977   \n75%       0.499660     0.503833             1.252666             1.253857   \nmax       3.900326     4.310693             1.931569             1.989338   \n\n       text_length  text_plus_prompt_text_lengths  \ncount  7165.000000                    7165.000000  \nmean    418.776971                    4302.183391  \nstd     307.833685                     840.802152  \nmin     114.000000                    3459.000000  \n25%     216.000000                    3646.000000  \n50%     320.000000                    3871.000000  \n75%     513.000000                    5302.000000  \nmax    3940.000000                    7911.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>wording</th>\n      <th>content_transformed</th>\n      <th>wording_transformed</th>\n      <th>text_length</th>\n      <th>text_plus_prompt_text_lengths</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>7165.000000</td>\n      <td>7165.000000</td>\n      <td>7165.000000</td>\n      <td>7165.000000</td>\n      <td>7165.000000</td>\n      <td>7165.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-0.014853</td>\n      <td>-0.063072</td>\n      <td>1.033240</td>\n      <td>1.012884</td>\n      <td>418.776971</td>\n      <td>4302.183391</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.043569</td>\n      <td>1.036048</td>\n      <td>0.350223</td>\n      <td>0.366330</td>\n      <td>307.833685</td>\n      <td>840.802152</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-1.729859</td>\n      <td>-1.962614</td>\n      <td>0.239128</td>\n      <td>0.036704</td>\n      <td>114.000000</td>\n      <td>3459.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-0.799545</td>\n      <td>-0.872720</td>\n      <td>0.788664</td>\n      <td>0.754844</td>\n      <td>216.000000</td>\n      <td>3646.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-0.093814</td>\n      <td>-0.081769</td>\n      <td>1.066842</td>\n      <td>1.070977</td>\n      <td>320.000000</td>\n      <td>3871.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.499660</td>\n      <td>0.503833</td>\n      <td>1.252666</td>\n      <td>1.253857</td>\n      <td>513.000000</td>\n      <td>5302.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.900326</td>\n      <td>4.310693</td>\n      <td>1.931569</td>\n      <td>1.989338</td>\n      <td>3940.000000</td>\n      <td>7911.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"prefix1 = \"Think through this step by step: \"\nprefix2 = \"Pay attention to the content and wording: \"\n\n# This function creates input ids, attention mask, and head mask\ndef preprocess(summary, prompt_question, prompt_text, tokenizer):\n    \n    sep = f\" {tokenizer.sep_token} \" \n    summary = prefix1 + prompt_question + sep + prefix2 + summary.apply(spell) + sep + prompt_text\n    tokenized = tokenizer.batch_encode_plus(summary.tolist(),\n                                            add_special_tokens=False,\n                                            truncation=True,\n                                            padding='max_length',\n                                            return_tensors='tf',\n                                            max_length=CFG.max_length,\n                                            return_attention_mask=True)\n    \n    input_ids = tokenized['input_ids']\n    attention_mask = tokenized['attention_mask']\n\n    # Create head mask\n    head_mask = np.zeros(input_ids.shape)\n    for i, summ in enumerate(input_ids.numpy()):\n        use_full = False\n        for j, token in enumerate(summ):\n            if token == tokenizer.sep_token_id:\n                use_full = not use_full  \n            elif token == tokenizer.pad_token_id:\n                break\n            head_mask[i][j] = (1. if use_full else 0.) \n    return [input_ids.numpy(), attention_mask.numpy(), head_mask.astype(np.float16)]","metadata":{"execution":{"iopub.status.busy":"2024-07-02T20:34:20.631884Z","iopub.execute_input":"2024-07-02T20:34:20.632220Z","iopub.status.idle":"2024-07-02T20:34:20.642151Z","shell.execute_reply.started":"2024-07-02T20:34:20.632177Z","shell.execute_reply":"2024-07-02T20:34:20.641275Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing for DEMO ONLY!","metadata":{}},{"cell_type":"code","source":"prefix1 = \"Think through this step by step: \"\nprefix2 = \"Pay attention to the content and wording: \"\n\n# This function creates input ids, attention mask, and head mask\ndef demo_preprocess(summary, prompt_question, prompt_text, tokenizer):\n    \n    sep = f\" {tokenizer.sep_token} \" \n    summary = prefix1 + prompt_question + sep + prefix2 + spell(summary) + sep + prompt_text\n    tokenized = tokenizer.batch_encode_plus(summary.split(),\n                                            add_special_tokens=False,\n                                            truncation=True,\n                                            padding='max_length',\n                                            return_tensors='tf',\n                                            max_length=CFG.max_length,\n                                            return_attention_mask=True)\n    \n    input_ids = tokenized['input_ids']\n    attention_mask = tokenized['attention_mask']\n\n    # Create head mask\n    head_mask = np.zeros(input_ids.shape)\n    for i, summ in enumerate(input_ids.numpy()):\n        use_full = False\n        for j, token in enumerate(summ):\n            if token == tokenizer.sep_token_id:\n                use_full = not use_full  \n            elif token == tokenizer.pad_token_id:\n                break\n            head_mask[i][j] = (1. if use_full else 0.) \n    return [input_ids.numpy(), attention_mask.numpy(), head_mask.astype(np.float16)]","metadata":{"execution":{"iopub.status.busy":"2024-07-02T20:34:22.805175Z","iopub.execute_input":"2024-07-02T20:34:22.805769Z","iopub.status.idle":"2024-07-02T20:34:22.815616Z","shell.execute_reply.started":"2024-07-02T20:34:22.805732Z","shell.execute_reply":"2024-07-02T20:34:22.814435Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# generate_predictions for DEMO ONLY!","metadata":{}},{"cell_type":"code","source":"def demo_generate_predictions(model, data):\n    contents = []\n    wordings = []\n    ids = []\n    predictions = model.predict(x=[data['input_ids'], data['attention_mask'], data['head_mask']],\n                                batch_size=CFG.batch_size)\n\n    for idx, output in enumerate(predictions):\n        contents.append(output[0])\n        wordings.append(output[1])\n        ids.append(data['student_id'])\n\n    contents = np.exp(contents) - 3\n    wordings = np.exp(wordings) - 3\n        \n    return ids, contents, wordings","metadata":{"execution":{"iopub.status.busy":"2024-07-02T20:58:25.624903Z","iopub.execute_input":"2024-07-02T20:58:25.625198Z","iopub.status.idle":"2024-07-02T20:58:25.632433Z","shell.execute_reply.started":"2024-07-02T20:58:25.625168Z","shell.execute_reply":"2024-07-02T20:58:25.631538Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Define Model","metadata":{}},{"cell_type":"code","source":"# Creates a model that wraps the pre trained model\n@keras.utils.register_keras_serializable()\nclass PreTrainedModel(keras.Model):\n    def __init__(self, model_path, trainable=False, num_layers_to_freeze=0, name=None, **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.model_path = model_path\n        self.trainable = trainable\n        self.num_layers_to_freeze = num_layers_to_freeze\n        \n        # Load model and tokenizer\n        self.model = TFAutoModel.from_pretrained(model_path + \"model\") \n        self.tokenizer = AutoTokenizer.from_pretrained(model_path + \"tokenizer\")\n        \n        # Define model configurations\n        self.model.trainable = self.trainable\n        self.model.config.hidden_dropout_prob = CFG.hidden_dropout_prob\n        self.model.config.attention_probs_dropout_prob = CFG.attention_probs_dropout_prob\n        \n        # Freeze layers if trainable\n        if self.trainable:\n            self.model.trainable = self.trainable\n            if self.trainable:\n                for layer in self.model.layers[0].encoder.layer[:self.num_layers_to_freeze]:\n                    layer.trainable = False\n\n    # Call the pre trained model and get the all hidden state\n    def call(self, input_ids, attention_mask):\n        output = self.model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n        return output.hidden_states\n    \n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'model_path': self.model_path,\n            'trainable': self.trainable,\n            'num_layers_to_freeze': self.num_layers_to_freeze\n        })\n        return config\n\n    @classmethod\n    def from_config(cls, config):\n        return cls(**config)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T20:34:24.662170Z","iopub.execute_input":"2024-07-02T20:34:24.663134Z","iopub.status.idle":"2024-07-02T20:34:24.676129Z","shell.execute_reply.started":"2024-07-02T20:34:24.663078Z","shell.execute_reply":"2024-07-02T20:34:24.674857Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Define layers for head mask step\n\n@keras.utils.register_keras_serializable()\nclass ExpandDimsLayer(layers.Layer):\n    def __init__(self, **kwargs):\n        super(ExpandDimsLayer, self).__init__(**kwargs)\n\n    def call(self, inputs):\n        return tf.expand_dims(tf.cast(inputs, dtype=tf.float32), axis=-1)\n\n@keras.utils.register_keras_serializable()\nclass MaskedEmbeddingsLayer(layers.Layer):\n    def __init__(self, **kwargs):\n        super(MaskedEmbeddingsLayer, self).__init__(**kwargs)\n\n    def call(self, inputs):\n        hidden_state, h_mask = inputs\n        return tf.multiply(hidden_state, h_mask)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T20:34:25.817266Z","iopub.execute_input":"2024-07-02T20:34:25.817762Z","iopub.status.idle":"2024-07-02T20:34:25.826037Z","shell.execute_reply.started":"2024-07-02T20:34:25.817729Z","shell.execute_reply":"2024-07-02T20:34:25.825079Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Define loss function","metadata":{}},{"cell_type":"code","source":"# The loss function\n@keras.utils.register_keras_serializable()\ndef mcrmse(y_true, y_pred):\n    y_true = tf.cast(y_true, tf.float16)\n    y_pred = tf.cast(y_pred, tf.float16)\n    columnwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=0)\n    return tf.reduce_mean(tf.sqrt(columnwise_mse), axis=-1)","metadata":{"papermill":{"duration":0.032128,"end_time":"2024-05-16T15:40:24.400490","exception":false,"start_time":"2024-05-16T15:40:24.368362","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-07-02T20:34:29.385292Z","iopub.execute_input":"2024-07-02T20:34:29.385600Z","iopub.status.idle":"2024-07-02T20:34:29.392004Z","shell.execute_reply.started":"2024-07-02T20:34:29.385568Z","shell.execute_reply":"2024-07-02T20:34:29.390957Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### (Optional) Add image of model design diagram","metadata":{}},{"cell_type":"code","source":"@keras.utils.register_keras_serializable()\ndef build_deberta():\n    return PreTrainedModel(CFG.pre_trained_model_name, name=\"deberta_layer\")","metadata":{"execution":{"iopub.status.busy":"2024-07-02T20:34:31.389066Z","iopub.execute_input":"2024-07-02T20:34:31.389622Z","iopub.status.idle":"2024-07-02T20:34:31.394814Z","shell.execute_reply.started":"2024-07-02T20:34:31.389588Z","shell.execute_reply":"2024-07-02T20:34:31.393508Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def create_model(decay_steps=10000):\n    \n    # Instances\n    pre_trained_model_instance = build_deberta()\n    expand_dims_instance = ExpandDimsLayer(name='expand_dims')\n    mask_instance = MaskedEmbeddingsLayer(name='masked_embeddings')\n    avg_pooling_instance = layers.GlobalAveragePooling1D()\n    reshape_instance1 = layers.Reshape((1, -1), name='reshape_layer1')\n    reshape_instance2 = layers.Reshape((1, -1), name='reshape_layer2')\n    dense_instance = layers.Dense(CFG.embeddings_len, activation='gelu')\n\n    # The NN starts from here\n    \n    # Input layers\n    input_ids = keras.Input(shape=(CFG.max_length,), dtype='int32', name='input_ids')\n    attention_mask = keras.Input(shape=(CFG.max_length,), dtype='int32', name='attention_mask')\n    head_mask = keras.Input(shape=(CFG.max_length,), dtype='float16', name='head_mask')\n    \n    # Create embeddings and get all hidden states\n    hidden_states = pre_trained_model_instance(input_ids, attention_mask)\n    \n    # Mask pooling all hidden states of pre-trained model\n    pooled_hidden_states = []\n    for hidden_state in hidden_states:\n        h_mask = expand_dims_instance(head_mask)\n        masked_outputs = mask_instance([hidden_state, h_mask])\n        avg_pooling_layer = avg_pooling_instance(masked_outputs)\n        reshape_layer = reshape_instance1(avg_pooling_layer)\n        pooled_hidden_states.append(reshape_layer)\n    \n    # Concatenate all the hidden states an forward pass through LSTM\n    x = layers.Concatenate(axis=1)(pooled_hidden_states)\n    x = layers.LSTM(CFG.embeddings_len, return_sequences=False)(x)\n    \n    # Multi-sample Dropout\n    x = layers.Dropout(0.1)(x)\n    dropoutList = [reshape_instance2(dense_instance(layers.Dropout((i + 1) * 0.1)(x))) for i in range(5)]\n    x = layers.Concatenate(axis=1)(dropoutList)\n    x = layers.GlobalAveragePooling1D()(x)\n    \n    # Final dense layer\n    x = layers.Dense(512, activation='linear')(x)\n    x = layers.LayerNormalization()(x)\n    x = layers.Dropout(0.2)(x)\n    x = layers.Activation(keras.activations.gelu, name='gelu')(x)\n    \n    output_layer = layers.Dense(2, activation='linear')(x)\n    \n\n    # Compile model\n    model = keras.Model(inputs=[input_ids, attention_mask, head_mask], outputs=output_layer)\n    lr_schedule = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=CFG.learning_rate,\n                                                            decay_steps=decay_steps,\n                                                            warmup_target=CFG.learning_rate,\n                                                            warmup_steps=CFG.warmup_steps,\n                                                           )\n    opt = keras.optimizers.AdamW(learning_rate=lr_schedule, weight_decay=CFG.weight_decay, use_ema=True)\n    model.compile(loss=mcrmse, optimizer=opt)\n    return model, pre_trained_model_instance","metadata":{"execution":{"iopub.status.busy":"2024-07-02T20:34:32.198479Z","iopub.execute_input":"2024-07-02T20:34:32.199290Z","iopub.status.idle":"2024-07-02T20:34:32.215882Z","shell.execute_reply.started":"2024-07-02T20:34:32.199252Z","shell.execute_reply":"2024-07-02T20:34:32.215044Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Train Model","metadata":{}},{"cell_type":"code","source":"X = train[['text', 'prompt_question', 'prompt_text']]    \n\n# apply transformations to the content and wording\ntrain['content_transformed'] = (train['content'] + 3).apply(np.log)\ntrain['wording_transformed'] = (train['wording'] + 3).apply(np.log)\ny = train[['content_transformed', 'wording_transformed']].astype('float16')\n    \ndecay_steps = math.ceil((len(X) / CFG.batch_size) * CFG.epochs) \nmodel, deberta = create_model(decay_steps=decay_steps)\n    \nX = preprocess(X['text'], X['prompt_question'], X['prompt_text'], deberta.tokenizer)\n    \n# Callbacks\nema = keras.callbacks.SwapEMAWeights(swap_on_epoch=True)\nckptcb = keras.callbacks.ModelCheckpoint(\n    CFG.final_model_path,\n    monitor=\"loss\",\n    save_best_only=True,\n    mode=\"min\",\n)\n    \nhistory = model.fit(x=X,\n                    y=y.values,\n                    epochs=CFG.epochs,\n                    batch_size=CFG.batch_size,\n                    callbacks=[ema, ckptcb],\n                    verbose=1)\n    \nprint('done')","metadata":{"execution":{"iopub.status.busy":"2024-07-01T19:27:42.831041Z","iopub.execute_input":"2024-07-01T19:27:42.831800Z","iopub.status.idle":"2024-07-01T19:30:00.556448Z","shell.execute_reply.started":"2024-07-01T19:27:42.831763Z","shell.execute_reply":"2024-07-01T19:30:00.555308Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"done\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Inference ","metadata":{}},{"cell_type":"code","source":"def generate_predictions(model, data):\n    contents = []\n    wordings = []\n    ids = []\n    predictions = model.predict(x=[data['input_ids'], data['attention_mask'], data['head_mask']],\n                                batch_size=CFG.batch_size)\n\n    for idx, output in enumerate(predictions):\n        contents.append(output[0])\n        wordings.append(output[1])\n        ids.append(data['student_id'][idx])\n\n    contents = np.exp(contents) - 3\n    wordings = np.exp(wordings) - 3\n        \n    return ids, contents, wordings","metadata":{"execution":{"iopub.status.busy":"2024-07-02T20:34:38.115106Z","iopub.execute_input":"2024-07-02T20:34:38.115790Z","iopub.status.idle":"2024-07-02T20:34:38.124148Z","shell.execute_reply.started":"2024-07-02T20:34:38.115749Z","shell.execute_reply":"2024-07-02T20:34:38.122844Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Inference Baseline Model","metadata":{}},{"cell_type":"code","source":"# content_scores = np.random.uniform(-1.73, 3.9, len(test))\n# wording_scores = np.random.uniform(-1.96, 4.31, len(test))\n\n# submission_df = pd.DataFrame({'student_id': test['student_id'],\n#                               'content': content_scores,\n#                               'wording': wording_scores})\n\n# submission_df.to_csv(\"submission.csv\", index=False)\n# submission_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-01T15:01:22.144859Z","iopub.execute_input":"2024-07-01T15:01:22.145126Z","iopub.status.idle":"2024-07-01T15:01:22.149379Z","shell.execute_reply.started":"2024-07-01T15:01:22.145096Z","shell.execute_reply":"2024-07-01T15:01:22.148537Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Inference Final Model","metadata":{}},{"cell_type":"code","source":"model_to_submit_path = '/kaggle/working/' + CFG.final_model_path\nmove_to_working_folder('/kaggle/input/models/' + CFG.final_model_path, model_to_submit_path)\n\n# Sort by prompt and text lengths\ntest['length'] = test['text'].apply(len) + test['prompt_text'].apply(len)\ntest = test.sort_values('length', ascending=True).reset_index(drop=True)\n\n\nX = test[['text', 'prompt_question', 'prompt_text']]\n\nmodel = keras.models.load_model(model_to_submit_path)\ndeberta = build_deberta()\n    \nX = preprocess(X['text'], X['prompt_question'], X['prompt_text'], deberta.tokenizer)\n\ntest_data = {\n    'input_ids': X[0],\n    'attention_mask': X[1],\n    'head_mask': X[2],\n    'student_id': test['student_id'],\n}\n\nmodel = keras.models.load_model(model_to_submit_path)\nids, contents, wordings = generate_predictions(model, test_data)\n    \n\nsubmission_df = pd.DataFrame({'student_id': ids,\n                              'content': contents,\n                              'wording': wordings})\n\nsubmission_df.to_csv(\"submission.csv\", index=False)\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-02T17:44:29.745684Z","iopub.execute_input":"2024-07-02T17:44:29.746116Z","iopub.status.idle":"2024-07-02T17:44:30.082827Z","shell.execute_reply.started":"2024-07-02T17:44:29.746079Z","shell.execute_reply":"2024-07-02T17:44:30.080512Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_to_submit_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mCFG\u001b[49m\u001b[38;5;241m.\u001b[39mfinal_model_path\n\u001b[1;32m      2\u001b[0m move_to_working_folder(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/models/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m CFG\u001b[38;5;241m.\u001b[39mfinal_model_path, model_to_submit_path)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Sort by prompt and text lengths\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'CFG' is not defined"],"ename":"NameError","evalue":"name 'CFG' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"# Demo","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nmodel_to_submit_path = '/kaggle/working/' + CFG.final_model_path\nmove_to_working_folder('/kaggle/input/models/' + CFG.final_model_path, model_to_submit_path)\n\nmodel = keras.models.load_model(model_to_submit_path)\ndeberta = build_deberta()\n\ndef run_demo(student_id, summary, prompt_question, prompt_text):\n    input_ids, attention_mask, head_mask = preprocess(summary, prompt_question, prompt_text, deberta.tokenizer)\n    \n    inputs = {\n        'input_ids': input_ids,\n        'attention_mask': attention_mask,\n        'head_mask': head_mask,\n        'student_id': student_id,\n    }\n    output = demo_generate_predictions(model, inputs)\n    \n    return output\n\ndf = pd.read_excel('/kaggle/input/llm-generate-test/LLM_Generate_Test.xlsx')\nrandom_row = df.sample(n=1)\n\nstudent_id = random_row.iloc[0,0]\nsummary = random_row.iloc[0,3]\nprompt_question = random_row.iloc[0,2]\nprompt_text = random_row.iloc[0,1]\n\nprint(f'student_id = {student_id}')\nprint(f'summary = {summary}')\nprint(f' prompt_question = { prompt_question}')\nprint(f'prompt_text = {prompt_text}')\n\nsummary_list = [item for item in summary.split()]\nsummary_pd = pd.Series(summary_list)\noutputs = run_demo(student_id, summary_pd, prompt_question, prompt_text)\nprint(outputs)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T20:58:44.935751Z","iopub.execute_input":"2024-07-02T20:58:44.936593Z","iopub.status.idle":"2024-07-02T21:00:22.570080Z","shell.execute_reply.started":"2024-07-02T20:58:44.936555Z","shell.execute_reply":"2024-07-02T21:00:22.569052Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"student_id = 431\nsummary = Social media, yay, connects all. But, oh no, privacy. Also, mental health, uh oh.\n prompt_question = Discuss the benefits and drawbacks of social media in modern society.\n\nprompt_text =  Social media has become an integral part of modern society, with millions of people around the world actively engaging with various platforms on a daily basis. While social media offers numerous benefits, it also presents certain drawbacks that need to be considered.\nOn one hand, social media has revolutionized the way we communicate and connect with others. It provides a platform for people to stay connected with friends and family, regardless of geographical barriers. Whether it is through sharing updates, photos, or videos, social media allows individuals to maintain relationships and stay updated on the lives of their loved ones. Additionally, social media enables users to join online communities and groups that share similar interests and passions, providing an avenue for like-minded individuals to connect and share ideas.\nFurthermore, social media has proven to be a powerful tool for information dissemination. News channels and organizations utilize social media platforms to share news headlines and updates in real-time, ensuring that people are informed around the clock. Social media has also facilitated grassroots movements and activism, allowing individuals to raise awareness about important social, environmental, and political issues. It has given a voice to marginalized communities and has been instrumental in bringing attention to injustices.\nHowever, it is crucial to recognize the drawbacks associated with social media as well. Firstly, there is a concern regarding privacy and security. With the amount of personal information shared on social media platforms, users are vulnerable to data breaches and identity theft. Additionally, the constant sharing of personal information and updates can lead to a lack of anonymity and potential surveillance. Furthermore, social media can contribute to mental health issues such as anxiety and depression. The curated nature of profiles and the constant comparison to others can lead to feelings of inadequacy and low self-esteem. Moreover, the addictive nature of social media, with its constant notifications and updates, can lead to a decrease in productivity and focus.\nIn conclusion, social media has undoubtedly revolutionized the way we communicate and interact with others. It offers numerous benefits, including staying connected with loved ones and spreading information. However, it is important to be mindful of the drawbacks such as privacy concerns and negative impacts on mental health. As with any powerful tool, it is essential to use social media responsibly and strike a balance between its advantages and disadvantages.\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6s/step\n([431, 431, 431, 431, 431, 431, 431, 431, 431, 431, 431, 431, 431, 431], array([-0.8867, -0.8438, -0.83  , -0.918 , -0.9023, -0.8926, -0.828 ,\n       -0.758 , -0.908 , -0.8887, -0.8945, -0.8203, -0.836 , -0.873 ],\n      dtype=float16), array([-0.9355, -0.789 , -0.8867, -0.8438, -0.8926, -0.9297, -0.8594,\n       -0.76  , -0.9707, -0.9043, -0.842 , -0.793 , -0.871 , -0.9277],\n      dtype=float16))\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}