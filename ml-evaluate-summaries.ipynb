{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":53482,"databundleVersionId":6201832,"sourceType":"competition"},{"sourceId":8139549,"sourceType":"datasetVersion","datasetId":4812209},{"sourceId":8139552,"sourceType":"datasetVersion","datasetId":4812212},{"sourceId":8146152,"sourceType":"datasetVersion","datasetId":4817190},{"sourceId":8421200,"sourceType":"datasetVersion","datasetId":5013476},{"sourceId":8469314,"sourceType":"datasetVersion","datasetId":5049859}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":109.119668,"end_time":"2024-05-16T15:40:29.014408","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-05-16T15:38:39.894740","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"059a11eda62448da981f7b2667b94637":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d4e90cc3beb40b890ffd3978dfb22d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"150f7c2a80124dad8408945c7c4a0fce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15104f9159d1410eb85b6379bc0756c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff9e6813dd3d499f8c44902f3806b49c","IPY_MODEL_588ef8f9110e4ba8897785a7816b52a6","IPY_MODEL_afa499e764d4423fbc616d6a8de52fd0"],"layout":"IPY_MODEL_deefef886f9c43cf88f6f162100f2e3e"}},"1982a9459b644ddf93b0670b17ed6427":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b2c1961d94c4a07b162c8e1f1f4ea8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e281edfb4944800b70ca3e7b078cd13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f7d29516b7a46dcb0fa01415173e1df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"25126573d458497987981721450a08ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c8166010478471ebcfeaff488254cc3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ed7fd040a494b91bcb6b11bf17446a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c55a6f3b2d6453d92734e1c2c6ccf3d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f8ee3fcf5ed47f08eb3eeaff0647d5e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42cdc6d0d53e4ab298128b8581bf4c3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c8166010478471ebcfeaff488254cc3","placeholder":"​","style":"IPY_MODEL_059a11eda62448da981f7b2667b94637","value":" 2.46M/2.46M [00:00&lt;00:00, 3.68MB/s]"}},"464d8379cbd842b6b0c919aa12c237ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1982a9459b644ddf93b0670b17ed6427","placeholder":"​","style":"IPY_MODEL_a0ed8c5740e846b7912490fe3541991c","value":"spm.model: 100%"}},"57d07143c3b54fb2baad23f96e0874aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"588ef8f9110e4ba8897785a7816b52a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d4e90cc3beb40b890ffd3978dfb22d8","max":1736592160,"min":0,"orientation":"horizontal","style":"IPY_MODEL_150f7c2a80124dad8408945c7c4a0fce","value":1736592160}},"640eb7d806d7408ba3ba560fa99b9142":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73ed4c4fc9104779b8fdb3fc52e64f4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa4f2028d4be4adfb1389b240b2c7ee0","placeholder":"​","style":"IPY_MODEL_cd53dfa32e15440aadac97ed88dbec02","value":" 580/580 [00:00&lt;00:00, 52.0kB/s]"}},"76c12b9e7502419da6c5d8afae0b45ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eb63820b62d49ea9bc8059798aabfb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_464d8379cbd842b6b0c919aa12c237ad","IPY_MODEL_d006714a85f746a2a1485b6e1faf7003","IPY_MODEL_42cdc6d0d53e4ab298128b8581bf4c3a"],"layout":"IPY_MODEL_25126573d458497987981721450a08ae"}},"999bd4cca8c94c3a8c59da5cb58d8c2e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ae4657f98844aa686e0a73f6bb69972":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_efc7d8e9f3cc457f93faf7367ab86cd3","IPY_MODEL_f37802e035ff44d181776f86eabe948d","IPY_MODEL_a915e75f5ed847a7b44823aadb68b8e3"],"layout":"IPY_MODEL_9cc123d4a6da4ac9bf37029593171ca6"}},"9cc123d4a6da4ac9bf37029593171ca6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d8022fde15349cf92f52a24eac326ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0ed8c5740e846b7912490fe3541991c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a915e75f5ed847a7b44823aadb68b8e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_640eb7d806d7408ba3ba560fa99b9142","placeholder":"​","style":"IPY_MODEL_1e281edfb4944800b70ca3e7b078cd13","value":" 52.0/52.0 [00:00&lt;00:00, 4.37kB/s]"}},"aa1ceb8e11cc412ea3062b14dcb51319":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3852559827e4748844d3b2927447926","max":580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b2c1961d94c4a07b162c8e1f1f4ea8f","value":580}},"aa4f2028d4be4adfb1389b240b2c7ee0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad398d8a95ab459abdfa03879da117ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afa499e764d4423fbc616d6a8de52fd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8b1ba7cf2354528ab658faf56c8985f","placeholder":"​","style":"IPY_MODEL_c4ef64c1429c4d049c4b952e1906bf5e","value":" 1.74G/1.74G [00:41&lt;00:00, 42.6MB/s]"}},"b3852559827e4748844d3b2927447926":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba8f192523cf4f3d81fe72f0c6b16060":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4ef64c1429c4d049c4b952e1906bf5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cae13970055a44a09fbe31e19911087a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76c12b9e7502419da6c5d8afae0b45ab","placeholder":"​","style":"IPY_MODEL_2ed7fd040a494b91bcb6b11bf17446a7","value":"config.json: 100%"}},"cd53dfa32e15440aadac97ed88dbec02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cde68addf7004559a03c89e3c5cd5070":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d006714a85f746a2a1485b6e1faf7003":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba8f192523cf4f3d81fe72f0c6b16060","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57d07143c3b54fb2baad23f96e0874aa","value":2464616}},"deefef886f9c43cf88f6f162100f2e3e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8b1ba7cf2354528ab658faf56c8985f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efc7d8e9f3cc457f93faf7367ab86cd3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f8ee3fcf5ed47f08eb3eeaff0647d5e","placeholder":"​","style":"IPY_MODEL_cde68addf7004559a03c89e3c5cd5070","value":"tokenizer_config.json: 100%"}},"f37802e035ff44d181776f86eabe948d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c55a6f3b2d6453d92734e1c2c6ccf3d","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f7d29516b7a46dcb0fa01415173e1df","value":52}},"f37f807ded5e4af5a607d3a76b4de99f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cae13970055a44a09fbe31e19911087a","IPY_MODEL_aa1ceb8e11cc412ea3062b14dcb51319","IPY_MODEL_73ed4c4fc9104779b8fdb3fc52e64f4e"],"layout":"IPY_MODEL_9d8022fde15349cf92f52a24eac326ed"}},"ff9e6813dd3d499f8c44902f3806b49c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_999bd4cca8c94c3a8c59da5cb58d8c2e","placeholder":"​","style":"IPY_MODEL_ad398d8a95ab459abdfa03879da117ba","value":"tf_model.h5: 100%"}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-16T15:38:42.556819Z","iopub.status.busy":"2024-05-16T15:38:42.556494Z","iopub.status.idle":"2024-05-16T15:38:42.561206Z","shell.execute_reply":"2024-05-16T15:38:42.560454Z"},"papermill":{"duration":0.030666,"end_time":"2024-05-16T15:38:42.563061","exception":false,"start_time":"2024-05-16T15:38:42.532395","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport warnings\nimport logging\nimport pickle\nimport os\nimport gc\n\n# disabling unnecceseray warnings\nwarnings.simplefilter(\"ignore\")\nlogging.disable(logging.ERROR)\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport tensorflow as tf\nfrom transformers import TFAutoModel, AutoTokenizer\nfrom tensorflow import keras\nfrom keras import layers\nimport datetime\nfrom keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\n\nkeras.mixed_precision.set_global_policy(\"mixed_float16\")\n\n# Limit the GPU memory growth using TensorFlow\nphysical_devices = tf.config.list_physical_devices('GPU')\ntf.config.experimental.set_memory_growth(physical_devices[0], True)\n# tf.config.experimental.set_memory_growth(physical_devices[1], True)\n\nimport random\n\n# Set random seeds\nrandom_seed = 42\nnp.random.seed(random_seed)\ntf.random.set_seed(random_seed)\nrandom.seed(random_seed)\nkeras.utils.set_random_seed(random_seed)\n\n!pip install autocorrect\nfrom autocorrect import Speller\nspell = Speller(lang='en', fast=True)\nspell('helo')","metadata":{"papermill":{"duration":33.079441,"end_time":"2024-05-16T15:39:15.664457","exception":false,"start_time":"2024-05-16T15:38:42.585016","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T16:07:20.284389Z","iopub.execute_input":"2024-05-20T16:07:20.285160Z","iopub.status.idle":"2024-05-20T16:07:35.558062Z","shell.execute_reply.started":"2024-05-20T16:07:20.285120Z","shell.execute_reply":"2024-05-20T16:07:35.557161Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting autocorrect\n  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.8/622.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: autocorrect\n  Building wheel for autocorrect (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622364 sha256=dabec0568e825ad362f11cad5e066f381d5bbe5241bb1f1f7a83caffde52347f\n  Stored in directory: /root/.cache/pip/wheels/b5/7b/6d/b76b29ce11ff8e2521c8c7dd0e5bfee4fb1789d76193124343\nSuccessfully built autocorrect\nInstalling collected packages: autocorrect\nSuccessfully installed autocorrect-2.6.1\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'held'"},"metadata":{}}]},{"cell_type":"code","source":"data_path = '/kaggle/input/commonlit-evaluate-student-summaries/'\n\n# prompts train\ntrain_pro = pd.read_csv(data_path + 'prompts_train.csv')\ntrain_pro.head(1)\n\n# summaries train\ntrain_sum = pd.read_csv(data_path + 'summaries_train.csv')\ntrain_sum.head(1)\n\n# we will need to take a portion of the train data as test data\n\ntrain = train_pro.merge(train_sum , on = \"prompt_id\")\ntrain.head(1)","metadata":{"papermill":{"duration":0.175105,"end_time":"2024-05-16T15:39:15.917548","exception":false,"start_time":"2024-05-16T15:39:15.742443","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T16:07:35.902057Z","iopub.execute_input":"2024-05-20T16:07:35.902260Z","iopub.status.idle":"2024-05-20T16:07:35.970184Z","shell.execute_reply.started":"2024-05-20T16:07:35.902230Z","shell.execute_reply":"2024-05-20T16:07:35.969399Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"  prompt_id                                    prompt_question prompt_title  \\\n0    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n\n                                         prompt_text    student_id  \\\n0  Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f   \n\n                                                text   content   wording  \n0  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>student_id</th>\n      <th>text</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>00791789cc1f</td>\n      <td>1 element of an ideal tragedy is that it shoul...</td>\n      <td>-0.210614</td>\n      <td>-0.471415</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Model name to load\nmodel_name =  \"microsoft/deberta-v3-large\"\n\n# Load DeBERTa / RoBERTa model and tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name)\npre_trained_model = TFAutoModel.from_pretrained(model_name)","metadata":{"papermill":{"duration":52.227164,"end_time":"2024-05-16T15:40:08.168031","exception":false,"start_time":"2024-05-16T15:39:15.940867","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T16:47:22.626547Z","iopub.execute_input":"2024-05-20T16:47:22.627388Z","iopub.status.idle":"2024-05-20T16:49:22.649655Z","shell.execute_reply.started":"2024-05-20T16:47:22.627341Z","shell.execute_reply":"2024-05-20T16:49:22.648839Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e5b4a18c9d54f868ddf78d982a33e28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af4d96aa16fa418e95e26e066e191a46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ea8a38414e548639b6b5f0e444560fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tf_model.h5:   0%|          | 0.00/1.74G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e43ac1d5c7b44cadb81d8ba9e3614ce0"}},"metadata":{}}]},{"cell_type":"code","source":"# Auto correcting spellings of all summaries\nsep = f\" {tokenizer.sep_token} \"\n\nprefix1 = \"Think through this step by step: \"\nprefix2 = \"Pay attention to the content and wording: \"\n\ntrain[\"text\"] = train[\"text\"].apply(lambda x: spell(x))\ntrain['input'] = train['prompt_title'] + sep + prefix1 + train['prompt_question'] + sep + prefix2 + train['text']\ntrain['input'][0]","metadata":{"papermill":{"duration":9.133516,"end_time":"2024-05-16T15:40:17.326497","exception":false,"start_time":"2024-05-16T15:40:08.192981","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T16:49:38.357934Z","iopub.execute_input":"2024-05-20T16:49:38.358636Z","iopub.status.idle":"2024-05-20T16:49:44.630896Z","shell.execute_reply.started":"2024-05-20T16:49:38.358595Z","shell.execute_reply":"2024-05-20T16:49:44.630051Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"'On Tragedy [SEP] Think through this step by step: Summarize at least 3 elements of an ideal tragedy, as described by Aristotle. [SEP] Pay attention to the content and wording: 1 element of an ideal tragedy is that it should be arranged on a complex plan.  Another element of an ideal tragedy is that it should only have one main issue. The last element of an ideal tragedy is that it should have a double thread plot and an opposite catastrophe for both good and bad.'"},"metadata":{}}]},{"cell_type":"code","source":"# Preprocessing features and labels\n\n# Tokenize text data\n\n# Change MAX_SUMMARY_LENGTH\nMAX_SUMMARY_LENGTH = 1500 + len(prefix1) + len(prefix2)\n\n# DEBERTA / RoBERTa Tokenizing\nX_train = tokenizer.batch_encode_plus(train['input'].tolist(),\n                                              add_special_tokens=True,\n                                              truncation=True,\n                                              padding='max_length',\n                                              return_tensors='tf',\n                                              max_length=MAX_SUMMARY_LENGTH,\n                                              return_attention_mask = True)\ndel X_train['token_type_ids']\n\nY_train = tf.constant(train[['content', 'wording']].values, dtype=tf.float32)","metadata":{"papermill":{"duration":6.221924,"end_time":"2024-05-16T15:40:23.962893","exception":false,"start_time":"2024-05-16T15:40:17.740969","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T16:49:44.632090Z","iopub.execute_input":"2024-05-20T16:49:44.632361Z","iopub.status.idle":"2024-05-20T16:49:50.474952Z","shell.execute_reply.started":"2024-05-20T16:49:44.632327Z","shell.execute_reply":"2024-05-20T16:49:50.474187Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Create head mask\nhead_mask = np.zeros(X_train['input_ids'].shape)\nfor i, summary in enumerate(X_train['input_ids'].numpy()):\n    use_full = False\n    first_sep_flag = True\n    for j, token in enumerate(summary):\n        if token == tokenizer.sep_token_id:\n            if first_sep_flag:\n                first_sep_flag = False\n            else:\n                use_full = not use_full  \n        head_mask[i][j] = (1 if use_full else 0) \nhead_mask = tf.constant(head_mask)\nhead_mask","metadata":{"papermill":{"duration":0.031859,"end_time":"2024-05-16T15:40:24.019759","exception":false,"start_time":"2024-05-16T15:40:23.987900","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T16:49:50.476055Z","iopub.execute_input":"2024-05-20T16:49:50.476278Z","iopub.status.idle":"2024-05-20T16:50:51.174128Z","shell.execute_reply.started":"2024-05-20T16:49:50.476253Z","shell.execute_reply":"2024-05-20T16:50:51.173330Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(7165, 1575), dtype=float64, numpy=\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])>"},"metadata":{}}]},{"cell_type":"code","source":"# def get_embeddings(input_ids, attention_mask, model_name):\n    \n#     # Forward pass through pre trained model\n#     outputs = pre_trained_model(input_ids=input_ids, attention_mask=attention_mask)\n    \n#     if model_name == 'roberta-large':\n#         return outputs['pooler_output']\n#     else:\n#         return outputs[0]\n\n# # Save roberta/deberta embeddings in the training set\n\n# batch_size = 10 # ten is the biggest batch possible (can try maybe 11)\n# num_samples = len(X_train['input_ids'])\n# num_batches = (num_samples + batch_size - 1) // batch_size\n# averaged_embeddings = []\n\n# for i in range(num_batches):\n#     start_idx = i * batch_size\n#     end_idx = min((i + 1) * batch_size, num_samples)\n#     inputs = X_train['input_ids'][start_idx: end_idx]\n#     masks = X_train['attention_mask'][start_idx: end_idx]\n    \n#     embeddings = get_embeddings(input_ids=inputs, attention_mask=masks, model_name=model_name)\n#     h_mask = tf.expand_dims(tf.cast(head_mask[start_idx: end_idx], dtype=tf.float32), axis=-1)\n#     masked_outputs = tf.multiply(embeddings, h_mask)\n#     pooled = (tf.reduce_mean(masked_outputs, axis=1)).numpy()\n#     averaged_embeddings.append(pooled)\n    \n#     if i % int(num_batches * 0.1) == 0:\n#         print(f\"Batch {i}/{num_batches}\")\n        \n#     del embeddings\n#     del masked_outputs\n#     del pooled\n#     del h_mask\n#     gc.collect()\n#     tf.keras.backend.clear_session()\n# # Write to a file    \n# concatenated_embeddings = np.concatenate(averaged_embeddings, axis=0)\n# with open('masked_pooled_deberta_embeddings.pkl', 'wb') as f:\n#     pickle.dump(concatenated_embeddings, f)","metadata":{"papermill":{"duration":0.032191,"end_time":"2024-05-16T15:40:24.076135","exception":false,"start_time":"2024-05-16T15:40:24.043944","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-16T16:05:06.471813Z","iopub.execute_input":"2024-05-16T16:05:06.472020Z","iopub.status.idle":"2024-05-16T16:05:06.477607Z","shell.execute_reply.started":"2024-05-16T16:05:06.471994Z","shell.execute_reply":"2024-05-16T16:05:06.476760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save file to output folder\n\n# NOTE: if not running on Kaggle then modify the paths\n\n# RoBERTa\n# file_path = '/kaggle/input/cls-roberta-embeddings/cls_embeddings.csv' # from input folder\n\n# DeBERTa \nfile_path = '/kaggle/input/pooled-deberta-embeddings/pooled_deberta_embeddings.csv'# from input folder\n\n# Load masked pooled Deberta embeddings\nwith open('/kaggle/input/masked-pooled-deberta-embeddings/mask_pooled_deberta_embeddings.pkl', 'rb') as f:\n    loaded_array = pickle.load(f)\n    \n# Save a csv file\n# df_to_save = df_with_embeddings['pooled_roberta_embedding'].apply(lambda x: ','.join(map(str, x)))\n# df_to_save.to_csv(file_path, index=False)\n\n# Load embeddings\nX_train_preprocessed = pd.read_csv(file_path)\n\nX_train_preprocessed['embeddings'] = X_train_preprocessed['embeddings'].apply(lambda x: list(map(float, x.split(','))))\nX_train_preprocessed['masked_embeddings'] = loaded_array.tolist()","metadata":{"papermill":{"duration":0.032352,"end_time":"2024-05-16T15:40:24.229783","exception":false,"start_time":"2024-05-16T15:40:24.197431","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T16:50:51.175416Z","iopub.execute_input":"2024-05-20T16:50:51.175627Z","iopub.status.idle":"2024-05-20T16:50:53.997746Z","shell.execute_reply.started":"2024-05-20T16:50:51.175603Z","shell.execute_reply":"2024-05-20T16:50:53.996858Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Compile the model (add loss, optimizer, metrics)\n\n# The loss function\ndef mcrmse(y_true, y_pred):\n    columnwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=0)\n    return tf.reduce_mean(tf.sqrt(columnwise_mse), axis=-1)\n\ninitial_learning_rate = 0.00015\n\n# log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n","metadata":{"papermill":{"duration":0.032128,"end_time":"2024-05-16T15:40:24.400490","exception":false,"start_time":"2024-05-16T15:40:24.368362","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T16:07:46.524585Z","iopub.execute_input":"2024-05-20T16:07:46.524808Z","iopub.status.idle":"2024-05-20T16:07:46.529903Z","shell.execute_reply.started":"2024-05-20T16:07:46.524784Z","shell.execute_reply":"2024-05-20T16:07:46.529174Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#pay attention to decay_steps size\nlr_schedule = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate, decay_steps=10000)\n\n# NN with embeddings preprocessed\ndef create_model():\n    input_shape = len(X_train_preprocessed['masked_embeddings'][0])\n\n    input_layer = keras.Input(shape=(input_shape, ), dtype='float32')\n    \n    layer_norm = layers.LayerNormalization(name='layer_norm1')(input_layer)\n    \n    reshape_input_layer = layers.Reshape((1,input_shape), name='reshape_layer')(layer_norm)\n    \n    LSTM_layer = layers.LSTM(512, return_sequences=True, name='LSTM_layer1', activation='linear')(reshape_input_layer)\n    \n    layer_norm = layers.LayerNormalization(name='layer_norm2')(LSTM_layer)\n    \n    act = layers.Activation(keras.activations.tanh, name='tanh1')(layer_norm)\n    \n    LSTM_layer = layers.LSTM(32, return_sequences=False, name='LSTM_layer2', activation='linear',)(act)\n    \n    layer_norm = layers.LayerNormalization(name='layer_norm3')(LSTM_layer)\n    \n    act = layers.Activation(keras.activations.tanh, name='tanh2')(layer_norm)\n    \n    hidden_layer = layers.Dense(16, activation='linear', name='dense_layer')(act)\n    \n    dropout = layers.Dropout(0.3, name='dropout_layer')(hidden_layer)\n    \n    # batch_norm = layers.BatchNormalization(name='batch_norm')(dropout)\n\n    output_layer = layers.Dense(2, activation='linear', name='output_layer')(dropout)\n    \n    model = keras.Model(inputs=input_layer, outputs=output_layer)\n\n    for layer in model.layers:\n        layer.trainable = True\n        \n    \n    opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n    model.compile(loss=mcrmse, optimizer=opt)\n    \n    return model\n\nmodel = create_model()\nmodel.summary()","metadata":{"papermill":{"duration":0.033231,"end_time":"2024-05-16T15:40:24.458629","exception":false,"start_time":"2024-05-16T15:40:24.425398","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T16:27:29.011016Z","iopub.execute_input":"2024-05-20T16:27:29.011264Z","iopub.status.idle":"2024-05-20T16:27:29.241008Z","shell.execute_reply.started":"2024-05-20T16:27:29.011240Z","shell.execute_reply":"2024-05-20T16:27:29.240211Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_13\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_norm1                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m2,048\u001b[0m │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reshape_layer (\u001b[38;5;33mReshape\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ LSTM_layer1 (\u001b[38;5;33mLSTM\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │     \u001b[38;5;34m3,147,776\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_norm2                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ tanh1 (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ LSTM_layer2 (\u001b[38;5;33mLSTM\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m69,760\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_norm3                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ tanh2 (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_layer (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_layer (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m34\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_norm1                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reshape_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ LSTM_layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,147,776</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_norm2                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ tanh1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ LSTM_layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">69,760</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_norm3                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ tanh2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,221,234\u001b[0m (12.29 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,221,234</span> (12.29 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,221,234\u001b[0m (12.29 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,221,234</span> (12.29 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"ckptcb = keras.callbacks.ModelCheckpoint(\n    \"best_model\" + \".weights.h5\",\n    monitor=\"loss\",\n    save_best_only=True,\n    save_weights_only=True,\n    mode=\"min\",\n)    \n    \nhistory = model.fit(x=X_train_input,\n                    y=Y_train_np,\n                    epochs=25,\n                    batch_size=4,\n                    callbacks=[ckptcb],\n                    verbose=2)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T16:30:22.093953Z","iopub.execute_input":"2024-05-20T16:30:22.094604Z","iopub.status.idle":"2024-05-20T16:32:29.088424Z","shell.execute_reply.started":"2024-05-20T16:30:22.094572Z","shell.execute_reply":"2024-05-20T16:32:29.087716Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/25\n1792/1792 - 9s - 5ms/step - loss: 0.5971\nEpoch 2/25\n1792/1792 - 5s - 3ms/step - loss: 0.5268\nEpoch 3/25\n1792/1792 - 5s - 3ms/step - loss: 0.5059\nEpoch 4/25\n1792/1792 - 5s - 3ms/step - loss: 0.4832\nEpoch 5/25\n1792/1792 - 5s - 3ms/step - loss: 0.4767\nEpoch 6/25\n1792/1792 - 5s - 3ms/step - loss: 0.4666\nEpoch 7/25\n1792/1792 - 5s - 3ms/step - loss: 0.4664\nEpoch 8/25\n1792/1792 - 5s - 3ms/step - loss: 0.4670\nEpoch 9/25\n1792/1792 - 5s - 3ms/step - loss: 0.4622\nEpoch 10/25\n1792/1792 - 5s - 3ms/step - loss: 0.4635\nEpoch 11/25\n1792/1792 - 5s - 3ms/step - loss: 0.4655\nEpoch 12/25\n1792/1792 - 5s - 3ms/step - loss: 0.4639\nEpoch 13/25\n1792/1792 - 5s - 3ms/step - loss: 0.4643\nEpoch 14/25\n1792/1792 - 5s - 3ms/step - loss: 0.4645\nEpoch 15/25\n1792/1792 - 5s - 3ms/step - loss: 0.4645\nEpoch 16/25\n1792/1792 - 5s - 3ms/step - loss: 0.4671\nEpoch 17/25\n1792/1792 - 5s - 3ms/step - loss: 0.4667\nEpoch 18/25\n1792/1792 - 5s - 3ms/step - loss: 0.4660\nEpoch 19/25\n1792/1792 - 5s - 3ms/step - loss: 0.4649\nEpoch 20/25\n1792/1792 - 5s - 3ms/step - loss: 0.4628\nEpoch 21/25\n1792/1792 - 5s - 3ms/step - loss: 0.4651\nEpoch 22/25\n1792/1792 - 5s - 3ms/step - loss: 0.4636\nEpoch 23/25\n1792/1792 - 5s - 3ms/step - loss: 0.4644\nEpoch 24/25\n1792/1792 - 5s - 3ms/step - loss: 0.4644\nEpoch 25/25\n1792/1792 - 5s - 3ms/step - loss: 0.4648\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train_input = np.array(X_train_preprocessed['masked_embeddings'].tolist())\nY_train = tf.constant(train[['content', 'wording']].values, dtype=tf.float32)\n\n# Initialize the KFold object\nkf = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n\n# Initialize an empty list to store the validation losses\nval_losses = []\nhistories = []\n\nY_train_np = Y_train.numpy()\n\n# Iterate over each fold\ni = 0\nfor train_index, val_index in kf.split(X_train_input, Y_train_np):\n    \n    print(f\"Fold {i + 1}\")\n    i += 1\n    \n    # Split data into training and validation sets\n    X_train_fold, X_val_fold = X_train_input[train_index], X_train_input[val_index]\n    Y_train_fold, Y_val_fold = Y_train_np[train_index], Y_train_np[val_index]\n    \n    # Create and compile your model\n    model = create_model()\n    # model.load_weights('/kaggle/input/best-weights/best.weights.h5')\n#     opt = keras.optimizers.Adam(learning_rate=initial_learning_rate)\n#     model.compile(loss=mcrmse, optimizer=opt)\n    \n    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n\n                \n    # Train the model\n    \n    # Get the validation loss from the last epoch\n    val_loss = min(history.history['val_loss'])\n    val_losses.append(val_loss)\n    histories.append(history)\n    print()\n\n# Calculate the mean validation loss\nmean_val_loss = np.mean(val_losses)\nprint(\"Mean Validation Loss:\", mean_val_loss)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T16:28:56.253132Z","iopub.execute_input":"2024-05-20T16:28:56.253699Z","iopub.status.idle":"2024-05-20T16:28:57.850232Z","shell.execute_reply.started":"2024-05-20T16:28:56.253667Z","shell.execute_reply":"2024-05-20T16:28:57.849497Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Fold 1\n\nFold 2\n\nFold 3\n\nFold 4\n\nFold 5\n\nMean Validation Loss: 0.4253554344177246\n","output_type":"stream"}]},{"cell_type":"code","source":"# Extracting training history\nfor i, history in enumerate(histories):\n    train_losses = history.history['loss']\n    val_losses = history.history['val_loss']\n    epochs = range(1, len(train_losses) + 1)\n\n    # Plotting losses\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, train_losses, 'b', label='Training loss')\n    plt.plot(epochs, val_losses, 'r', label='Validation loss')\n    plt.title(f'Training and Validation Loss Fold {i + 1}')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#build our NN on top of Deberta\n# Create a layer that wraps the pre trained model to support Keras library\nclass PreTrainedModel(keras.Model):\n    def __init__(self, pre_trained_model, trainable=True, num_layers_to_freeze=-1, **kwargs):\n        super().__init__(**kwargs)\n        self.pre_trained_model = pre_trained_model\n        self.trainable = trainable\n        self.num_layers_to_freeze = num_layers_to_freeze\n\n        # if equal to -1 freeze all layers\n        if num_layers_to_freeze == -1:\n            layers = self.pre_trained_model.layers[0].encoder.layer\n        else:\n            layers = self.pre_trained_model.layers[0].encoder.layer[:self.num_layers_to_freeze]\n            \n        self.pre_trained_model.trainable = self.trainable\n        if self.trainable:\n            for layer in layers:\n                layer.trainable = False\n                \n        # Dynamically create properties from pre-trained model\n#         for prop_name, prop in inspect.getmembers(self.pre_trained_model):\n#             if not prop_name.startswith('_') and not inspect.ismethod(prop):\n#                 setattr(self.__class__, prop_name, prop)\n\n    def call(self, input_ids, attention_mask):\n        # Call the pre trained model and get the last hidden state\n        output = self.pre_trained_model(input_ids=input_ids, attention_mask=attention_mask)\n        return output[0]\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-20T17:53:12.719365Z","iopub.execute_input":"2024-05-20T17:53:12.719670Z","iopub.status.idle":"2024-05-20T17:53:12.727516Z","shell.execute_reply.started":"2024-05-20T17:53:12.719631Z","shell.execute_reply":"2024-05-20T17:53:12.726607Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2024-05-20T17:01:04.654431Z","iopub.execute_input":"2024-05-20T17:01:04.655182Z","iopub.status.idle":"2024-05-20T17:01:04.662272Z","shell.execute_reply.started":"2024-05-20T17:01:04.655147Z","shell.execute_reply":"2024-05-20T17:01:04.661323Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"{'input_ids': <tf.Tensor: shape=(7165, 1575), dtype=int32, numpy=\narray([[    1,   589, 56195, ...,     0,     0,     0],\n       [    1,   589, 56195, ...,     0,     0,     0],\n       [    1,   589, 56195, ...,     0,     0,     0],\n       ...,\n       [    1, 56299,   292, ...,     0,     0,     0],\n       [    1, 56299,   292, ...,     0,     0,     0],\n       [    1, 56299,   292, ...,     0,     0,     0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(7165, 1575), dtype=int32, numpy=\narray([[1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       ...,\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}"},"metadata":{}}]},{"cell_type":"code","source":"deberta = pre_trained_model(input_ids=X_train['input_ids'][:1], attention_mask=X_train['attention_mask'][:1])[0]\nprint(deberta.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T17:02:49.192638Z","iopub.execute_input":"2024-05-20T17:02:49.193166Z","iopub.status.idle":"2024-05-20T17:02:54.741058Z","shell.execute_reply.started":"2024-05-20T17:02:49.193136Z","shell.execute_reply":"2024-05-20T17:02:54.740213Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"(1, 1575, 1024)\n","output_type":"stream"}]},{"cell_type":"code","source":"#pay attention to decay_steps size\nlr_schedule = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate, decay_steps=10000)\n\n# NN with embeddings preprocessed\ndef create_model():\n    input_shape = (1575,)\n\n    input_ids = keras.Input(shape=input_shape, dtype='int32')\n    \n    attention_mask = keras.Input(shape=input_shape, dtype='int32')\n    \n    head_mask = keras.Input(shape=input_shape, dtype='float32', name='head_mask')\n    \n    deberta = PreTrainedModel(pre_trained_model)(input_ids, attention_mask)\n    \n    h_mask = layers.Lambda(lambda x: tf.expand_dims(tf.cast(x, dtype=tf.float32), axis=-1))(head_mask)\n    masked_outputs = layers.Lambda(lambda x,y: tf.multiply(x, y), output_shape=(1575, 1024))(deberta, h_mask)\n    \n    avg_pooling = layers.GlobalAveragePooling1D()(masked_outputs)\n    \n    # Our NN\n    layer_norm = layers.LayerNormalization(name='layer_norm1')(avg_pooling)\n    \n    reshape_input_layer = layers.Reshape((1,input_shape), name='reshape_layer')(layer_norm)\n    \n    LSTM_layer = layers.LSTM(512, return_sequences=True, name='LSTM_layer1', activation='linear')(reshape_input_layer)\n    \n    layer_norm = layers.LayerNormalization(name='layer_norm2')(LSTM_layer)\n    \n    act = layers.Activation(keras.activations.tanh, name='tanh1')(layer_norm)\n    \n    LSTM_layer = layers.LSTM(32, return_sequences=False, name='LSTM_layer2', activation='linear',)(act)\n    \n    layer_norm = layers.LayerNormalization(name='layer_norm3')(LSTM_layer)\n    \n    act = layers.Activation(keras.activations.tanh, name='tanh2')(layer_norm)\n    \n    hidden_layer = layers.Dense(16, activation='linear', name='dense_layer')(act)\n    \n    dropout = layers.Dropout(0.3, name='dropout_layer')(hidden_layer)\n    \n    # batch_norm = layers.BatchNormalization(name='batch_norm')(dropout)\n\n    output_layer = layers.Dense(2, activation='linear', name='output_layer')(dropout)\n    \n    model = keras.Model(inputs=input_layer, outputs=output_layer)\n\n    for layer in model.layers:\n        layer.trainable = True\n        \n    \n    opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n    model.compile(loss=mcrmse, optimizer=opt)\n    \n    return model\n\nmodel = create_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-05-20T17:59:30.455711Z","iopub.execute_input":"2024-05-20T17:59:30.456295Z","iopub.status.idle":"2024-05-20T17:59:51.413560Z","shell.execute_reply.started":"2024-05-20T17:59:30.456259Z","shell.execute_reply":"2024-05-20T17:59:51.412397Z"},"trusted":true},"execution_count":39,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[39], line 57\u001b[0m\n\u001b[1;32m     53\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mmcrmse, optimizer\u001b[38;5;241m=\u001b[39mopt)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m---> 57\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n","Cell \u001b[0;32mIn[39], line 24\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Our NN\u001b[39;00m\n\u001b[1;32m     22\u001b[0m layer_norm \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mLayerNormalization(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer_norm1\u001b[39m\u001b[38;5;124m'\u001b[39m)(avg_pooling)\n\u001b[0;32m---> 24\u001b[0m reshape_input_layer \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape_layer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_norm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m LSTM_layer \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mLSTM(\u001b[38;5;241m512\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM_layer1\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m)(reshape_input_layer)\n\u001b[1;32m     28\u001b[0m layer_norm \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mLayerNormalization(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer_norm2\u001b[39m\u001b[38;5;124m'\u001b[39m)(LSTM_layer)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/ops/operation_utils.py:295\u001b[0m, in \u001b[0;36mcompute_reshape_output_shape\u001b[0;34m(input_shape, newshape, newshape_arg_name)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unknown_dim_count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_size \u001b[38;5;241m!=\u001b[39m math\u001b[38;5;241m.\u001b[39mprod(newshape):\n\u001b[0;32m--> 295\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe total size of the tensor must be unchanged. Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnewshape_arg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnewshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m         )\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m newshape\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# We have one -1 in `newshape`, compute the actual value\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: The total size of the tensor must be unchanged. Received: input_shape=(1024,), target_shape=(1, (1575,))"],"ename":"ValueError","evalue":"The total size of the tensor must be unchanged. Received: input_shape=(1024,), target_shape=(1, (1575,))","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}