{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":53482,"databundleVersionId":6201832,"sourceType":"competition"},{"sourceId":2977194,"sourceType":"datasetVersion","datasetId":1825054},{"sourceId":6258399,"sourceType":"datasetVersion","datasetId":3596984},{"sourceId":8139549,"sourceType":"datasetVersion","datasetId":4812209},{"sourceId":8139552,"sourceType":"datasetVersion","datasetId":4812212},{"sourceId":8141507,"sourceType":"datasetVersion","datasetId":4813598},{"sourceId":8146152,"sourceType":"datasetVersion","datasetId":4817190},{"sourceId":8469314,"sourceType":"datasetVersion","datasetId":5049859},{"sourceId":8507789,"sourceType":"datasetVersion","datasetId":5078374},{"sourceId":8558953,"sourceType":"datasetVersion","datasetId":5115575},{"sourceId":8565128,"sourceType":"datasetVersion","datasetId":5120491},{"sourceId":8579511,"sourceType":"datasetVersion","datasetId":5130807},{"sourceId":8583556,"sourceType":"datasetVersion","datasetId":5133543},{"sourceId":8642912,"sourceType":"datasetVersion","datasetId":5176303},{"sourceId":8642927,"sourceType":"datasetVersion","datasetId":5118268},{"sourceId":8656067,"sourceType":"datasetVersion","datasetId":5013476}],"dockerImageVersionId":30665,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":109.119668,"end_time":"2024-05-16T15:40:29.014408","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-05-16T15:38:39.894740","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"059a11eda62448da981f7b2667b94637":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d4e90cc3beb40b890ffd3978dfb22d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"150f7c2a80124dad8408945c7c4a0fce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15104f9159d1410eb85b6379bc0756c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff9e6813dd3d499f8c44902f3806b49c","IPY_MODEL_588ef8f9110e4ba8897785a7816b52a6","IPY_MODEL_afa499e764d4423fbc616d6a8de52fd0"],"layout":"IPY_MODEL_deefef886f9c43cf88f6f162100f2e3e"}},"1982a9459b644ddf93b0670b17ed6427":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b2c1961d94c4a07b162c8e1f1f4ea8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e281edfb4944800b70ca3e7b078cd13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f7d29516b7a46dcb0fa01415173e1df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"25126573d458497987981721450a08ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c8166010478471ebcfeaff488254cc3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ed7fd040a494b91bcb6b11bf17446a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c55a6f3b2d6453d92734e1c2c6ccf3d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f8ee3fcf5ed47f08eb3eeaff0647d5e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42cdc6d0d53e4ab298128b8581bf4c3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c8166010478471ebcfeaff488254cc3","placeholder":"​","style":"IPY_MODEL_059a11eda62448da981f7b2667b94637","value":" 2.46M/2.46M [00:00&lt;00:00, 3.68MB/s]"}},"464d8379cbd842b6b0c919aa12c237ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1982a9459b644ddf93b0670b17ed6427","placeholder":"​","style":"IPY_MODEL_a0ed8c5740e846b7912490fe3541991c","value":"spm.model: 100%"}},"57d07143c3b54fb2baad23f96e0874aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"588ef8f9110e4ba8897785a7816b52a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d4e90cc3beb40b890ffd3978dfb22d8","max":1736592160,"min":0,"orientation":"horizontal","style":"IPY_MODEL_150f7c2a80124dad8408945c7c4a0fce","value":1736592160}},"640eb7d806d7408ba3ba560fa99b9142":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73ed4c4fc9104779b8fdb3fc52e64f4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa4f2028d4be4adfb1389b240b2c7ee0","placeholder":"​","style":"IPY_MODEL_cd53dfa32e15440aadac97ed88dbec02","value":" 580/580 [00:00&lt;00:00, 52.0kB/s]"}},"76c12b9e7502419da6c5d8afae0b45ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eb63820b62d49ea9bc8059798aabfb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_464d8379cbd842b6b0c919aa12c237ad","IPY_MODEL_d006714a85f746a2a1485b6e1faf7003","IPY_MODEL_42cdc6d0d53e4ab298128b8581bf4c3a"],"layout":"IPY_MODEL_25126573d458497987981721450a08ae"}},"999bd4cca8c94c3a8c59da5cb58d8c2e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ae4657f98844aa686e0a73f6bb69972":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_efc7d8e9f3cc457f93faf7367ab86cd3","IPY_MODEL_f37802e035ff44d181776f86eabe948d","IPY_MODEL_a915e75f5ed847a7b44823aadb68b8e3"],"layout":"IPY_MODEL_9cc123d4a6da4ac9bf37029593171ca6"}},"9cc123d4a6da4ac9bf37029593171ca6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d8022fde15349cf92f52a24eac326ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0ed8c5740e846b7912490fe3541991c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a915e75f5ed847a7b44823aadb68b8e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_640eb7d806d7408ba3ba560fa99b9142","placeholder":"​","style":"IPY_MODEL_1e281edfb4944800b70ca3e7b078cd13","value":" 52.0/52.0 [00:00&lt;00:00, 4.37kB/s]"}},"aa1ceb8e11cc412ea3062b14dcb51319":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3852559827e4748844d3b2927447926","max":580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b2c1961d94c4a07b162c8e1f1f4ea8f","value":580}},"aa4f2028d4be4adfb1389b240b2c7ee0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad398d8a95ab459abdfa03879da117ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afa499e764d4423fbc616d6a8de52fd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8b1ba7cf2354528ab658faf56c8985f","placeholder":"​","style":"IPY_MODEL_c4ef64c1429c4d049c4b952e1906bf5e","value":" 1.74G/1.74G [00:41&lt;00:00, 42.6MB/s]"}},"b3852559827e4748844d3b2927447926":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba8f192523cf4f3d81fe72f0c6b16060":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4ef64c1429c4d049c4b952e1906bf5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cae13970055a44a09fbe31e19911087a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76c12b9e7502419da6c5d8afae0b45ab","placeholder":"​","style":"IPY_MODEL_2ed7fd040a494b91bcb6b11bf17446a7","value":"config.json: 100%"}},"cd53dfa32e15440aadac97ed88dbec02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cde68addf7004559a03c89e3c5cd5070":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d006714a85f746a2a1485b6e1faf7003":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba8f192523cf4f3d81fe72f0c6b16060","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57d07143c3b54fb2baad23f96e0874aa","value":2464616}},"deefef886f9c43cf88f6f162100f2e3e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8b1ba7cf2354528ab658faf56c8985f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efc7d8e9f3cc457f93faf7367ab86cd3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f8ee3fcf5ed47f08eb3eeaff0647d5e","placeholder":"​","style":"IPY_MODEL_cde68addf7004559a03c89e3c5cd5070","value":"tokenizer_config.json: 100%"}},"f37802e035ff44d181776f86eabe948d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c55a6f3b2d6453d92734e1c2c6ccf3d","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f7d29516b7a46dcb0fa01415173e1df","value":52}},"f37f807ded5e4af5a607d3a76b4de99f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cae13970055a44a09fbe31e19911087a","IPY_MODEL_aa1ceb8e11cc412ea3062b14dcb51319","IPY_MODEL_73ed4c4fc9104779b8fdb3fc52e64f4e"],"layout":"IPY_MODEL_9d8022fde15349cf92f52a24eac326ed"}},"ff9e6813dd3d499f8c44902f3806b49c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_999bd4cca8c94c3a8c59da5cb58d8c2e","placeholder":"​","style":"IPY_MODEL_ad398d8a95ab459abdfa03879da117ba","value":"tf_model.h5: 100%"}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nimport warnings\nimport logging\nimport pickle\nimport inspect\nimport os\nimport gc\nimport math\n\n# disabling unnecceseray warnings\nwarnings.simplefilter(\"ignore\")\nlogging.disable(logging.ERROR)\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nimport tensorflow as tf\nfrom transformers import TFAutoModel, AutoTokenizer\nfrom tensorflow import keras\nfrom keras import layers\nimport datetime\nfrom keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom keras import regularizers\nfrom typing import List\nimport shutil\nimport json\nfrom tqdm import tqdm\nimport nltk\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nimport spacy\nimport re\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor, log_evaluation, early_stopping\nfrom sklearn.metrics import mean_squared_error\nimport polars as pl\nimport spacy\nimport re\nimport string\nimport inspect\ntqdm.pandas()\n\n\nkeras.mixed_precision.set_global_policy(\"mixed_float16\")\n\n# Limit the GPU memory growth using TensorFlow\n# physical_devices = tf.config.list_physical_devices('GPU')\n# if len(physical_devices) > 0:\n#     tf.config.experimental.set_memory_growth(physical_devices[0], True)\n    # tf.config.experimental.set_memory_growth(physical_devices[1], True)\n\nimport random\n# Set random seeds\nrandom_seed = 42\nnp.random.seed(random_seed)\ntf.random.set_seed(random_seed)\nrandom.seed(random_seed)\nkeras.utils.set_random_seed(random_seed)\n\n# !pip install /kaggle/input/autocorrect/autocorrect-2.6.1.tar\n# from autocorrect import Speller\n# spell = Speller(lang='en', fast=True)\n\n!pip install /kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\nfrom spellchecker import SpellChecker\nspellchecker = SpellChecker()","metadata":{"papermill":{"duration":33.079441,"end_time":"2024-05-16T15:39:15.664457","exception":false,"start_time":"2024-05-16T15:38:42.585016","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-20T20:40:16.936634Z","iopub.execute_input":"2024-06-20T20:40:16.937055Z","iopub.status.idle":"2024-06-20T20:41:18.929494Z","shell.execute_reply.started":"2024-06-20T20:40:16.937021Z","shell.execute_reply":"2024-06-20T20:41:18.928287Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-06-20 20:40:20.460240: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-20 20:40:20.460381: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-20 20:40:20.632340: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Processing /kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\nInstalling collected packages: pyspellchecker\nSuccessfully installed pyspellchecker-0.7.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"data_path = '/kaggle/input/commonlit-evaluate-student-summaries/'\n\n# prompts train\ntrain_pro = pd.read_csv(data_path + 'prompts_train.csv')\ntrain_pro.head(1)\n\n# summaries train\ntrain_sum = pd.read_csv(data_path + 'summaries_train.csv')\ntrain_sum.head(1)\n\ntrain = train_pro.merge(train_sum , on = \"prompt_id\")\ntrain.head(1)\n\n# prompts test\ntest_pro = pd.read_csv(data_path + 'prompts_test.csv')\ntest_pro.head(1)\n\n# summaries test\ntest_sum = pd.read_csv(data_path + 'summaries_test.csv')\ntest_sum.head(1)\ntest = test_pro.merge(test_sum , on = \"prompt_id\")\ntest.head()","metadata":{"papermill":{"duration":0.175105,"end_time":"2024-05-16T15:39:15.917548","exception":false,"start_time":"2024-05-16T15:39:15.742443","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-20T20:41:18.931845Z","iopub.execute_input":"2024-06-20T20:41:18.932157Z","iopub.status.idle":"2024-06-20T20:41:19.091306Z","shell.execute_reply.started":"2024-06-20T20:41:18.932122Z","shell.execute_reply":"2024-06-20T20:41:19.090267Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"  prompt_id prompt_question     prompt_title       prompt_text    student_id  \\\n0    abc123    Summarize...  Example Title 1  Heading\\nText...  000000ffffff   \n1    abc123    Summarize...  Example Title 1  Heading\\nText...  222222cccccc   \n2    def789    Summarize...  Example Title 2  Heading\\nText...  111111eeeeee   \n3    def789    Summarize...  Example Title 2  Heading\\nText...  333333dddddd   \n\n             text  \n0  Example text 1  \n1  Example text 3  \n2  Example text 2  \n3  Example text 4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>student_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abc123</td>\n      <td>Summarize...</td>\n      <td>Example Title 1</td>\n      <td>Heading\\nText...</td>\n      <td>000000ffffff</td>\n      <td>Example text 1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abc123</td>\n      <td>Summarize...</td>\n      <td>Example Title 1</td>\n      <td>Heading\\nText...</td>\n      <td>222222cccccc</td>\n      <td>Example text 3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>def789</td>\n      <td>Summarize...</td>\n      <td>Example Title 2</td>\n      <td>Heading\\nText...</td>\n      <td>111111eeeeee</td>\n      <td>Example text 2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>def789</td>\n      <td>Summarize...</td>\n      <td>Example Title 2</td>\n      <td>Heading\\nText...</td>\n      <td>333333dddddd</td>\n      <td>Example text 4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocessing (Full Model)","metadata":{}},{"cell_type":"code","source":"prefix1 = \"Think through this step by step: \"\nprefix2 = \"Pay attention to the content and wording: \"\nMAX_SUMMARY_LENGTH = 1500 + len(prefix1) + len(prefix2)\n\ndef preprocess(summary, prompt_question, prompt_text, tokenizer):\n    \n    sep = f\" {tokenizer.sep_token} \" \n    summary = prefix1 + prompt_question + sep + prefix2 + summary + sep + prompt_text\n    tokenized = tokenizer.batch_encode_plus(summary.tolist(),\n                                              add_special_tokens=False,\n                                              truncation=True,\n                                              padding='max_length',\n                                              return_tensors='tf',\n                                              max_length=MAX_SUMMARY_LENGTH,\n                                              return_attention_mask=True)\n    \n    input_ids = tokenized['input_ids']\n    attention_mask = tokenized['attention_mask']\n\n    # Create head mask\n    head_mask = np.zeros(input_ids.shape)\n    for i, summ in enumerate(input_ids.numpy()):\n        use_full = False\n        for j, token in enumerate(summ):\n            if token == tokenizer.sep_token_id:\n                use_full = not use_full  \n            head_mask[i][j] = (1. if use_full else 0.) \n    head_mask = tf.constant(head_mask)\n    \n    return input_ids, attention_mask, head_mask\n\ndef build_dataset(summaries, prompt_questions, prompt_texts, tokenizer):    \n    # Tokenization\n    input_ids, attention_mask, head_mask = preprocess(summaries, prompt_questions, prompt_texts, tokenizer)\n    return [input_ids.numpy(), attention_mask.numpy(), head_mask.numpy()]","metadata":{"execution":{"iopub.status.busy":"2024-06-20T11:27:51.266282Z","iopub.execute_input":"2024-06-20T11:27:51.266522Z","iopub.status.idle":"2024-06-20T11:27:51.276416Z","shell.execute_reply.started":"2024-06-20T11:27:51.266490Z","shell.execute_reply":"2024-06-20T11:27:51.275504Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# # Check head mask of first prompt (for debug)\n\n\n# ids, mask, head = build_dataset(train['text'], train['prompt_question'], train['prompt_text'])\n# train['input'] = prefix1 + train['prompt_question'] + sep + prefix2 + train['text'] + sep + train['prompt_text']\n# first = tokenizer.tokenize(train['input'][0],                                               \n#           add_special_tokens=False,\n#           truncation=True,\n#           padding='max_length',\n#           return_tensors='tf',\n#           max_length=MAX_SUMMARY_LENGTH,\n#           return_attention_mask=False)\n\n# def find_indexes(array):\n#     return [index for index, value in enumerate(array) if value == 1]\n# np.array(first)[find_indexes(head[0])]","metadata":{"execution":{"iopub.status.busy":"2024-06-19T20:29:22.847949Z","iopub.execute_input":"2024-06-19T20:29:22.848151Z","iopub.status.idle":"2024-06-19T20:29:22.859969Z","shell.execute_reply.started":"2024-06-19T20:29:22.848124Z","shell.execute_reply":"2024-06-19T20:29:22.859108Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Define Full Model","metadata":{}},{"cell_type":"code","source":"# build our NN on top of Deberta\n\n# Create a layer that wraps the pre trained model to support Keras library\nclass PreTrainedModel(keras.Model):\n    def __init__(self, model_path, trainable=False, num_layers_to_freeze=8, name=None, **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.model = TFAutoModel.from_pretrained(model_path + \"model\") \n        self.tokenizer = AutoTokenizer.from_pretrained(model_path + \"tokenizer\")\n        self.trainable = trainable\n        self.num_layers_to_freeze = num_layers_to_freeze\n        \n        # define model configurations\n        self.model.trainable = self.trainable\n        self.model.config.hidden_dropout_prob = 0.0\n        self.model.config.attention_probs_dropout_prob = 0.0\n        \n        # freeze layers if trainable\n        if self.trainable:\n            self.model.trainable = self.trainable\n            if self.trainable:\n                for layer in self.model.layers[0].encoder.layer[:self.num_layers_to_freeze]:\n                    layer.trainable = False\n\n        # Dynamically create properties from pre-trained model\n        # for prop_name, prop in inspect.getmembers(self.model):\n        #    if not prop_name.startswith('_') and not inspect.ismethod(prop):\n        #        setattr(self.__class__, prop_name, prop)\n\n    def call(self, input_ids, attention_mask):\n        # Call the pre trained model and get the last hidden state\n        output = self.model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n        return output.hidden_states","metadata":{"execution":{"iopub.status.busy":"2024-06-20T11:27:51.278455Z","iopub.execute_input":"2024-06-20T11:27:51.278656Z","iopub.status.idle":"2024-06-20T11:27:51.290564Z","shell.execute_reply.started":"2024-06-20T11:27:51.278634Z","shell.execute_reply":"2024-06-20T11:27:51.289819Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# The loss function\ndef mcrmse(y_true, y_pred):\n    y_true = tf.cast(y_true, tf.float16)\n    y_pred = tf.cast(y_pred, tf.float16)\n    columnwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=0)\n    return tf.reduce_mean(tf.sqrt(columnwise_mse), axis=-1)","metadata":{"papermill":{"duration":0.032128,"end_time":"2024-05-16T15:40:24.400490","exception":false,"start_time":"2024-05-16T15:40:24.368362","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-20T11:27:51.291480Z","iopub.execute_input":"2024-06-20T11:27:51.291649Z","iopub.status.idle":"2024-06-20T11:27:51.302406Z","shell.execute_reply.started":"2024-06-20T11:27:51.291630Z","shell.execute_reply":"2024-06-20T11:27:51.301679Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# HyperParameters\ninit_lr = 0.00015\nbatch_size = 4\nepochs = 4","metadata":{"execution":{"iopub.status.busy":"2024-06-20T11:27:51.303445Z","iopub.execute_input":"2024-06-20T11:27:51.303686Z","iopub.status.idle":"2024-06-20T11:27:51.310534Z","shell.execute_reply.started":"2024-06-20T11:27:51.303658Z","shell.execute_reply":"2024-06-20T11:27:51.309690Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def create_model(decay_steps=10000, warmup_steps=100, input_shape=(1575,), embeddings_len=1024):\n    \n    # Instances\n    model_path = '/kaggle/input/deberta-v3-large/deberta_v3_large/'\n    pre_trained_model_instance = PreTrainedModel(model_path, name=\"deberta_layer\")\n    expand_dims_instance = layers.Lambda(lambda x: tf.expand_dims(tf.cast(x, dtype=tf.float32), axis=-1), name=f'expand_dims')\n    mask_instance = layers.Lambda(lambda x: tf.multiply(x[0], x[1]), output_shape=(1575, embeddings_len,), name='masked_embeddings')\n    avg_pooling_instance = layers.GlobalAveragePooling1D()\n    reshape_instance1 = layers.Reshape((1, -1), name='reshape_layer1')\n#     reshape_instance2 = layers.Reshape((1, -1), name='reshape_layer2')\n#     dense_instance = layers.Dense(embeddings_len, activation='gelu')\n#     avg_pooling_instance2 = layers.GlobalAveragePooling1D()\n    dropout_instance = layers.Dropout(0.3)\n    \n\n    # The NN starts from here\n    \n    # Input layers\n    input_ids = keras.Input(shape=input_shape, dtype='int32', name='input_ids')\n    attention_mask = keras.Input(shape=input_shape, dtype='int32', name='attention_mask')\n    head_mask = keras.Input(shape=input_shape, dtype='float32', name='head_mask')\n    \n    # Create embeddings and get all hidden states\n    deberta = pre_trained_model_instance(input_ids, attention_mask)\n    \n    # Mask pooling all hidden states of pre-trained model\n    pooled_hidden_states = []\n    num_hidden_layers = 4\n    for layer in deberta[-num_hidden_layers:]:\n        h_mask = expand_dims_instance(head_mask)\n        masked_outputs = mask_instance([dropout_instance(layer), h_mask])\n        avg_pooling_layer = avg_pooling_instance(masked_outputs)\n        reshape_layer = reshape_instance1(avg_pooling_layer)\n        pooled_hidden_states.append(reshape_layer)\n    \n    # Concatenate all the hidden states an forward pass through LSTM\n    x = layers.Concatenate(axis=1)(pooled_hidden_states)\n    x = layers.LSTM(embeddings_len, return_sequences=False)(x)\n    x = layers.Dense(512, activation='linear')(x)\n    x = layers.LayerNormalization()(x)\n    x = layers.Dropout(0.2)(x)\n    x = layers.Activation(keras.activations.gelu, name='gelu')(x)\n    \n    output_layer = layers.Dense(2, activation='linear')(x)\n    \n    # Multi-sample Dropout\n#     x = layers.Dropout(0.3)(x)\n#     dropoutList = [reshape_instance2(avg_pooling_instance2(dense_instance(layers.Dropout((i + 1) * 0.1)(x)))) for i in range(5)]\n#     x = layers.Concatenate(axis=1)(dropoutList)\n#     x = layers.GlobalAveragePooling1D()(x)\n\n    model = keras.Model(inputs=[input_ids, attention_mask, head_mask], outputs=output_layer)\n    lr_schedule = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=init_lr,\n                                                            decay_steps=decay_steps,\n                                                            warmup_target=init_lr,\n                                                            warmup_steps=warmup_steps,\n                                                           )\n    opt = keras.optimizers.AdamW(learning_rate=lr_schedule)\n    model.compile(loss=mcrmse, optimizer=opt)\n    return model, pre_trained_model_instance\n\n# model, deberta_model = create_model()\n# model.summary()\n# model.load_weights(\"/kaggle/input/no-aug-model-weights/no_augmentation_model.weights.h5\")\n# deberta_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Full Model","metadata":{}},{"cell_type":"code","source":"# Choose Training type\ntrain_with_folds = True","metadata":{"execution":{"iopub.status.busy":"2024-06-20T11:28:49.767815Z","iopub.execute_input":"2024-06-20T11:28:49.768028Z","iopub.status.idle":"2024-06-20T11:28:49.772023Z","shell.execute_reply.started":"2024-06-20T11:28:49.768004Z","shell.execute_reply":"2024-06-20T11:28:49.771083Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X = train[['text', 'prompt_question', 'prompt_text']]\ny = train[['content', 'wording']].astype('float16')\n\nif train_with_folds:\n    \n    # Train full model with GroupKFolds\n    gkf = GroupKFold(n_splits=4)\n    folds = gkf.split(X, y, groups=train['prompt_id'])\n\n    val_losses = []\n    histories = []\n\n    for i, (train_index, val_index) in enumerate(folds):\n        print(f\"Fold {i}\")\n        \n        if i != 3:\n             continue\n\n        X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n        y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n\n        decay_steps = math.ceil((len(X_train_fold) / batch_size) * epochs) \n        model, deberta = create_model(decay_steps=decay_steps)\n\n        X_train_fold = build_dataset(X_train_fold['text'], X_train_fold['prompt_question'], X_train_fold['prompt_text'], deberta.tokenizer)\n        X_val_fold = build_dataset(X_val_fold['text'], X_val_fold['prompt_question'], X_val_fold['prompt_text'], deberta.tokenizer)\n\n\n        early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n#         ema = keras.callbacks.SwapEMAWeights(swap_on_epoch=True)\n\n        # Checkpoint callback\n        ckptcb = keras.callbacks.ModelCheckpoint(\n            f\"full_model_fold_{i}\" + \".weights.h5\",\n            monitor=\"val_loss\",\n            save_best_only=True,\n            save_weights_only=True,\n            mode=\"min\",\n        ) \n\n        history = model.fit(x=X_train_fold,\n                            y=y_train_fold.values,\n                            validation_data=(X_val_fold, y_val_fold.values),\n                            epochs=epochs,\n                            batch_size=batch_size,\n                            callbacks=[early_stopping, ckptcb],\n                            verbose=1)\n\n        # Get the validation loss from the last epoch\n        val_loss = min(history.history['val_loss'])\n        val_losses.append(val_loss)\n        histories.append(history)\n        print()\n\n    # Calculate the mean validation loss\n    mean_val_loss = np.mean(val_losses)\n    print(\"Mean Validation Loss:\", mean_val_loss)\n    \n    \nelse:\n    # Train full model no folds all data\n    decay_steps = math.ceil((len(X) / batch_size) * epochs) \n    model, deberta = create_model(decay_steps=decay_steps)\n    \n    X = build_dataset(X['text'], X['prompt_question'], X['prompt_text'], deberta.tokenizer)\n    \n    # Callbacks\n    early_stopping = EarlyStopping(monitor='loss', patience=2, restore_best_weights=True)\n#     ema = keras.callbacks.SwapEMAWeights(swap_on_epoch=True)\n    ckptcb = keras.callbacks.ModelCheckpoint(\n        \"no_augment_full_model\" + \".weights.h5\",\n        monitor=\"loss\",\n        save_best_only=True,\n        save_weights_only=True,\n        mode=\"min\",\n    )    \n    \n    history = model.fit(x=X,\n                        y=y.values,\n                        epochs=epochs,\n                        batch_size=batch_size,\n                        callbacks=[early_stopping, ckptcb],\n                        verbose=1)\nprint('done')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Meta Psuedo Labels Training loop","metadata":{}},{"cell_type":"code","source":"# # loading augmented data\n# augmented_data = pd.read_excel('/kaggle/input/llm-generate-test/LLM_Generate_Test.xlsx')\n# augmented_data.columns = ['student_id', 'prompt_text', 'prompt_question', 'text']\n\n# augmented_data[\"text\"] = augmented_data[\"text\"].apply(lambda x: spell(x))\n# augmented_data['input'] = prefix1 + augmented_data['prompt_question'] + sep + prefix2 + augmented_data['text']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_predictions(model, data):\n    contents = []\n    wordings = []\n    ids = []\n    predictions = model.predict(x=[data['input_ids'], data['attention_mask'], data['head_mask']],\n                                batch_size=4)\n\n    for idx, output in enumerate(predictions):\n        contents.append(output[0])\n        wordings.append(output[1])\n        ids.append(data['student_id'][idx])\n    return ids, contents, wordings","metadata":{"execution":{"iopub.status.busy":"2024-06-19T11:56:41.427255Z","iopub.execute_input":"2024-06-19T11:56:41.427523Z","iopub.status.idle":"2024-06-19T11:56:41.434131Z","shell.execute_reply.started":"2024-06-19T11:56:41.427496Z","shell.execute_reply":"2024-06-19T11:56:41.433117Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# # Tokenizing augmented data\n# tokenized_summaries_aug = tokenizer.batch_encode_plus(augmented_data['input'].tolist(),\n#                                               add_special_tokens=True,\n#                                               truncation=True,\n#                                               padding='max_length',\n#                                               return_tensors='tf',\n#                                               max_length=MAX_SUMMARY_LENGTH,\n#                                               return_attention_mask = True)\n# del tokenized_summaries_aug['token_type_ids']\n\n# # Create head mask that excludes anything but sep + prefix2 + train['text']\n# head_mask_aug = np.zeros(tokenized_summaries_aug['input_ids'].shape)\n# for i, summary in enumerate(tokenized_summaries_aug['input_ids'].numpy()):\n#     use_full = False\n#     for j, token in enumerate(summary):\n#         if token == tokenizer.sep_token_id:\n#             use_full = not use_full\n#         head_mask_aug[i][j] = (1 if use_full else 0) \n# head_mask_aug = tf.constant(head_mask_aug)\n\n# aug_input = {\n#     'input_ids': tokenized_summaries_aug['input_ids'],\n#     'attention_mask': tokenized_summaries_aug['attention_mask'],\n#     'head_mask': head_mask_aug,\n#     'student_id': augmented_data['student_id']\n# }","metadata":{"execution":{"iopub.status.busy":"2024-06-07T21:36:25.314476Z","iopub.execute_input":"2024-06-07T21:36:25.314661Z","iopub.status.idle":"2024-06-07T21:39:50.714377Z","shell.execute_reply.started":"2024-06-07T21:36:25.314637Z","shell.execute_reply":"2024-06-07T21:39:50.713567Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# ROUNDS = 3\n# SAVED_DATASETS_INDEXES = [0, 1, 2]\n# SAVED_WEIGHTS_INDEXES = [0, 1, 2]\n\n# # the initial model\n# model, _ = create_model()\n\n# if SAVED_WEIGHTS_INDEXES[-1] == 0:\n#     model.load_weights('/kaggle/input/no-aug-model-weights/no_augmentation_model.weights.h5')\n# else:\n#     print(f\"Loading weights: meta_model_{SAVED_WEIGHTS_INDEXES[-1]}\")\n#     model.load_weights(f'/kaggle/input/meta-model-weights/meta_model_{SAVED_WEIGHTS_INDEXES[-1]}.weights.h5')\n\n# Y_train = tf.constant(train[['content', 'wording']].values, dtype=tf.float32)\n# Y_train = Y_train.numpy()\n\n# for i in range(ROUNDS):\n            \n#     print(f\"Round {i + 1}/{ROUNDS}\")\n    \n#     if i < SAVED_WEIGHTS_INDEXES[-1]:\n#         continue\n    \n#     # predict meta psuedo labels\n    \n#     if i in SAVED_DATASETS_INDEXES:\n#         # predictions already generated\n#         if i == 0:\n#             augmented_labeled_data = pd.read_csv('/kaggle/input/augmented-labeled-data/augmented_labeled_data.csv')\n#         else:\n#             augmented_labeled_data = pd.read_csv(f'/kaggle/input/augmented-labeled-data/augmented_labeled_data_round_{i + 1}.csv')\n#     else:\n#         print()\n#         print(f\"Generateing predictions...\")\n#         ids, contents, wordings = generate_predictions(model, aug_input)\n#         augmented_data['content'] = contents\n#         augmented_data['wording'] = wordings\n#         augmented_data.to_csv(f\"augmented_labeled_data_round_{i + 1}.csv\")\n#         augmented_labeled_data = augmented_data\n        \n#     # update the labels    \n#     Y_train_aug = tf.constant(augmented_labeled_data[['content', 'wording']].values, dtype=tf.float32)\n#     Y_train_aug = Y_train_aug.numpy()\n\n#     # checkpoint callback\n#     ckptcb = keras.callbacks.ModelCheckpoint(\n#         f\"meta_model_{i + 1}\" + \".weights.h5\",\n#         monitor=\"loss\",\n#         save_best_only=True,\n#         save_weights_only=True,\n#         mode=\"min\",\n#     )\n    \n#     print()\n#     print(f\"Training on unlabeled data...\")\n#     model.fit(x=[tokenized_summaries_aug['input_ids'], tokenized_summaries_aug['attention_mask'], head_mask_aug],\n#                       y=Y_train_aug,\n#                       epochs=2,\n#                       batch_size=4,\n#                       validation_data=([tokenized_summaries['input_ids'], tokenized_summaries['attention_mask'], head_mask], Y_train),\n#                       verbose=1)\n    \n#     # Fine tune the pre-trained model only on the labeled data\n#     print()\n#     print(f\"Training on labeled data...\")\n#     model.fit(x=[tokenized_summaries['input_ids'], tokenized_summaries['attention_mask'], head_mask],\n#                       y=Y_train,\n#                       epochs=3,\n#                       batch_size=4,\n#                       callbacks=[ckptcb],\n#                       verbose=1)\n#     print()","metadata":{"execution":{"iopub.status.busy":"2024-06-07T21:55:43.444684Z","iopub.execute_input":"2024-06-07T21:55:43.444956Z","iopub.status.idle":"2024-06-08T09:06:36.886494Z","shell.execute_reply.started":"2024-06-07T21:55:43.444926Z","shell.execute_reply":"2024-06-08T09:06:36.885217Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Loading weights: meta_model_1\nRound 1/3\nRound 2/3\n\nGenerateing predictions...\n\u001b[1m   1/5000\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48:40:10\u001b[0m 35s/step","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1717797400.180685     116 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1717797400.232535     116 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5529s\u001b[0m 1s/step\n\nTraining on unlabeled data...\nEpoch 1/2\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1717802965.185144     116 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.1885","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1717808521.972703     117 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1717810520.321222     116 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7620s\u001b[0m 2s/step - loss: 0.1885 - val_loss: 0.4478\nEpoch 2/2\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7500s\u001b[0m 2s/step - loss: 0.1660 - val_loss: 0.4378\n\nTraining on labeled data...\nEpoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1717818085.708646     115 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1791/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4596","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1717820098.837005     116 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2078s\u001b[0m 1s/step - loss: 0.4596\nEpoch 2/3\n\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1982s\u001b[0m 1s/step - loss: 0.4573\nEpoch 3/3\n\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1982s\u001b[0m 1s/step - loss: 0.4561\n\nRound 3/3\n\nGenerateing predictions...\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5494s\u001b[0m 1s/step\n\nTraining on unlabeled data...\nEpoch 1/2\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7502s\u001b[0m 2s/step - loss: 0.1541 - val_loss: 0.4378\nEpoch 2/2\n\u001b[1m 480/5000\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:14\u001b[0m 1s/step - loss: 0.1568","output_type":"stream"},{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# LGBM Model","metadata":{}},{"cell_type":"markdown","source":"## Preprocessing + Feature Engineering","metadata":{}},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\n\nprompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\nprompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\nsummaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\nsummaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\nsample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-20T20:41:19.092563Z","iopub.execute_input":"2024-06-20T20:41:19.092793Z","iopub.status.idle":"2024-06-20T20:41:19.168988Z","shell.execute_reply.started":"2024-06-20T20:41:19.092766Z","shell.execute_reply":"2024-06-20T20:41:19.167898Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class Preprocessor:\n    def __init__(self, model_name: str,) -> None:\n        self.STOP_WORDS = set(stopwords.words('english'))\n\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name + \"tokenizer\")\n        self.spacy_ner_model = spacy.load('en_core_web_sm',)\n        self.speller = SpellChecker() #Speller(lang='en')\n        \n    def count_text_length(self, df: pd.DataFrame, col:str) -> pd.Series:\n        \"\"\" text length \"\"\"\n        tokenizer=self.tokenizer\n        return df[col].progress_apply(lambda x: len(tokenizer.encode(x)))\n\n    def word_overlap_count(self, row):\n        \"\"\" intersection(prompt_text, text) \"\"\"        \n        def check_is_stop_word(word):\n            return word in self.STOP_WORDS\n        \n        prompt_words = row['prompt_tokens']\n        summary_words = row['summary_tokens']\n        if self.STOP_WORDS:\n            prompt_words = list(filter(check_is_stop_word, prompt_words))\n            summary_words = list(filter(check_is_stop_word, summary_words))\n        return len(set(prompt_words).intersection(set(summary_words)))\n            \n    def ngrams(self, token, n):\n        # Use the zip function to help us generate n-grams\n        # Concatentate the tokens into ngrams and return\n        ngrams = zip(*[token[i:] for i in range(n)])\n        return [\" \".join(ngram) for ngram in ngrams]\n\n    def ngram_co_occurrence(self, row, n: int):\n        # Tokenize the original text and summary into words\n        original_tokens = row['prompt_tokens']\n        summary_tokens = row['summary_tokens']\n\n        # Generate n-grams for the original text and summary\n        original_ngrams = set(self.ngrams(original_tokens, n))\n        summary_ngrams = set(self.ngrams(summary_tokens, n))\n\n        # Calculate the number of common n-grams\n        common_ngrams = original_ngrams.intersection(summary_ngrams)\n\n        # # Optionally, you can get the frequency of common n-grams for a more nuanced analysis\n        # original_ngram_freq = Counter(ngrams(original_words, n))\n        # summary_ngram_freq = Counter(ngrams(summary_words, n))\n        # common_ngram_freq = {ngram: min(original_ngram_freq[ngram], summary_ngram_freq[ngram]) for ngram in common_ngrams}\n\n        return len(common_ngrams)\n    \n    def ner_overlap_count(self, row, mode:str):\n        model = self.spacy_ner_model\n        def clean_ners(ner_list):\n            return set([(ner[0].lower(), ner[1]) for ner in ner_list])\n        prompt = model(row['prompt_text'])\n        summary = model(row['text'])\n\n        if \"spacy\" in str(model):\n            prompt_ner = set([(token.text, token.label_) for token in prompt.ents])\n            summary_ner = set([(token.text, token.label_) for token in summary.ents])\n        elif \"stanza\" in str(model):\n            prompt_ner = set([(token.text, token.type) for token in prompt.ents])\n            summary_ner = set([(token.text, token.type) for token in summary.ents])\n        else:\n            raise Exception(\"Model not supported\")\n\n        prompt_ner = clean_ners(prompt_ner)\n        summary_ner = clean_ners(summary_ner)\n\n        intersecting_ners = prompt_ner.intersection(summary_ner)\n        \n        ner_dict = dict(Counter([ner[1] for ner in intersecting_ners]))\n        \n        if mode == \"train\":\n            return ner_dict\n        elif mode == \"test\":\n            return {key: ner_dict.get(key) for key in self.ner_keys}\n\n    \n    def quotes_count(self, row):\n        summary = row['text']\n        text = row['prompt_text']\n        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n        if len(quotes_from_summary)>0:\n            return [quote in text for quote in quotes_from_summary].count(True)\n        else:\n            return 0\n\n    def spelling(self, text):\n        \n        wordlist=text.split()\n        amount_miss = len(list(self.speller.unknown(wordlist)))\n\n        return amount_miss\n    \n    def run(self, \n            prompts: pd.DataFrame,\n            summaries:pd.DataFrame,\n            mode:str\n        ) -> pd.DataFrame:\n        \n        # before merge preprocess\n        prompts[\"prompt_length\"] = prompts[\"prompt_text\"].apply(\n            lambda x: len(self.tokenizer.encode(x))\n        )\n        prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].apply(\n            lambda x: self.tokenizer.convert_ids_to_tokens(\n                self.tokenizer.encode(x), \n                skip_special_tokens=True\n            )\n        )\n\n        summaries[\"summary_length\"] = summaries[\"text\"].apply(\n            lambda x: len(self.tokenizer.encode(x))\n        )\n        summaries[\"summary_tokens\"] = summaries[\"text\"].apply(\n            lambda x: self.tokenizer.convert_ids_to_tokens(\n                self.tokenizer.encode(x), \n                skip_special_tokens=True\n            )\n\n        )\n        summaries[\"splling_err_num\"] = summaries[\"text\"].progress_apply(self.spelling)\n\n        # merge prompts and summaries\n        input_df = summaries.merge(prompts, how=\"left\", on=\"prompt_id\")\n\n        # after merge preprocess\n        input_df['length_ratio'] = input_df['summary_length'] / input_df['prompt_length']\n        \n        input_df['word_overlap_count'] = input_df.progress_apply(self.word_overlap_count, axis=1)\n        input_df['bigram_overlap_count'] = input_df.progress_apply(\n            self.ngram_co_occurrence,args=(2,), axis=1 \n        )\n        input_df['trigram_overlap_count'] = input_df.progress_apply(\n            self.ngram_co_occurrence, args=(3,), axis=1\n        )\n        \n        input_df['quotes_count'] = input_df.progress_apply(self.quotes_count, axis=1)\n        \n        return input_df.drop(columns=[\"summary_tokens\", \"prompt_tokens\"])","metadata":{"execution":{"iopub.status.busy":"2024-06-20T20:41:19.172593Z","iopub.execute_input":"2024-06-20T20:41:19.173241Z","iopub.status.idle":"2024-06-20T20:41:19.207926Z","shell.execute_reply.started":"2024-06-20T20:41:19.173192Z","shell.execute_reply":"2024-06-20T20:41:19.206672Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model_path = '/kaggle/input/deberta-v3-large/deberta_v3_large/'\npreprocessor = Preprocessor(model_name=model_path)\n\nfeatures_train = preprocessor.run(prompts_train, summaries_train, mode=\"train\")\nfeatures_test = preprocessor.run(prompts_test, summaries_test, mode=\"test\")\nfeatures_test['length'] = features_test['summary_length'] + features_test['prompt_length']\nfeatures_test = features_test.sort_values('length', ascending=True).reset_index(drop=True)\nfeatures_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-20T20:41:19.209519Z","iopub.execute_input":"2024-06-20T20:41:19.209852Z","iopub.status.idle":"2024-06-20T20:41:53.038596Z","shell.execute_reply.started":"2024-06-20T20:41:19.209791Z","shell.execute_reply":"2024-06-20T20:41:53.037600Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"100%|██████████| 7165/7165 [00:01<00:00, 4104.66it/s]\n100%|██████████| 7165/7165 [00:01<00:00, 6075.95it/s]\n100%|██████████| 7165/7165 [00:02<00:00, 2860.89it/s]\n100%|██████████| 7165/7165 [00:02<00:00, 2422.51it/s]\n100%|██████████| 7165/7165 [00:00<00:00, 39593.62it/s]\n100%|██████████| 4/4 [00:00<00:00, 10125.05it/s]\n100%|██████████| 4/4 [00:00<00:00, 4642.28it/s]\n100%|██████████| 4/4 [00:00<00:00, 4431.38it/s]\n100%|██████████| 4/4 [00:00<00:00, 4406.94it/s]\n100%|██████████| 4/4 [00:00<00:00, 4908.49it/s]\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"     student_id prompt_id                                               text  \\\n0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n\n    content   wording  summary_length  splling_err_num  \\\n0  0.205683  0.380538              69                5   \n1 -0.548304  0.506755              56                2   \n2  3.128928  4.231226             285               32   \n3 -0.210614 -0.471415              43                5   \n4  3.272894  3.219757             253               29   \n\n                                     prompt_question  \\\n0  Summarize how the Third Wave developed over su...   \n1  Summarize the various ways the factory would u...   \n2  In complete sentences, summarize the structure...   \n3  In complete sentences, summarize the structure...   \n4  Summarize how the Third Wave developed over su...   \n\n                prompt_title  \\\n0             The Third Wave   \n1    Excerpt from The Jungle   \n2  Egyptian Social Structure   \n3  Egyptian Social Structure   \n4             The Third Wave   \n\n                                         prompt_text  prompt_length  \\\n0  Background \\r\\nThe Third Wave experiment took ...            671   \n1  With one member trimming beef in a cannery, an...           1137   \n2  Egyptian society was structured like a pyramid...            651   \n3  Egyptian society was structured like a pyramid...            651   \n4  Background \\r\\nThe Third Wave experiment took ...            671   \n\n   length_ratio  word_overlap_count  bigram_overlap_count  \\\n0      0.102832                   0                     5   \n1      0.049252                   0                    22   \n2      0.437788                   1                    56   \n3      0.066052                   1                    10   \n4      0.377049                   1                    27   \n\n   trigram_overlap_count  quotes_count  \n0                      0             0  \n1                     10             0  \n2                     26             2  \n3                      6             0  \n4                      5             4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>content</th>\n      <th>wording</th>\n      <th>summary_length</th>\n      <th>splling_err_num</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>prompt_length</th>\n      <th>length_ratio</th>\n      <th>word_overlap_count</th>\n      <th>bigram_overlap_count</th>\n      <th>trigram_overlap_count</th>\n      <th>quotes_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000e8c3c7ddb</td>\n      <td>814d6b</td>\n      <td>The third wave was an experimentto see how peo...</td>\n      <td>0.205683</td>\n      <td>0.380538</td>\n      <td>69</td>\n      <td>5</td>\n      <td>Summarize how the Third Wave developed over su...</td>\n      <td>The Third Wave</td>\n      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n      <td>671</td>\n      <td>0.102832</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0020ae56ffbf</td>\n      <td>ebad26</td>\n      <td>They would rub it up with soda to make the sme...</td>\n      <td>-0.548304</td>\n      <td>0.506755</td>\n      <td>56</td>\n      <td>2</td>\n      <td>Summarize the various ways the factory would u...</td>\n      <td>Excerpt from The Jungle</td>\n      <td>With one member trimming beef in a cannery, an...</td>\n      <td>1137</td>\n      <td>0.049252</td>\n      <td>0</td>\n      <td>22</td>\n      <td>10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>004e978e639e</td>\n      <td>3b9047</td>\n      <td>In Egypt, there were many occupations and soci...</td>\n      <td>3.128928</td>\n      <td>4.231226</td>\n      <td>285</td>\n      <td>32</td>\n      <td>In complete sentences, summarize the structure...</td>\n      <td>Egyptian Social Structure</td>\n      <td>Egyptian society was structured like a pyramid...</td>\n      <td>651</td>\n      <td>0.437788</td>\n      <td>1</td>\n      <td>56</td>\n      <td>26</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>005ab0199905</td>\n      <td>3b9047</td>\n      <td>The highest class was Pharaohs these people we...</td>\n      <td>-0.210614</td>\n      <td>-0.471415</td>\n      <td>43</td>\n      <td>5</td>\n      <td>In complete sentences, summarize the structure...</td>\n      <td>Egyptian Social Structure</td>\n      <td>Egyptian society was structured like a pyramid...</td>\n      <td>651</td>\n      <td>0.066052</td>\n      <td>1</td>\n      <td>10</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0070c9e7af47</td>\n      <td>814d6b</td>\n      <td>The Third Wave developed  rapidly because the ...</td>\n      <td>3.272894</td>\n      <td>3.219757</td>\n      <td>253</td>\n      <td>29</td>\n      <td>Summarize how the Third Wave developed over su...</td>\n      <td>The Third Wave</td>\n      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n      <td>671</td>\n      <td>0.377049</td>\n      <td>1</td>\n      <td>27</td>\n      <td>5</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## More Feature Engineering (6000+ features)","metadata":{}},{"cell_type":"code","source":"data_path = '/kaggle/input/commonlit-evaluate-student-summaries/'\n# prompts train\ntrain_pro_polars = pl.read_csv(data_path + 'prompts_train.csv')\ntrain_pro_polars.head(1)\n\n# summaries train\ntrain_sum_polars = pl.read_csv(data_path + 'summaries_train.csv')\ntrain_sum_polars.head(1)\n\ntrain_polars = train_pro_polars.join(train_sum_polars , on=\"prompt_id\", how='inner')\ntrain_polars.head(1)\n\n# prompts train\ntest_pro_polars = pl.read_csv(data_path + 'prompts_test.csv')\ntest_pro_polars.head(1)\n\n# summaries train\ntest_sum_polars = pl.read_csv(data_path + 'summaries_test.csv')\ntest_sum_polars.head(1)\n\ntest_polars = test_pro_polars.join(test_sum_polars , on=\"prompt_id\", how='inner')\ntest_polars.head(1)\n\ncolumns = [  \n    (\n        pl.col(\"text\").str.split(by=\"\\n\\n\").alias(\"paragraph\")\n    ),\n]\n# Load training and testing sets, while using \\ n \\ n character segmentation to list and renaming to paragraph for text data\ntrain_polars = train_polars.with_columns(columns)\ntest_polars = test_polars.with_columns(columns)\n# train_polars.head(1)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T20:41:53.040169Z","iopub.execute_input":"2024-06-20T20:41:53.040426Z","iopub.status.idle":"2024-06-20T20:41:53.210152Z","shell.execute_reply.started":"2024-06-20T20:41:53.040398Z","shell.execute_reply":"2024-06-20T20:41:53.208946Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\nwith open('/kaggle/input/english-word-hx/words.txt', 'r') as file:\n    english_vocab = set(word.strip().lower() for word in file)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T20:41:53.211633Z","iopub.execute_input":"2024-06-20T20:41:53.212423Z","iopub.status.idle":"2024-06-20T20:41:54.787307Z","shell.execute_reply.started":"2024-06-20T20:41:53.212387Z","shell.execute_reply":"2024-06-20T20:41:54.786207Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Feature Engineering\n\nparagraph_fea = ['paragraph_len','paragraph_sentence_cnt','paragraph_word_cnt']\nparagraph_fea2 = ['paragraph_error_num'] + paragraph_fea\nsentence_fea = ['sentence_len','sentence_word_cnt']\n\ndef count_spelling_errors(text):\n    doc = nlp(text)\n    lemmatized_tokens = [token.lemma_.lower() for token in doc]\n    spelling_errors = sum(1 for token in lemmatized_tokens if token not in english_vocab)\n    return spelling_errors\n\ndef removeHTML(x):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',x)\n\ndef dataPreprocessing(x):\n    # Convert words to lowercase\n    x = x.lower()\n    # Remove HTML\n    x = removeHTML(x)\n    # Delete strings starting with @\n    x = re.sub(\"@\\w+\", '',x)\n    # Delete Numbers\n    x = re.sub(\"'\\d+\", '',x)\n    x = re.sub(\"\\d+\", '',x)\n    # Delete URL\n    x = re.sub(\"http\\w+\", '',x)\n    # Replace consecutive empty spaces with a single space character\n    x = re.sub(r\"\\s+\", \" \", x)\n    # Replace consecutive commas and periods with one comma and period character\n    x = re.sub(r\"\\.+\", \".\", x)\n    x = re.sub(r\"\\,+\", \",\", x)\n    # Remove empty characters at the beginning and end\n    x = x.strip()\n    return x\n\n\n# paragraph features\ndef remove_punctuation(text):\n    \"\"\"\n    Remove all punctuation from the input text.\n    \n    Args:\n    - text (str): The input text.\n    \n    Returns:\n    - str: The text with punctuation removed.\n    \"\"\"\n    # string.punctuation\n    translator = str.maketrans('', '', string.punctuation)\n    return text.translate(translator)\n\n\ndef Paragraph_Preprocess(tmp):\n    # Expand the paragraph list into several lines of data\n    tmp = tmp.explode('paragraph')\n    # Paragraph preprocessing\n    tmp = tmp.with_columns(pl.col('paragraph').map_elements(dataPreprocessing))\n    tmp = tmp.with_columns(pl.col('paragraph').map_elements(remove_punctuation).alias('paragraph_no_pinctuation'))\n    tmp = tmp.with_columns(pl.col('paragraph_no_pinctuation').map_elements(count_spelling_errors).alias(\"paragraph_error_num\"))\n    # Calculate the length of each paragraph\n    tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x)).alias(\"paragraph_len\"))\n    # Calculate the number of sentences and words in each paragraph\n    tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x.split('.'))).alias(\"paragraph_sentence_cnt\"),\n                    pl.col('paragraph').map_elements(lambda x: len(x.split(' '))).alias(\"paragraph_word_cnt\"),)\n    return tmp\n\ndef Paragraph_Eng(train_tmp):\n    num_list = [0, 50,75,100,125,150,175,200,250,300,350,400,500,600]\n    num_list2 = [0, 50,75,100,125,150,175,200,250,300,350,400,500,600,700]\n    aggs = [\n        # Count the number of paragraph lengths greater than and less than the i-value\n        *[pl.col('paragraph').filter(pl.col('paragraph_len') >= i).count().alias(f\"paragraph_{i}_cnt\") for i in [0, 50,75,100,125,150,175,200,250,300,350,400,500,600,700] ], \n        *[pl.col('paragraph').filter(pl.col('paragraph_len') <= i).count().alias(f\"paragraph_{i}_cnt\") for i in [25,49]], \n        # other\n        *[pl.col(fea).max().alias(f\"{fea}_max\") for fea in paragraph_fea2],\n        *[pl.col(fea).mean().alias(f\"{fea}_mean\") for fea in paragraph_fea2],\n        *[pl.col(fea).min().alias(f\"{fea}_min\") for fea in paragraph_fea2],\n        *[pl.col(fea).sum().alias(f\"{fea}_sum\") for fea in paragraph_fea2],\n        *[pl.col(fea).first().alias(f\"{fea}_first\") for fea in paragraph_fea2],\n        *[pl.col(fea).last().alias(f\"{fea}_last\") for fea in paragraph_fea2],\n        *[pl.col(fea).kurtosis().alias(f\"{fea}_kurtosis\") for fea in paragraph_fea2],\n        *[pl.col(fea).quantile(0.25).alias(f\"{fea}_q1\") for fea in paragraph_fea2],  \n        *[pl.col(fea).quantile(0.75).alias(f\"{fea}_q3\") for fea in paragraph_fea2],  \n        ]\n    \n    df = train_tmp.group_by(['student_id'], maintain_order=True).agg(aggs).sort(\"student_id\")\n    df = df.to_pandas()\n    return df\n\n# sentence feature\ndef Sentence_Preprocess(tmp):\n    # Preprocess text and use periods to segment sentences in the text\n    tmp = tmp.with_columns(pl.col('text').map_elements(dataPreprocessing).str.split(by=\".\").alias(\"sentence\"))\n    tmp = tmp.explode('sentence')\n    # Calculate the length of a sentence\n    tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x)).alias(\"sentence_len\"))\n    # Filter out the portion of data with a sentence length greater than 15\n    tmp = tmp.filter(pl.col('sentence_len')>=15)\n    # Count the number of words in each sentence\n    tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x.split(' '))).alias(\"sentence_word_cnt\"))\n    \n    return tmp\n\n\n# feature_eng\ndef Sentence_Eng(train_tmp):\n    aggs = [\n        # Count the number of sentences with a length greater than i\n        *[pl.col('sentence').filter(pl.col('sentence_len') >= i).count().alias(f\"sentence_{i}_cnt\") for i in [0,15,50,100,150,200,250,300] ], \n        *[pl.col('sentence').filter(pl.col('sentence_len') <= i).count().alias(f\"sentence_<{i}_cnt\") for i in [15,50] ], \n        # other\n        *[pl.col(fea).max().alias(f\"{fea}_max\") for fea in sentence_fea],\n        *[pl.col(fea).mean().alias(f\"{fea}_mean\") for fea in sentence_fea],\n        *[pl.col(fea).min().alias(f\"{fea}_min\") for fea in sentence_fea],\n        *[pl.col(fea).sum().alias(f\"{fea}_sum\") for fea in sentence_fea],\n        *[pl.col(fea).first().alias(f\"{fea}_first\") for fea in sentence_fea],\n        *[pl.col(fea).last().alias(f\"{fea}_last\") for fea in sentence_fea],\n        *[pl.col(fea).kurtosis().alias(f\"{fea}_kurtosis\") for fea in sentence_fea],\n        *[pl.col(fea).quantile(0.25).alias(f\"{fea}_q1\") for fea in sentence_fea], \n        *[pl.col(fea).quantile(0.75).alias(f\"{fea}_q3\") for fea in sentence_fea], \n        ]\n    df = train_tmp.group_by(['student_id'], maintain_order=True).agg(aggs).sort(\"student_id\")\n    df = df.to_pandas()\n    return df\n\n# word feature\ndef Word_Preprocess(tmp):\n    # Preprocess text and use spaces to separate words from the text\n    tmp = tmp.with_columns(pl.col('text').map_elements(dataPreprocessing).str.split(by=\" \").alias(\"word\"))\n    tmp = tmp.explode('word')\n    # Calculate the length of each word\n    tmp = tmp.with_columns(pl.col('word').map_elements(lambda x: len(x)).alias(\"word_len\"))\n    # Delete data with a word length of 0\n    tmp = tmp.filter(pl.col('word_len')!=0)\n    \n    return tmp\n\n\n# feature_eng\ndef Word_Eng(train_tmp):\n    aggs = [\n        # Count the number of words with a length greater than i+1\n        *[pl.col('word').filter(pl.col('word_len') >= i+1).count().alias(f\"word_{i+1}_cnt\") for i in range(15) ], \n        # other\n        pl.col('word_len').max().alias(f\"word_len_max\"),\n        pl.col('word_len').mean().alias(f\"word_len_mean\"),\n        pl.col('word_len').std().alias(f\"word_len_std\"),\n        pl.col('word_len').quantile(0.25).alias(f\"word_len_q1\"),\n        pl.col('word_len').quantile(0.50).alias(f\"word_len_q2\"),\n        pl.col('word_len').quantile(0.75).alias(f\"word_len_q3\"),\n        ]\n    df = train_tmp.group_by(['student_id'], maintain_order=True).agg(aggs).sort(\"student_id\")\n    df = df.to_pandas()\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-06-20T20:41:54.790023Z","iopub.execute_input":"2024-06-20T20:41:54.790257Z","iopub.status.idle":"2024-06-20T20:41:54.890493Z","shell.execute_reply.started":"2024-06-20T20:41:54.790231Z","shell.execute_reply":"2024-06-20T20:41:54.889056Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# The preprocessing and feature engineering main function\n\ndef preprocess_data(data, fold_indexes=None, vectorizer=None, vectorizer_cnt=None):\n    \n    tmp = Paragraph_Preprocess(data)\n    train_feats = Paragraph_Eng(tmp)\n    \n    # Obtain feature names\n    feature_names = list(filter(lambda x: x not in ['student_id','content', 'wording'], train_feats.columns))\n    print('Features Number: ',len(feature_names))\n    \n    # Sentence features\n    tmp = Sentence_Preprocess(data)\n    # Merge the newly generated feature data with the previously generated feature data\n    train_feats = train_feats.merge(Sentence_Eng(tmp), on='student_id', how='left')\n\n    feature_names = list(filter(lambda x: x not in ['student_id','content', 'wording'], train_feats.columns))\n    print('Features Number: ',len(feature_names))\n    \n    # Word features\n    tmp = Word_Preprocess(data)\n    # Merge the newly generated feature data with the previously generated feature data\n    train_feats = train_feats.merge(Word_Eng(tmp), on='student_id', how='left')\n\n    feature_names = list(filter(lambda x: x not in ['student_id', 'content', 'wording'], train_feats.columns))\n    print('Features Number: ',len(feature_names))\n    \n    # TfidfVectorizer parameter\n    if vectorizer == None:\n        vectorizer = TfidfVectorizer(\n                    tokenizer=lambda x: x,\n                    preprocessor=lambda x: x,\n                    token_pattern=None,\n                    strip_accents='unicode',\n                    analyzer = 'word',\n                    ngram_range=(3,6),\n                    min_df=0.05,\n                    max_df=0.95,\n                    sublinear_tf=True,\n        )\n\n        # Fit all datasets into TfidfVector,this may cause leakage and overly optimistic CV scores\n        train_tfid = vectorizer.fit_transform([i for i in data['text']])\n    else:\n        train_tfid = vectorizer.transform([i for i in data['text']])\n        \n    # Convert to array\n    dense_matrix = train_tfid.toarray()\n    # Convert to dataframe\n    df = pd.DataFrame(dense_matrix)\n    # rename features\n    tfid_columns = [ f'tfid_{i}' for i in range(len(df.columns))]\n    df.columns = tfid_columns\n    df['student_id'] = train_feats['student_id']\n    # Merge the newly generated feature data with the previously generated feature data\n    train_feats = train_feats.merge(df, on='student_id', how='left')\n\n    feature_names = list(filter(lambda x: x not in ['student_id','content', 'wording'], train_feats.columns))\n    print('Features Number: ',len(feature_names))\n    \n    if vectorizer_cnt == None:\n        \n        vectorizer_cnt = CountVectorizer(\n                tokenizer=lambda x: x,\n                preprocessor=lambda x: x,\n                token_pattern=None,\n                strip_accents='unicode',\n                analyzer = 'word',\n                ngram_range=(2,3),\n                min_df=0.10,\n                max_df=0.85,\n        )\n\n        train_tfid = vectorizer_cnt.fit_transform([i for i in data['text']])\n    else:\n        train_tfid = vectorizer_cnt.transform([i for i in data['text']])\n        \n    dense_matrix = train_tfid.toarray()\n    df = pd.DataFrame(dense_matrix)\n    tfid_columns = [ f'tfid_cnt_{i}' for i in range(len(df.columns))]\n    df.columns = tfid_columns\n    df['student_id'] = train_feats['student_id']\n    train_feats = train_feats.merge(df, on='student_id', how='left')\n\n    feature_names = list(filter(lambda x: x not in ['student_id','content', 'wording'], train_feats.columns))\n    print('Features Number: ',len(feature_names))\n    \n    # DeBERTa model predictions as features\n    # TODO\n    # deberta_oof = joblib.load('/kaggle/input/model_predictions.pkl')\n    # print(deberta_oof.shape, train_feats.shape)\n\n    # train_feats['deberta_oof'] = deberta_oof\n\n    # feature_names = list(filter(lambda x: x not in ['student_id','content', 'wording'], train_feats.columns))\n    # print('Features Number: ', len(feature_names))   \n\n    # merge features \n    if fold_indexes is not None:\n        ft = features_train.iloc[fold_indexes].drop(columns=train.columns)\n        train_feats_pandas = pd.DataFrame(train_feats.to_numpy(), columns=train_feats.columns, index=fold_indexes)\n    else:\n        ft = features_train.drop(columns=train.columns)\n        train_feats_pandas = pd.DataFrame(train_feats.to_numpy(), columns=train_feats.columns)\n    lgbm_input = pd.concat([train_feats_pandas, ft], axis=1)\n    \n    feature_names = list(filter(lambda x: x not in ['student_id','content', 'wording'], lgbm_input.columns))\n    print('Features Number: ',len(feature_names))\n    \n    return lgbm_input[feature_names].astype(float), feature_names, vectorizer, vectorizer_cnt","metadata":{"execution":{"iopub.status.busy":"2024-06-20T20:41:54.892153Z","iopub.execute_input":"2024-06-20T20:41:54.892431Z","iopub.status.idle":"2024-06-20T20:41:54.919365Z","shell.execute_reply.started":"2024-06-20T20:41:54.892400Z","shell.execute_reply":"2024-06-20T20:41:54.918214Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# The loss function\ndef mcrmse(y_true, y_pred):\n    assert y_true.shape == y_pred.shape\n    scores = []\n    for i in range(y_true.shape[1]):\n        scores.append(mean_squared_error(y_true[:, i], y_pred[:, i], squared=False))\n    return np.mean(scores), scores","metadata":{"execution":{"iopub.status.busy":"2024-06-20T20:41:54.922621Z","iopub.execute_input":"2024-06-20T20:41:54.923037Z","iopub.status.idle":"2024-06-20T20:41:54.934654Z","shell.execute_reply.started":"2024-06-20T20:41:54.923000Z","shell.execute_reply":"2024-06-20T20:41:54.933407Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Randomized Search","metadata":{}},{"cell_type":"code","source":"# Randomized search\nfrom sklearn.model_selection import RandomizedSearchCV\n\nX = train_polars.drop(columns=['content', 'wording'])\ny = train[['content', 'wording']].astype('float16')\nX, _, _, _ = preprocess_data(X)\n\n# Define the parameter grid for randomized search\nparam_distributions = {\n    'learning_rate': [0.5, 0.01, 0.05, 0.1, 0.2, 0.3, 0.02, 0.03],\n    'max_depth': [3, 4, 5, 6],\n    'num_leaves': [5, 10, 15, 20, 25, 30, 35, 40],\n    'colsample_bytree': [0.1, 0.3, 0.5, 0.7, 0.8],\n    'reg_alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0],\n    'reg_lambda': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0],\n    'n_estimators': [100, 300, 500, 700, 1000, 1500, 2000]\n}\n\nbest_params = []\nfor target in ['content', 'wording']:\n    \n    gkf = GroupKFold(n_splits=4)\n    folds = gkf.split(X, y, groups=train['prompt_id'])\n\n    # Initialize the LightGBM regressor\n    model = lgb.LGBMRegressor(\n            objective = 'regression',\n            metrics = 'rmse',\n            learning_rate = param_distributions['learning_rate'],\n            max_depth =param_distributions['max_depth'],\n            num_leaves =param_distributions['num_leaves'],\n            colsample_bytree=param_distributions['colsample_bytree'],\n            reg_alpha =param_distributions['reg_alpha'],\n            reg_lambda =param_distributions['reg_lambda'],\n            n_estimators=param_distributions['n_estimators'],\n            random_state= 42,\n            extra_trees=True,\n            verbosity = -1)\n\n    # Initialize RandomizedSearchCV\n    random_search = RandomizedSearchCV(\n        estimator=model,\n        param_distributions=param_distributions,\n        n_iter=70,\n        scoring='neg_root_mean_squared_error',\n        cv=folds,\n        verbose=2,\n        random_state=42,\n        n_jobs=-1\n    )\n    \n    # Fit the randomized search\n    random_search.fit(X, y[target])\n    best_params.append((random_search.best_score_, random_search.best_params_))\n    print()\n    \n    # Output the best parameters and best score for the current target\n    print(f\"Best parameters found for {target}: \", random_search.best_params_)\n    print(f\"Best RMSE score for {target}: \", -random_search.best_score_)\n    print()\n    \n    # breaking to find hyperparams only for content LGBM\n    break\n    \nprint(\"Content best params and scores:\", best_params[0])\n# print(\"Wording best params and scores:\", best_params[1])","metadata":{"execution":{"iopub.status.busy":"2024-06-20T20:41:54.936616Z","iopub.execute_input":"2024-06-20T20:41:54.937036Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Features Number:  53\nFeatures Number:  81\nFeatures Number:  102\nFeatures Number:  5266\nFeatures Number:  6296\nFeatures Number:  6304\nFitting 4 folds for each of 70 candidates, totalling 280 fits\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Feature Selection","metadata":{}},{"cell_type":"code","source":"def feature_select_wrapper():\n    \"\"\"\n    lgm\n    :param train\n    :param test\n    :return\n    \"\"\"\n    \n    X = train_polars.drop(columns=['content', 'wording'])\n    y = train[['content', 'wording']].astype('float16')\n    gkf = GroupKFold(n_splits=4)\n    folds = gkf.split(X, y, groups=train['prompt_id'])\n    callbacks = [log_evaluation(period=25), early_stopping(stopping_rounds=700, first_metric_only=True)]\n\n    # Part 1.\n    print('feature_select_wrapper...')\n    \n    models = []\n    predictions = []\n    fold_scores = []\n    fse_content = {}\n    fse_wording = {}\n    mcrmse_scores = np.array([])\n    \n    for fold_idx, (train_index, test_index) in enumerate(folds):\n\n        print('fold', fold_idx)\n        X_train_fold, X_test_fold = X[train_index], X[test_index]\n        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n        \n        X_train_fold, feature_names, vectorizer, vectorizer_cnt = preprocess_data(X_train_fold, fold_indexes=train_index)\n        X_test_fold, _, _, _ = preprocess_data(X_test_fold, fold_indexes=test_index, vectorizer=vectorizer, vectorizer_cnt=vectorizer_cnt)\n        \n        features = feature_names \n        \n        fold_predictions = []\n        fold_models = []\n        for target in ['content', 'wording']:\n            y_train_target = y_train_fold[target]\n            y_test_target = y_test_fold[target]\n            \n            model = lgb.LGBMRegressor(\n                    objective = 'regression',\n                    metrics = 'rmse',\n                    learning_rate = 0.01,\n                    max_depth = 3,\n                    num_leaves = 10,\n                    colsample_bytree=0.7,\n                    reg_alpha = 0.1,\n                    reg_lambda = 1.0,\n                    n_estimators=100,\n                    random_state= 42,\n                    extra_trees=True,\n                    verbosity = -1)\n\n            predictor = model.fit(X_train_fold,\n                                  y_train_target,\n                                  eval_names=['train', 'valid'],\n                                  eval_set=[(X_train_fold, y_train_target), (X_test_fold, y_test_target)],\n                                  eval_metric='rmse',\n                                  callbacks=callbacks)\n            \n            fold_models.append(predictor)\n            fold_predictions.append(predictor.predict(X_test_fold))\n            \n            # Aggregate feature importances\n            importances = pd.Series(predictor.feature_importances_, index=features)\n            print()\n            if target == 'content':\n                for feature, importance in importances.items():\n                    if feature in fse_content:\n                        fse_content[feature] += importance\n                    else:\n                        fse_content[feature] = importance\n            else:\n                for feature, importance in importances.items():\n                    if feature in fse_wording:\n                        fse_wording[feature] += importance\n                    else:\n                        fse_wording[feature] = importance\n                \n        models.append(fold_models)\n        predictions.append(fold_predictions)\n        \n        # Calculate mcrmse \n        y_true_fold = np.array(y_test_fold)\n        y_pred_fold = np.array(fold_predictions).T.reshape(-1, 2)\n        fold_mcrmse, _ = mcrmse(y_true_fold, y_pred_fold)    \n        mcrmse_scores = np.append(mcrmse_scores, fold_mcrmse)\n        print(f\"Fold {fold_idx} MCRMSE: {fold_mcrmse}\")\n        print()\n    \n    print(f\"MCRMSE across all folds: {np.mean(mcrmse_scores)}\")\n    \n    # Convert dictionaries to Series\n    fse_content = pd.Series(fse_content)\n    fse_wording = pd.Series(fse_wording)\n    fse_aggregate = (fse_content + fse_wording) / 2\n    \n    # Part 4.\n    feature_select_content = fse_content.sort_values(ascending=False).index.tolist()\n    feature_select_wording = fse_wording.sort_values(ascending=False).index.tolist()\n    feature_select_aggregate = fse_aggregate.sort_values(ascending=False).index.tolist()\n\n    # Combine feature importance scores into a DataFrame\n    feature_importance_df = pd.DataFrame({\n        'Feature':  fse_aggregate.index,\n        'Content_Importance': fse_content,\n        'Wording_Importance': fse_wording,\n        'Aggregate_Importance': fse_aggregate\n    }).fillna(0)\n    \n    # Sort by aggregate importance and select top features\n    feature_importance_df = feature_importance_df.sort_values(by='Aggregate_Importance', ascending=False).reset_index(drop=True)\n    top_features = feature_importance_df\n    \n    print('done')\n    return top_features, feature_select_content, feature_select_wording, feature_select_aggregate","metadata":{"execution":{"iopub.status.busy":"2024-06-17T23:11:16.925385Z","iopub.execute_input":"2024-06-17T23:11:16.925674Z","iopub.status.idle":"2024-06-17T23:11:16.944459Z","shell.execute_reply.started":"2024-06-17T23:11:16.925641Z","shell.execute_reply":"2024-06-17T23:11:16.943280Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Run feature selection\ntop_features, fs_content, fs_wording, fs_aggregate = feature_select_wrapper()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T23:11:17.938019Z","iopub.execute_input":"2024-06-17T23:11:17.939080Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"feature_select_wrapper...\nfold 0\nFeatures Number:  97\nFeatures Number:  153\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Choose Selected Features","metadata":{}},{"cell_type":"code","source":"# select num of features based on the plots\n# Plot the data\nplt.figure(figsize=(12, 10))\ntop_idxs = 30\n\n# plot options: Content_Importance, Wording_Importance, Aggregate_Importance\nimportance_to_plot = 'Aggregate_Importance'\nplt.barh(top_features['Feature'][:top_idxs], top_features.sort_values(by=importance_to_plot, ascending=False).reset_index(drop=True)[importance_to_plot][:top_idxs], color='skyblue')\nplt.xlabel('Feature importance')\nplt.ylabel('Features')\nplt.title('Feature Importance')\nplt.gca().invert_yaxis()  # Invert y-axis to have the highest importance on top\nplt.show()\n\n# fs_content[:top_idxs]\n# fs_wording[:top_idxs]\n# fs_aggregate[:top_idxs]\ntop_features.sort_values(by=importance_to_plot, ascending=False).reset_index(drop=True)[:top_idxs]","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:29:05.655561Z","iopub.execute_input":"2024-06-17T22:29:05.655839Z","iopub.status.idle":"2024-06-17T22:29:06.225863Z","shell.execute_reply.started":"2024-06-17T22:29:05.655809Z","shell.execute_reply":"2024-06-17T22:29:06.224885Z"},"trusted":true},"execution_count":44,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x1000 with 1 Axes>","image/png":"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"},"metadata":{}},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"         Feature  Content_Importance  Wording_Importance  Aggregate_Importance\n0      tfid_1303                   3                  17                  10.0\n1       tfid_243                   4                   8                   6.0\n2      tfid_1557                   0                  12                   6.0\n3    tfid_cnt_39                   1                  10                   5.5\n4    tfid_cnt_36                   2                   9                   5.5\n5        tfid_91                   0                  10                   5.0\n6      tfid_5008                   3                   7                   5.0\n7      tfid_4979                   3                   7                   5.0\n8       tfid_246                   2                   8                   5.0\n9       tfid_782                   0                  10                   5.0\n10        tfid_9                   0                  10                   5.0\n11     tfid_4696                   0                   9                   4.5\n12     tfid_1293                   0                   9                   4.5\n13     tfid_2767                   1                   8                   4.5\n14     tfid_3688                   0                   8                   4.0\n15      tfid_581                   0                   8                   4.0\n16     tfid_3222                   6                   1                   3.5\n17      tfid_589                   0                   7                   3.5\n18       tfid_10                   0                   7                   3.5\n19  tfid_cnt_834                   0                   7                   3.5\n20      tfid_523                   7                   0                   3.5\n21     tfid_1825                   0                   7                   3.5\n22     tfid_4315                   3                   4                   3.5\n23     tfid_2201                   0                   7                   3.5\n24        tfid_8                   0                   7                   3.5\n25     tfid_3026                   0                   7                   3.5\n26     tfid_1559                   1                   5                   3.0\n27      tfid_590                   0                   6                   3.0\n28     tfid_1962                   6                   0                   3.0\n29     tfid_3536                   2                   4                   3.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>Content_Importance</th>\n      <th>Wording_Importance</th>\n      <th>Aggregate_Importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tfid_1303</td>\n      <td>3</td>\n      <td>17</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tfid_243</td>\n      <td>4</td>\n      <td>8</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tfid_1557</td>\n      <td>0</td>\n      <td>12</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tfid_cnt_39</td>\n      <td>1</td>\n      <td>10</td>\n      <td>5.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tfid_cnt_36</td>\n      <td>2</td>\n      <td>9</td>\n      <td>5.5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>tfid_91</td>\n      <td>0</td>\n      <td>10</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>tfid_5008</td>\n      <td>3</td>\n      <td>7</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>tfid_4979</td>\n      <td>3</td>\n      <td>7</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>tfid_246</td>\n      <td>2</td>\n      <td>8</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>tfid_782</td>\n      <td>0</td>\n      <td>10</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>tfid_9</td>\n      <td>0</td>\n      <td>10</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>tfid_4696</td>\n      <td>0</td>\n      <td>9</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>tfid_1293</td>\n      <td>0</td>\n      <td>9</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>tfid_2767</td>\n      <td>1</td>\n      <td>8</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>tfid_3688</td>\n      <td>0</td>\n      <td>8</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>tfid_581</td>\n      <td>0</td>\n      <td>8</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>tfid_3222</td>\n      <td>6</td>\n      <td>1</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>tfid_589</td>\n      <td>0</td>\n      <td>7</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>tfid_10</td>\n      <td>0</td>\n      <td>7</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>tfid_cnt_834</td>\n      <td>0</td>\n      <td>7</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>tfid_523</td>\n      <td>7</td>\n      <td>0</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>tfid_1825</td>\n      <td>0</td>\n      <td>7</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>tfid_4315</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>tfid_2201</td>\n      <td>0</td>\n      <td>7</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>tfid_8</td>\n      <td>0</td>\n      <td>7</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>tfid_3026</td>\n      <td>0</td>\n      <td>7</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>tfid_1559</td>\n      <td>1</td>\n      <td>5</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>tfid_590</td>\n      <td>0</td>\n      <td>6</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>tfid_1962</td>\n      <td>6</td>\n      <td>0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>tfid_3536</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Train LGBM","metadata":{}},{"cell_type":"code","source":"LOAD = True # re-train\n# Define the number of splits for cross-validation\nn_splits = 4\nmodels = []\nif not LOAD:\n    for i in range(n_splits):\n        # TODO: Change path !!!!!!!\n        models.append(lgb.Booster(model_file=f'/kaggle/input/aes-15fold/fold_{i+1}.txt'))\nelse:\n    X = train_polars.drop(columns=['content', 'wording'])\n    y = train[['content', 'wording']].astype('float16')\n    gkf = GroupKFold(n_splits=4)\n    folds = gkf.split(X, y, groups=train['prompt_id'])\n    callbacks = [log_evaluation(period=25), early_stopping(stopping_rounds=700, first_metric_only=True)]\n    predictions = []\n    mcrmse_scores = np.array([])\n    \n    top_features_list = top_features['Feature'][:top_idxs]\n    # Loop through each fold of the cross-validation\n    for fold_idx, (train_index, test_index) in enumerate(folds):\n        \n        print('fold', fold_idx)\n        X_train_fold, X_test_fold = X[train_index], X[test_index]\n        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n        \n        X_train_fold, feature_names, vectorizer, vectorizer_cnt = preprocess_data(X_train_fold, fold_indexes=train_index)\n        X_test_fold, _, _, _ = preprocess_data(X_test_fold, fold_indexes=test_index, vectorizer=vectorizer, vectorizer_cnt=vectorizer_cnt)\n        \n        # Intersect the list of top features with the columns in X_train_fold\n        existing_top_features = [feature for feature in top_features_list if feature in X_train_fold.columns]\n        \n        # Using the top features only\n        X_train_fold = X_train_fold[existing_top_features]\n        X_test_fold = X_test_fold[existing_top_features]\n        \n        print(X_train_fold.shape)\n        \n        fold_predictions = []\n        fold_models = []\n        \n        for target in ['content', 'wording']:\n            y_train_target = y_train_fold[target]\n            y_test_target = y_test_fold[target]\n            \n            model = lgb.LGBMRegressor(\n                    objective = 'regression',\n                    metrics = 'rmse',\n                    learning_rate = 0.01,\n                    max_depth = 3,\n                    num_leaves = 10,\n                    colsample_bytree=0.7,\n                    reg_alpha = 0.1,\n                    reg_lambda = 1.0,\n                    n_estimators=100,\n                    random_state= 42,\n                    extra_trees=True,\n                    verbosity = -1)\n\n            predictor = model.fit(X_train_fold,\n                                  y_train_target,\n                                  eval_names=['train', 'valid'],\n                                  eval_set=[(X_train_fold, y_train_target), (X_test_fold, y_test_target)],\n                                  eval_metric='rmse',\n                                  callbacks=callbacks)\n            \n            fold_models.append(predictor)\n            fold_predictions.append(predictor.predict(X_test_fold))\n            # predictor.booster_.save_model(f'fold_{fold_idx}_{target}.txt')\n            \n        models.append(fold_models)\n        predictions.append(fold_predictions)\n        \n        # Calculate mcrmse \n        y_true_fold = np.array(y_test_fold)\n        y_pred_fold = np.array(fold_predictions).T.reshape(-1, 2)\n        fold_mcrmse, _ = mcrmse(y_true_fold, y_pred_fold)    \n        mcrmse_scores = np.append(mcrmse_scores, fold_mcrmse)\n        print(f\"Fold {fold_idx} MCRMSE: {fold_mcrmse}\")\n        print()\n        \n    print(f\"MCRMSE across all folds: {np.mean(mcrmse_scores)}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:29:08.045710Z","iopub.execute_input":"2024-06-17T22:29:08.046032Z","iopub.status.idle":"2024-06-17T22:40:42.935564Z","shell.execute_reply.started":"2024-06-17T22:29:08.046002Z","shell.execute_reply":"2024-06-17T22:40:42.934513Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"fold 0\nFeatures Number:  53\nFeatures Number:  81\nFeatures Number:  102\nFeatures Number:  5264\nFeatures Number:  6288\nFeatures Number:  53\nFeatures Number:  81\nFeatures Number:  102\nFeatures Number:  5264\nFeatures Number:  6288\n(5108, 30)\nTraining until validation scores don't improve for 700 rounds\n[25]\ttrain's rmse: 1.06851\tvalid's rmse: 0.975776\n[50]\ttrain's rmse: 1.06711\tvalid's rmse: 0.975683\n[75]\ttrain's rmse: 1.06593\tvalid's rmse: 0.975573\n[100]\ttrain's rmse: 1.06481\tvalid's rmse: 0.975476\nDid not meet early stopping. Best iteration is:\n[94]\ttrain's rmse: 1.06506\tvalid's rmse: 0.97546\nEvaluated only: rmse\nTraining until validation scores don't improve for 700 rounds\n[25]\ttrain's rmse: 1.02426\tvalid's rmse: 1.06082\n[50]\ttrain's rmse: 1.02233\tvalid's rmse: 1.06091\n[75]\ttrain's rmse: 1.02064\tvalid's rmse: 1.06085\n[100]\ttrain's rmse: 1.01913\tvalid's rmse: 1.06103\nDid not meet early stopping. Best iteration is:\n[35]\ttrain's rmse: 1.02345\tvalid's rmse: 1.06078\nEvaluated only: rmse\nFold 0 MCRMSE: 1.0181190225092491\n\nfold 1\nFeatures Number:  53\nFeatures Number:  81\nFeatures Number:  102\nFeatures Number:  5284\nFeatures Number:  6319\nFeatures Number:  53\nFeatures Number:  81\nFeatures Number:  102\nFeatures Number:  5284\nFeatures Number:  6319\n(5156, 30)\nTraining until validation scores don't improve for 700 rounds\n[25]\ttrain's rmse: 1.01592\tvalid's rmse: 1.10955\n[50]\ttrain's rmse: 1.01485\tvalid's rmse: 1.10955\n[75]\ttrain's rmse: 1.01393\tvalid's rmse: 1.10962\n[100]\ttrain's rmse: 1.01308\tvalid's rmse: 1.10973\nDid not meet early stopping. Best iteration is:\n[3]\ttrain's rmse: 1.01693\tvalid's rmse: 1.10942\nEvaluated only: rmse\nTraining until validation scores don't improve for 700 rounds\n[25]\ttrain's rmse: 1.06549\tvalid's rmse: 0.952032\n[50]\ttrain's rmse: 1.06426\tvalid's rmse: 0.9516\n[75]\ttrain's rmse: 1.06329\tvalid's rmse: 0.951284\n[100]\ttrain's rmse: 1.06234\tvalid's rmse: 0.951321\nDid not meet early stopping. Best iteration is:\n[85]\ttrain's rmse: 1.06291\tvalid's rmse: 0.95125\nEvaluated only: rmse\nFold 1 MCRMSE: 1.0303355826625495\n\nfold 2\nFeatures Number:  53\nFeatures Number:  81\nFeatures Number:  102\nFeatures Number:  5224\nFeatures Number:  6251\nFeatures Number:  53\nFeatures Number:  81\nFeatures Number:  102\nFeatures Number:  5224\nFeatures Number:  6251\n(5169, 30)\nTraining until validation scores don't improve for 700 rounds\n[25]\ttrain's rmse: 1.06088\tvalid's rmse: 0.995144\n[50]\ttrain's rmse: 1.05978\tvalid's rmse: 0.995171\n[75]\ttrain's rmse: 1.05877\tvalid's rmse: 0.99515\n[100]\ttrain's rmse: 1.05797\tvalid's rmse: 0.995326\nDid not meet early stopping. Best iteration is:\n[57]\ttrain's rmse: 1.05949\tvalid's rmse: 0.995047\nEvaluated only: rmse\nTraining until validation scores don't improve for 700 rounds\n[25]\ttrain's rmse: 1.05855\tvalid's rmse: 0.9857\n[50]\ttrain's rmse: 1.05726\tvalid's rmse: 0.985619\n[75]\ttrain's rmse: 1.05612\tvalid's rmse: 0.98558\n[100]\ttrain's rmse: 1.05512\tvalid's rmse: 0.985623\nDid not meet early stopping. Best iteration is:\n[83]\ttrain's rmse: 1.05582\tvalid's rmse: 0.985553\nEvaluated only: rmse\nFold 2 MCRMSE: 0.9903001091877044\n\nfold 3\nFeatures Number:  53\nFeatures Number:  81\nFeatures Number:  102\nFeatures Number:  5297\nFeatures Number:  6335\nFeatures Number:  53\nFeatures Number:  81\nFeatures Number:  102\nFeatures Number:  5297\nFeatures Number:  6335\n(6062, 30)\nTraining until validation scores don't improve for 700 rounds\n[25]\ttrain's rmse: 1.02388\tvalid's rmse: 1.14026\n[50]\ttrain's rmse: 1.0225\tvalid's rmse: 1.1402\n[75]\ttrain's rmse: 1.02131\tvalid's rmse: 1.14005\n[100]\ttrain's rmse: 1.02025\tvalid's rmse: 1.14011\nDid not meet early stopping. Best iteration is:\n[69]\ttrain's rmse: 1.02163\tvalid's rmse: 1.14001\nEvaluated only: rmse\nTraining until validation scores don't improve for 700 rounds\n[25]\ttrain's rmse: 0.984685\tvalid's rmse: 1.30266\n[50]\ttrain's rmse: 0.98338\tvalid's rmse: 1.30213\n[75]\ttrain's rmse: 0.982107\tvalid's rmse: 1.30163\n[100]\ttrain's rmse: 0.981052\tvalid's rmse: 1.30127\nDid not meet early stopping. Best iteration is:\n[100]\ttrain's rmse: 0.981052\tvalid's rmse: 1.30127\nEvaluated only: rmse\nFold 3 MCRMSE: 1.2206435370581679\n\nMCRMSE across all folds: 1.0648495628544177\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Inference ","metadata":{}},{"cell_type":"markdown","source":"## Inference Baseline Model","metadata":{}},{"cell_type":"code","source":"# content_scores = np.random.uniform(-1.73, 3.9, len(test))\n# wording_scores = np.random.uniform(-1.96, 4.31, len(test))\n\n# submission_df = pd.DataFrame({'student_id': test['student_id'],\n#                               'content': content_scores,\n#                               'wording': wording_scores})\n\n# submission_df.to_csv(\"submission.csv\", index=False)\n# submission_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-18T22:09:23.287056Z","iopub.execute_input":"2024-06-18T22:09:23.287348Z","iopub.status.idle":"2024-06-18T22:09:23.303148Z","shell.execute_reply.started":"2024-06-18T22:09:23.287312Z","shell.execute_reply":"2024-06-18T22:09:23.302121Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"     student_id   content   wording\n0  000000ffffff  1.654278  3.259415\n1  222222cccccc  2.256449 -0.628634\n2  111111eeeeee -1.614109 -0.819957\n3  333333dddddd  3.730592 -0.810054","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000ffffff</td>\n      <td>1.654278</td>\n      <td>3.259415</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>222222cccccc</td>\n      <td>2.256449</td>\n      <td>-0.628634</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>111111eeeeee</td>\n      <td>-1.614109</td>\n      <td>-0.819957</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>333333dddddd</td>\n      <td>3.730592</td>\n      <td>-0.810054</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Inference Without LGBM","metadata":{}},{"cell_type":"code","source":"# MODIFY ACCORDINGLY\nweights_to_submit_path = '/kaggle/input/meta-model-weights/meta_model_3.weights.h5'\n\nX = test[['text', 'prompt_question', 'prompt_text']]\n\ndecay_steps = math.ceil((len(X) / batch_size) * epochs) \nmodel, deberta = create_model(decay_steps=decay_steps)\nmodel.load_weights(weights_to_submit_path)\n\nX = build_dataset(X['text'], X['prompt_question'], X['prompt_text'], deberta.tokenizer)\n\ntest_data = {\n    'input_ids': X[0],\n    'attention_mask': X[1],\n    'head_mask': X[2],\n    'student_id': test['student_id'],\n}\n\nids, contents, wordings = generate_predictions(model, test_data)\n\nsubmission_df = pd.DataFrame({'student_id': ids,\n                              'content': contents,\n                              'wording': wordings})\n\nsubmission_df.to_csv(\"submission.csv\", index=False)\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-19T12:00:01.244788Z","iopub.execute_input":"2024-06-19T12:00:01.245073Z","iopub.status.idle":"2024-06-19T12:00:51.807346Z","shell.execute_reply.started":"2024-06-19T12:00:01.245042Z","shell.execute_reply":"2024-06-19T12:00:51.806462Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"     student_id   content   wording\n0  000000ffffff  0.000441 -0.000741\n1  222222cccccc  0.000556 -0.001060\n2  111111eeeeee  0.000401 -0.000998\n3  333333dddddd  0.000462 -0.000885","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000ffffff</td>\n      <td>0.000441</td>\n      <td>-0.000741</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>222222cccccc</td>\n      <td>0.000556</td>\n      <td>-0.001060</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>111111eeeeee</td>\n      <td>0.000401</td>\n      <td>-0.000998</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>333333dddddd</td>\n      <td>0.000462</td>\n      <td>-0.000885</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Inference With LGBM","metadata":{}},{"cell_type":"code","source":"# TODO","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Leftovers","metadata":{}},{"cell_type":"code","source":"\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n\n# log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n\n\n# Model name to load\n# model_name =  \"microsoft/deberta-v3-large\"\n\n# # Load DeBERTa / RoBERTa model and tokenizer\n# tokenizer = AutoTokenizer.from_pretrained(model_name)\n# pre_trained_model = TFAutoModel.from_pretrained(model_name)\n\n\n# tokenizer.save_pretrained(\"deberta_v3_large_tokenizer\")\n# pre_trained_model.save_pretrained(\"deberta_v3_large_model\")\n\n\n\n# def get_embeddings(input_ids, attention_mask, model_name):\n    \n#     # Forward pass through pre trained model\n#     outputs = pre_trained_model(input_ids=input_ids, attention_mask=attention_mask)\n    \n#     if model_name == 'roberta-large':\n#         return outputs['pooler_output']\n#     else:\n#         return outputs[0]\n\n# # Save roberta/deberta embeddings in the training set\n\n# batch_size = 10 # ten is the biggest batch possible (can try maybe 11)\n# num_samples = len(X_train['input_ids'])\n# num_batches = (num_samples + batch_size - 1) // batch_size\n# averaged_embeddings = []\n\n# for i in range(num_batches):\n#     start_idx = i * batch_size\n#     end_idx = min((i + 1) * batch_size, num_samples)\n#     inputs = X_train['input_ids'][start_idx: end_idx]\n#     masks = X_train['attention_mask'][start_idx: end_idx]\n    \n#     embeddings = get_embeddings(input_ids=inputs, attention_mask=masks, model_name=model_name)\n#     h_mask = tf.expand_dims(tf.cast(head_mask[start_idx: end_idx], dtype=tf.float32), axis=-1)\n#     masked_outputs = tf.multiply(embeddings, h_mask)\n#     pooled = (tf.reduce_mean(masked_outputs, axis=1)).numpy()\n#     averaged_embeddings.append(pooled)\n    \n#     if i % int(num_batches * 0.1) == 0:\n#         print(f\"Batch {i}/{num_batches}\")\n        \n#     del embeddings\n#     del masked_outputs\n#     del pooled\n#     del h_mask\n#     gc.collect()\n#     tf.keras.backend.clear_session()\n# # Write to a file    \n# concatenated_embeddings = np.concatenate(averaged_embeddings, axis=0)\n# with open('masked_pooled_deberta_embeddings.pkl', 'wb') as f:\n#     pickle.dump(concatenated_embeddings, f)\n\n\n# Save file to output folder\n\n# # DeBERTa \n# file_path = '/kaggle/input/pooled-deberta-embeddings/pooled_deberta_embeddings.csv'# from input folder\n\n# # Load masked pooled Deberta embeddings\n# with open('/kaggle/input/masked-pooled-deberta-embeddings/mask_pooled_deberta_embeddings.pkl', 'rb') as f:\n#     loaded_array = pickle.load(f)\n# # Load embeddings\n# X_train_preprocessed = pd.read_csv(file_path)\n\n\n# X_train_preprocessed['embeddings'] = X_train_preprocessed['embeddings'].apply(lambda x: list(map(float, x.split(','))))\n# X_train_preprocessed['masked_embeddings'] = loaded_array.tolist()\n# Save a csv file\n# df_to_save = df_with_embeddings['pooled_roberta_embedding'].apply(lambda x: ','.join(map(str, x)))\n# df_to_save.to_csv(file_path, index=False)\n\n\n\n\n# # NN with embeddings preprocessed\n# def create_model_preprocessed():\n#     input_shape = len(X_train_preprocessed['masked_embeddings'][0])\n\n#     input_layer = keras.Input(shape=(input_shape, ), dtype='float32')\n    \n#     layer_norm = layers.LayerNormalization(name='layer_norm1')(input_layer)\n    \n#     reshape_input_layer = layers.Reshape((1,input_shape), name='reshape_layer')(layer_norm)\n    \n#     LSTM_layer = layers.LSTM(512, return_sequences=True, name='LSTM_layer1', activation='linear')(reshape_input_layer)\n    \n#     layer_norm = layers.LayerNormalization(name='layer_norm2')(LSTM_layer)\n    \n#     act = layers.Activation(keras.activations.tanh, name='tanh1')(layer_norm)\n    \n#     LSTM_layer = layers.LSTM(32, return_sequences=False, name='LSTM_layer2', activation='linear',)(act)\n    \n#     layer_norm = layers.LayerNormalization(name='layer_norm3')(LSTM_layer)\n    \n#     act = layers.Activation(keras.activations.tanh, name='tanh2')(layer_norm)\n    \n#     hidden_layer = layers.Dense(16, activation='linear', name='dense_layer')(act)\n    \n#     dropout = layers.Dropout(0.3, name='dropout_layer')(hidden_layer)\n    \n#     # batch_norm = layers.BatchNormalization(name='batch_norm')(dropout)\n\n#     output_layer = layers.Dense(2, activation='linear', name='output_layer')(dropout)\n    \n#     model = keras.Model(inputs=input_layer, outputs=output_layer)\n\n#     for layer in model.layers:\n#         layer.trainable = True\n        \n    \n#     opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n#     model.compile(loss=mcrmse, optimizer=opt)\n    \n#     return model\n\n# model = create_model_preprocessed()\n# model.summary()\n\n\n\n# Train prepocessed model (head only) without validation\n\n# Checkpoint callback\n# ckptcb = keras.callbacks.ModelCheckpoint(\n#     \"best_model\" + \".weights.h5\",\n#     monitor=\"loss\",\n#     save_best_only=True,\n#     save_weights_only=True,\n#     mode=\"min\",\n# )    \n\n# history = model.fit(x=X_train_input,\n#                     y=Y_train_np,\n#                     epochs=25,\n#                     batch_size=4,\n#                     callbacks=[ckptcb],\n#                     verbose=2)\n\n\n\n# Train prepocessed model (head only) with K folds\n\n# X_train_input = np.array(X_train_preprocessed['masked_embeddings'].tolist())\n# Y_train = tf.constant(train[['content', 'wording']].values, dtype=tf.float32)\n\n# # Initialize the KFold object\n# kf = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n\n# # Initialize an empty list to store the validation losses\n# val_losses = []\n# histories = []\n\n# Y_train_np = Y_train.numpy()\n\n# # Iterate over each fold\n# i = 0\n# for train_index, val_index in kf.split(X_train_input, Y_train_np):\n    \n#     print(f\"Fold {i + 1}\")\n#     i += 1\n    \n#     # Split data into training and validation sets\n#     X_train_fold, X_val_fold = X_train_input[train_index], X_train_input[val_index]\n#     Y_train_fold, Y_val_fold = Y_train_np[train_index], Y_train_np[val_index]\n    \n#     # Create and compile your model\n#     model = create_model()\n    \n#     early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    \n#     # Train the model\n    \n#     # Get the validation loss from the last epoch\n#     val_loss = min(history.history['val_loss'])\n#     val_losses.append(val_loss)\n#     histories.append(history)\n#     print()\n\n# # Calculate the mean validation loss\n# mean_val_loss = np.mean(val_losses)\n# print(\"Mean Validation Loss:\", mean_val_loss)\n\n# # Plot training and val losses across folds\n# for i, history in enumerate(histories):\n#     train_losses = history.history['loss']\n#     val_losses = history.history['val_loss']\n#     epochs = range(1, len(train_losses) + 1)\n\n#     # Plotting losses\n#     plt.figure(figsize=(12, 5))\n#     plt.subplot(1, 2, 1)\n#     plt.plot(epochs, train_losses, 'b', label='Training loss')\n#     plt.plot(epochs, val_losses, 'r', label='Validation loss')\n#     plt.title(f'Training and Validation Loss Fold {i + 1}')\n#     plt.xlabel('Epochs')\n#     plt.ylabel('Loss')\n#     plt.legend()\n\n#     plt.tight_layout()\n#     plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # NN with embeddings preprocessed (head only)\n# def create_model_preprocessed():\n#     input_shape = 1024 \n\n#     input_layer = keras.Input(shape=(input_shape, ), dtype='float32')\n\n#     x = layers.LayerNormalization(name='layer_norm1')(input_layer)\n#     x = layers.Reshape((1,input_shape), name='reshape_layer')(x)\n    \n#     x = layers.LSTM(512, return_sequences=True, name='LSTM_layer1', activation='linear')(x)\n#     x = layers.LayerNormalization(name='layer_norm2')(x)\n#     x = layers.Activation(keras.activations.tanh, name='tanh1')(x)\n#     x = layers.LSTM(32, return_sequences=False, name='LSTM_layer2', activation='linear',)(x)\n#     x = layers.LayerNormalization(name='layer_norm3')(x)\n    \n#     x = layers.Activation(keras.activations.tanh, name='tanh2')(x)\n#     x = layers.Dense(16, activation='linear', name='dense_layer')(x)\n#     x = layers.Dropout(0.3, name='dropout_layer')(x)\n\n#     output_layer = layers.Dense(2, activation='linear', name='output_layer')(x)\n    \n#     model = keras.Model(inputs=input_layer, outputs=output_layer)\n\n#     for layer in model.layers:\n#         layer.trainable = True\n        \n    \n#     opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n#     model.compile(loss=mcrmse, optimizer=opt)\n    \n#     return model\n\n# # model_preprocessed = create_model_preprocessed()\n# # model_preprocessed.load_weights(\"/kaggle/input/model-weights-1/best_model.weights.h5\")\n# # model_preprocessed.summary()\n\n\n\n\n# Save file to output folder\n\n# DeBERTa \n# file_path = '/kaggle/input/pooled-deberta-embeddings/pooled_deberta_embeddings.csv'\n\n# # Load masked pooled Deberta embeddings\n# with open('/kaggle/input/masked-pooled-deberta-embeddings/mask_pooled_deberta_embeddings.pkl', 'rb') as f:\n#     loaded_array = pickle.load(f)\n# # Load embeddings\n# X_train_preprocessed = pd.read_csv(file_path)\n\n# X_train_preprocessed['embeddings'] = X_train_preprocessed['embeddings'].apply(lambda x: list(map(float, x.split(','))))\n# X_train_preprocessed['masked_embeddings'] = loaded_array.tolist()\n\n# # Save a csv file\n# df_to_save = df_with_embeddings['pooled_roberta_embedding'].apply(lambda x: ','.join(map(str, x)))\n# df_to_save.to_csv(file_path, index=False)\n\n\n\n# # Train prepocessed model (head only) with K folds\n\n# X_train_input = np.array(X_train_preprocessed['masked_embeddings'].tolist())\n# Y_train = tf.constant(train[['content', 'wording']].values, dtype=tf.float32)\n# Y_train_np = Y_train.numpy()\n\n# # Initialize the KFold object\n# kf = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n# folds = kf.split(X_train_input, Y_train_np)\n\n# # Initialize an empty list to store the validation losses\n# val_losses = []\n# histories = []\n\n# # Iterate over each fold\n# i = 0\n# for train_index, val_index in folds:\n    \n#     print(f\"Fold {i + 1}\")\n#     i += 1\n    \n#     # Split data into training and validation sets\n#     X_train_fold, X_val_fold = X_train_input[train_index], X_train_input[val_index]\n#     Y_train_fold, Y_val_fold = Y_train_np[train_index], Y_train_np[val_index]\n    \n#     # Create and compile your model\n#     model = create_model_preprocessed()\n#     early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n    \n#     # Checkpoint callback\n#     ckptcb = keras.callbacks.ModelCheckpoint(\n#         f\"model_fold_{i}\" + \".weights.h5\",\n#         monitor=\"val_loss\",\n#         save_best_only=True,\n#         save_weights_only=True,\n#         mode=\"min\",\n#     )    \n\n#     # Train the model\n#     history = model.fit(x=X_train_fold,\n#                         y=Y_train_fold,\n#                         epochs=100,\n#                         batch_size=4,\n#                         validation_data=(X_val_fold, Y_val_fold),\n#                         callbacks=[ckptcb, early_stopping],\n#                         verbose=2)\n    \n#     # Get the validation loss from the last epoch\n#     val_loss = min(history.history['val_loss'])\n#     val_losses.append(val_loss)\n#     histories.append(history)\n#     print()\n\n# # Calculate the mean validation loss\n# mean_val_loss = np.mean(val_losses)\n# print(\"Mean Validation Loss:\", mean_val_loss)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Training full model 5 folds\n\n# # Transferring weights \n# def transfer_weights(model_preprocessed, model):\n#     for layer in model.layers:\n#         origin_name = layer.name\n#         new_name = f\"{layer.name}_full\"\n#         layer.name = new_name    # Change the internal name attribute\n\n#         if any(origin_name == preprocessed_layer.name for preprocessed_layer in model_preprocessed.layers):\n#             layer.set_weights(model_preprocessed.get_layer(name=origin_name).get_weights())\n#             layer.trainable = True\n#     return model\n# #     model.summary() \n# #     model_preprocessed.summary()\n\n\n# # Train prepocessed model with K folds\n# tokenized_summaries_np = {\n#     'input_ids': tokenized_summaries['input_ids'].numpy(),\n#     'attention_mask': tokenized_summaries['attention_mask'].numpy(),\n#     'head_mask': head_mask.numpy(),\n# }\n\n# Y_train = tf.constant(train[['content', 'wording']].values, dtype=tf.float32)\n# Y_train_np = Y_train.numpy()\n\n# # Initialize the KFold object\n# kf = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n# folds = kf.split(X_train_input, Y_train_np)\n\n# # Initialize an empty list to store the validation losses\n# val_losses = []\n# histories = []\n\n# # Iterate over each fold\n# i = 0\n# for train_index, val_index in folds:\n            \n#     print(f\"Fold {i + 1}\")\n#     i += 1\n    \n#     # Split data into training and validation sets\n#     train_input_ids_fold, train_attention_mask_fold, train_head_mask_fold = tokenized_summaries_np['input_ids'][train_index], tokenized_summaries_np['attention_mask'][train_index], tokenized_summaries_np['head_mask'][train_index]\n#     val_input_ids_fold, val_attention_mask_fold, val_head_mask_fold = tokenized_summaries_np['input_ids'][val_index], tokenized_summaries_np['attention_mask'][val_index], tokenized_summaries_np['head_mask'][val_index]\n#     Y_train_fold, Y_val_fold = Y_train_np[train_index], Y_train_np[val_index]\n    \n#     # Create and compile your model\n#     model_preprocessed = create_model_preprocessed()\n#     model_preprocessed.load_weights(f'/kaggle/input/head-model-weights-folds/head_model_weights/model_fold_{i}.weights.h5')\n#     model, _ = create_model()\n#     model = transfer_weights(model_preprocessed, model)\n    \n#     early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n#     # Checkpoint callback\n#     ckptcb = keras.callbacks.ModelCheckpoint(\n#         f\"full_model_fold_{i}\" + \".weights.h5\",\n#         monitor=\"val_loss\",\n#         save_best_only=True,\n#         save_weights_only=True,\n#         mode=\"min\",\n#     )    \n\n#     # Train the model\n#     history = model.fit(x=[train_input_ids_fold, train_attention_mask_fold, train_head_mask_fold],\n#                         y=Y_train_fold,\n#                         epochs=100,\n#                         batch_size=4,\n#                         validation_data=([val_input_ids_fold, val_attention_mask_fold, val_head_mask_fold], Y_val_fold),\n#                         callbacks=[ckptcb, early_stopping],\n#                         verbose=1)\n    \n#     # Get the validation loss from the last epoch\n#     val_loss = min(history.history['val_loss'])\n#     val_losses.append(val_loss)\n#     histories.append(history)\n#     print()\n\n# # Calculate the mean validation loss\n# mean_val_loss = np.mean(val_losses)\n# print(\"Mean Validation Loss:\", mean_val_loss)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train full model no folds all data\n\n\n# Y_train = tf.constant(train[['content', 'wording']].values, dtype=tf.float32)\n# Y_train_np = Y_train.numpy()\n\n# Checkpoint callback\n# ckptcb = keras.callbacks.ModelCheckpoint(\n#     \"best_model\" + \".weights.h5\",\n#     monitor=\"loss\",\n#     save_best_only=True,\n#     save_weights_only=True,\n#     mode=\"min\",\n# )    \n\n# history = model.fit(x=[tokenized_summaries['input_ids'], tokenized_summaries['attention_mask'], head_mask],\n#                     y=Y_train_np,\n#                     epochs=6,\n#                     batch_size=4,\n#                     callbacks=[ckptcb],\n#                     verbose=1)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model with augmentation folds\n\n\n# tokenized_summaries_aug = tokenizer.batch_encode_plus(augmented_labeled_data['input'].tolist(),\n#                                               add_special_tokens=True,\n#                                               truncation=True,\n#                                               padding='max_length',\n#                                               return_tensors='tf',\n#                                               max_length=MAX_SUMMARY_LENGTH,\n#                                               return_attention_mask = True)\n# del tokenized_summaries_aug['token_type_ids']\n\n# # Create head mask that excludes anything but sep + prefix2 + train['text']\n# head_mask_aug = np.zeros(tokenized_summaries_aug['input_ids'].shape)\n# for i, summary in enumerate(tokenized_summaries_aug['input_ids'].numpy()):\n#     use_full = False\n#     for j, token in enumerate(summary):\n#         if token == tokenizer.sep_token_id:\n#             use_full = not use_full\n#         head_mask_aug[i][j] = (1 if use_full else 0) \n# head_mask_aug = tf.constant(head_mask_aug)\n\n# # Train prepocessed model with K folds\n# tokenized_summaries_np = {\n#     'input_ids': tokenized_summaries_aug['input_ids'].numpy(),\n#     'attention_mask': tokenized_summaries_aug['attention_mask'].numpy(),\n#     'head_mask': head_mask_aug.numpy(),\n# }\n\n# Y_train = tf.constant(augmented_labeled_data[['content', 'wording']].values, dtype=tf.float32)\n# Y_train_np = Y_train.numpy()\n\n# # Initialize the KFold object\n# kf = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n# folds = kf.split(tokenized_summaries_np['input_ids'], Y_train_np)\n\n# # Initialize an empty list to store the validation losses\n# val_losses = []\n# histories = []\n\n# # Iterate over each fold\n# i = 0\n# for train_index, val_index in folds:\n            \n#     print(f\"Fold {i + 1}\")\n#     i += 1\n    \n#     # Split data into training and validation sets\n#     train_input_ids_fold, train_attention_mask_fold, train_head_mask_fold = tokenized_summaries_np['input_ids'][train_index], tokenized_summaries_np['attention_mask'][train_index], tokenized_summaries_np['head_mask'][train_index]\n#     val_input_ids_fold, val_attention_mask_fold, val_head_mask_fold = tokenized_summaries_np['input_ids'][val_index], tokenized_summaries_np['attention_mask'][val_index], tokenized_summaries_np['head_mask'][val_index]\n#     Y_train_fold, Y_val_fold = Y_train_np[train_index], Y_train_np[val_index]\n    \n#     # Create and compile your model\n#     model, _ = create_model()\n#     model.load_weights(f'/kaggle/input/no-aug-model-folds-weights/no-aug-model-folds-weights/full_model_fold_{i}.weights.h5')\n#     early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n    \n#     # Checkpoint callback\n#     ckptcb = keras.callbacks.ModelCheckpoint(\n#         f\"aug_full_model_fold_{i}\" + \".weights.h5\",\n#         monitor=\"val_loss\",\n#         save_best_only=True,\n#         save_weights_only=True,\n#         mode=\"min\",\n#     )    \n\n#     # Train the model\n#     history = model.fit(x=[train_input_ids_fold, train_attention_mask_fold, train_head_mask_fold],\n#                         y=Y_train_fold,\n#                         epochs=100,\n#                         batch_size=4,\n#                         validation_data=([val_input_ids_fold, val_attention_mask_fold, val_head_mask_fold], Y_val_fold),\n#                         callbacks=[ckptcb, early_stopping],\n#                         verbose=1)\n    \n#     # Get the validation loss from the last epoch\n#     val_loss = min(history.history['val_loss'])\n#     val_losses.append(val_loss)\n#     histories.append(history)\n    \n#     del model \n#     gc.collect()\n#     print()\n\n# # Calculate the mean validation loss\n# mean_val_loss = np.mean(val_losses)\n# print(\"Mean Validation Loss:\", mean_val_loss)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting Meta Psuedo Labels\n\n# augmented_data[\"text\"] = augmented_data[\"text\"].apply(lambda x: spell(x))\n# augmented_data['input'] = prefix1 + augmented_data['prompt_question'] + sep + prefix2 + augmented_data['text']\n# augmented_data['input'][0]\n\n# tokenized_summaries_aug = tokenizer.batch_encode_plus(augmented_data['input'].tolist(),\n#                                               add_special_tokens=True,\n#                                               truncation=True,\n#                                               padding='max_length',\n#                                               return_tensors='tf',\n#                                               max_length=MAX_SUMMARY_LENGTH,\n#                                               return_attention_mask = True)\n# del tokenized_summaries_aug['token_type_ids']\n\n# # Create head mask that excludes anything but sep + prefix2 + train['text']\n# head_mask_aug = np.zeros(tokenized_summaries_aug['input_ids'].shape)\n# for i, summary in enumerate(tokenized_summaries_aug['input_ids'].numpy()):\n#     use_full = False\n#     for j, token in enumerate(summary):\n#         if token == tokenizer.sep_token_id:\n#             use_full = not use_full\n#         head_mask_aug[i][j] = (1 if use_full else 0) \n# head_mask_aug = tf.constant(head_mask_aug)\n\n# aug_input = {\n#     'input_ids': tokenized_summaries_aug['input_ids'],\n#     'attention_mask': tokenized_summaries_aug['attention_mask'],\n#     'head_mask': head_mask_aug,\n#     'student_id': augmented_data['student_id']\n# }\n\n# # ids, contents, wordings = generate_predictions(model, aug_input) # uncomment if not using folds\n\n# preds = []\n# for i in range(1,6):\n#     model, _ = create_model()\n#     model.load_weights(f'/kaggle/input/no-aug-model-folds-weights/no-aug-model-folds-weights/full_model_fold_{i}.weights.h5')\n    \n#     ids, contents, wordings = generate_predictions(model, aug_input)\n#     preds.append([ids, contents, wordings])\n#     del model\n#     gc.collect()\n    \n# # Calculate mean predictions\n# contents = np.stack([pred[1] for pred in preds]).mean(axis=0)\n# wordings = np.stack([pred[2] for pred in preds]).mean(axis=0)\n\n# augmented_data['content'] = contents\n# augmented_data['wording'] = wordings\n# augmented_data.to_csv(\"augmented_labeled_data.csv\")\n\n# augmented_labeled_data = pd.read_csv('/kaggle/input/augmented-labeled-data-folds/augmented_labeled_data.csv')\n# augmented_labeled_data['input'] = prefix1 + augmented_labeled_data['prompt_question'] + sep + prefix2 + augmented_labeled_data['text']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # NN full model\n# def create_model(input_shape=(1575,), embeddings_len=1024):\n#     pre_trained_model_instance = PreTrainedModel(pre_trained_model, name=\"deberta_layer\")\n\n#     # Input layers\n#     input_ids = keras.Input(shape=input_shape, dtype='int32', name='input_ids')\n#     attention_mask = keras.Input(shape=input_shape, dtype='int32', name='attention_mask')\n#     head_mask = keras.Input(shape=input_shape, dtype='float32', name='head_mask')\n    \n#     # Create embeddings and mask pool them\n#     deberta = pre_trained_model_instance(input_ids, attention_mask)\n#     h_mask = layers.Lambda(lambda x: tf.expand_dims(tf.cast(x, dtype=tf.float32), axis=-1), name='expand_dims')(head_mask)\n#     masked_outputs = layers.Lambda(lambda x: tf.multiply(x[0], x[1]), output_shape=(1575, 1024,), name='masked_embeddings')([deberta, h_mask])\n#     avg_pooling = layers.GlobalAveragePooling1D()(masked_outputs)\n    \n#     # Head of NN\n#     x = layers.LayerNormalization(name='layer_norm1')(avg_pooling)\n#     x = layers.Reshape((1, embeddings_len), name='reshape_layer')(x)\n    \n#     x = layers.LSTM(512, return_sequences=True, name='LSTM_layer1', activation='linear')(x)\n#     x = layers.LayerNormalization(name='layer_norm2')(x)\n#     x = layers.Activation(keras.activations.tanh, name='tanh1')(x)\n#     x = layers.LSTM(32, return_sequences=False, name='LSTM_layer2', activation='linear',)(x)\n#     x = layers.LayerNormalization(name='layer_norm3')(x)\n#     x = layers.Activation(keras.activations.tanh, name='tanh2')(x)\n    \n#     x = layers.Dense(16, activation='linear', name='dense_layer')(x)\n#     x = layers.Dropout(0.3, name='dropout_layer')(x)\n#     output_layer = layers.Dense(2, activation='linear', name='output_layer')(x)\n    \n#     model = keras.Model(inputs=[input_ids, attention_mask, head_mask], outputs=output_layer)\n\n#     for layer in model.layers:\n#         layer.trainable = True\n    \n#     opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n#     model.compile(loss=mcrmse, optimizer=opt)\n    \n#     return model, pre_trained_model_instance\n\n# # model, deberta_model = create_model()\n# # model.summary()\n\n# # model.load_weights(\"/kaggle/input/no-aug-model-weights/no_augmentation_model.weights.h5\")\n# # deberta_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sep = f\" {tokenizer.sep_token} \"\n# prefix1 = \"Think through this step by step: \"\n# prefix2 = \"Pay attention to the content and wording: \"\n# MAX_SUMMARY_LENGTH = 1500 + len(prefix1) + len(prefix2)\n\n# # Tokenization + Head Mask creation\n# def preprocess_summary(data, label=None):\n    \n#     print(data.shape)\n#     summary, prompt_question = data\n#     summary = summary.numpy().decode()\n#     prompt_question= prompt_question.numpy().decode()\n    \n#     summary = spell(summary)\n#     summary = prefix1 + prompt_question + sep + prefix2 + summary\n#     # Tokenize the summary\n#     tokenized = tokenizer(summary,\n#                           truncation=True,\n#                           padding='max_length',\n#                           return_tensors='tf',\n#                           max_length=MAX_SUMMARY_LENGTH,\n#                           return_attention_mask=True)\n    \n#     input_ids = tokenized['input_ids']\n#     attention_mask = tokenized['attention_mask']\n\n#     # Create head mask\n#     head_mask = np.zeros_like(input_ids)\n#     use_full = False\n#     for j, token in enumerate(input_ids[0]):\n#         if token == tokenizer.sep_token_id:\n#             use_full = not use_full\n#         head_mask[0][j] = 1 if use_full else 0\n#     head_mask = tf.constant(head_mask, dtype=tf.int32)\n      \n#     if label is None:\n#         return input_ids[0], attention_mask[0], head_mask[0]\n#     else:\n#         return (input_ids[0], attention_mask[0], head_mask[0]), label\n\n# # wrapper function to work with keras dataloader\n# def preprocess_summary_wrapper(data, label=None):\n#     if label is None:\n#         output = tf.py_function(preprocess_summary, [data], [tf.int32])\n#     else:\n#         output = tf.py_function(preprocess_summary, [data, label], [tf.int32, tf.float64])\n#         output[1].set_shape([2])\n        \n#     output[0][0].set_shape([MAX_SUMMARY_LENGTH])\n#     output[0][1].set_shape([MAX_SUMMARY_LENGTH])\n#     output[0][2].set_shape([MAX_SUMMARY_LENGTH])\n#     output[0].set_shape([3])\n#     return output[0], output[1]\n\n# # split in NN to inout ids, attention mask and head mask\n# def split_input(inputs):\n#     split_tensors = tf.split(inputs, num_or_size_splits=3, axis=1)\n#     # Remove the redundant dimension\n#     input_ids = tf.cast(tf.squeeze(split_tensors[0], axis=1), tf.int32)\n#     attention_mask = tf.cast(tf.squeeze(split_tensors[1], axis=1), tf.int32)\n#     head_mask = tf.cast(tf.squeeze(split_tensors[2], axis=1), tf.float32)\n#     return input_ids, attention_mask, head_mask\n\n# Data Loader\n\n# def build_dataset(data, labels=None, batch_size=4, cache=True, shuffle=True):\n#     AUTOTUNE = tf.data.AUTOTUNE\n\n#     dataset = tf.data.Dataset.from_tensor_slices(data) if labels is None else tf.data.Dataset.from_tensor_slices((data, labels))    \n#     dataset = dataset.cache() if cache else dataset\n    \n#     # tokenize + preprocess summaries\n#     if labels is None:\n#         dataset = dataset.map(lambda x: preprocess_summary_wrapper(x), num_parallel_calls=2)\n#     else:\n#         dataset = dataset.map(lambda x, y: preprocess_summary_wrapper(x, y), num_parallel_calls=2)\n        \n#     dataset = dataset.shuffle(buffer_size=len(data), seed=random_seed) if shuffle else dataset\n        \n#     # CAN ADD AUGMENTATION PREPROCESS HERE\n    \n#     # Batch and prefetch the dataset\n#     dataset = dataset.batch(batch_size, drop_remainder=True)\n#     dataset = dataset.prefetch(AUTOTUNE)\n    \n#     return dataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    # Head of NN\n#     x = layers.LayerNormalization(name='layer_norm1')(avg_pooling)\n#     x = layers.Reshape((1, embeddings_len), name='reshape_layer')(x)\n    \n#     x = layers.LSTM(64, return_sequences=True, name='LSTM_layer1', activation='linear')(x)\n#     x = layers.LayerNormalization(name='layer_norm2')(x)\n#     x = layers.Activation(keras.activations.tanh, name='tanh1')(x)\n#     x = layers.LSTM(16, return_sequences=False, name='LSTM_layer2', activation='linear',)(x)\n#     x = layers.LayerNormalization(name='layer_norm3')(x)\n#     x = layers.Activation(keras.activations.tanh, name='tanh2')(x)\n#     x = layers.Dropout(0.3, name='dropout_layer')(x)\n    \n#     x = layers.Dense(16, activation='linear', name='dense_layer')(x)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Auto correcting spellings of all summaries\n# sep = f\" {tokenizer.sep_token} \"\n\n# prefix1 = \"Think through this step by step: \"\n# prefix2 = \"Pay attention to the content and wording: \"\n\n# train[\"text\"] = train[\"text\"].apply(lambda x: spell(x))\n# train['input'] = prefix1 + train['prompt_question'] + sep + prefix2 + train['text']\n# print(train['input'][0])\n\n# # Tokenize text data\n# MAX_SUMMARY_LENGTH = 1500 + len(prefix1) + len(prefix2)\n\n# tokenized_summaries = tokenizer.batch_encode_plus(train['input'].tolist(),\n#                                               add_special_tokens=False,\n#                                               truncation=True,\n#                                               padding='max_length',\n#                                               return_tensors='tf',\n#                                               max_length=MAX_SUMMARY_LENGTH,\n#                                               return_attention_mask=True)\n# del tokenized_summaries['token_type_ids']\n\n# # Create head mask that excludes anything but sep + prefix2 + train['text']\n# head_mask = np.zeros(tokenized_summaries['input_ids'].shape)\n# for i, summary in enumerate(tokenized_summaries['input_ids'].numpy()):\n#     use_full = False\n#     for j, token in enumerate(summary):\n#         if token == tokenizer.sep_token_id:\n#             use_full = not use_full  \n#         head_mask[i][j] = (1 if use_full else 0) \n# head_mask = tf.constant(head_mask)\n# head_mask\n\n\n\n\n\n\n# # DeBERTa \n# file_path = '/kaggle/input/pooled-deberta-embeddings/pooled_deberta_embeddings.csv'# from input folder\n\n# # Load masked pooled Deberta embeddings\n# with open('/kaggle/input/masked-pooled-deberta-embeddings/masked_pooled_deberta_embeddings_no_title.pkl', 'rb') as f:\n#     loaded_array = pickle.load(f)\n# # Load embeddings\n# X_train_preprocessed = pd.read_csv(file_path)\n\n\n# X_train_preprocessed['embeddings'] = X_train_preprocessed['embeddings'].apply(lambda x: list(map(float, x.split(','))))\n# X_train_preprocessed['masked_embeddings'] = loaded_array.tolist()\n# # Save a csv file\n# # df_to_save = df_with_embeddings['pooled_roberta_embedding'].apply(lambda x: ','.join(map(str, x)))\n# # df_to_save.to_csv(file_path, index=False)\n\n\n\n\n# Y_train = tf.constant(train[['content', 'wording']].values, dtype=tf.float32)\n# Y_train_np = Y_train.numpy()\n# X_train_input = np.array(X_train_preprocessed['masked_embeddings'].tolist())\n\n# # The loss function\n# def mcrmse(y_true, y_pred):\n#     columnwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=0)\n#     return tf.reduce_mean(tf.sqrt(columnwise_mse), axis=-1)\n\n# init_lr = 0.00015\n# lr_schedule = tf.keras.optimizers.schedules.CosineDecay(init_lr, decay_steps=100000)\n\n\n\n\n# # def concat_embedding(x):\n# #     expanded_text_embedding = tf.expand_dims(prefix_embed, axis=0)\n# #     tiled_text_embedding = tf.tile(expanded_text_embedding, [tf.shape(x)[0], 1, 1])\n# #     expanded_input_tensor = tf.expand_dims(x, axis=1)\n# #     return tf.concat([tiled_text_embedding, expanded_input_tensor], axis=1)\n\n# # # Use prefix2 embed\n# #\n# # prefix_tensor = tokenizer.encode(prefix, add_special_tokens=False, return_tensors='tf')\n# # tokenized_prefix = tokenizer.encode(prefix2, add_special_tokens=False, return_tensors='tf')\n# # prefix_len = len(tokenized_prefix)\n# # prefix_embed = pre_trained_model(tokenized_prefix)[0]\n# # prefix_embed = tf.cast(tf.reduce_mean(prefix_embed, axis=1), dtype=tf.float16)\n\n# # NN with embeddings preprocessed\n# def create_model_preprocessed():\n#     input_shape = len(X_train_preprocessed['masked_embeddings'][0])\n#     input_layer = keras.Input(shape=(input_shape, ), dtype='float32')\n    \n#     x = layers.LayerNormalization(name='layer_norm1')(input_layer)\n#     x = layers.Reshape((1,input_shape,), name='reshape_layer')(x)\n#     x = layers.LSTM(128, return_sequences=True, name='LSTM_layer1', activation='linear')(x)\n#     x = layers.LayerNormalization(name='layer_norm2')(x)\n#     x = layers.Activation(keras.activations.tanh, name='tanh1')(x)\n    \n#     x = layers.LSTM(32, return_sequences=True, name='LSTM_layer2', activation='linear')(x)\n#     x = layers.LayerNormalization(name='layer_norm3')(x)\n#     x = layers.Activation(keras.activations.tanh, name='tanh2')(x)\n#     x = layers.Dropout(0.4, name='dropout_layer')(x)\n#     x = layers.GlobalAveragePooling1D()(x)\n    \n# #     x = layers.Dense(16, activation='linear', name='dense_layer')(x)\n# #     x = layers.Dropout(0.5, name='dropout_layer3')(x)\n\n#     output_layer = layers.Dense(2, activation='linear', name='output_layer')(x)\n    \n#     model = keras.Model(inputs=input_layer, outputs=output_layer)\n\n#     for layer in model.layers:\n#         layer.trainable = True\n\n#     opt = keras.optimizers.Adam(learning_rate=lr_schedule, use_ema=True)\n#     model.compile(loss=mcrmse, optimizer=opt)\n    \n#     return model\n\n# model = create_model_preprocessed()\n# model.summary()\n\n\n\n\n\n\n# # Train head only model\n# val_losses = []\n# histories = []\n# gkf = GroupKFold(n_splits=4)\n# folds = gkf.split(X_train_input, Y_train_np, groups=train['prompt_id'])\n\n# for i, (train_index, val_index) in enumerate(folds):\n#     print(f\"Fold {i + 1}\")\n    \n#     # Split data into training and validation sets\n#     X_train_fold, X_val_fold = X_train_input[train_index], X_train_input[val_index]\n#     Y_train_fold, Y_val_fold = Y_train_np[train_index], Y_train_np[val_index]\n    \n#     # Create and compile your model\n#     model = create_model_preprocessed()\n#     early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n#     ema = keras.callbacks.SwapEMAWeights(swap_on_epoch=True)\n#     # Checkpoint callback\n# #     ckptcb = keras.callbacks.ModelCheckpoint(\n# #         f\"model_fold_{i}\" + \".weights.h5\",\n# #         monitor=\"val_loss\",\n# #         save_best_only=True,\n# #         save_weights_only=True,\n# #         mode=\"min\",\n# #     )    \n\n#     # Train the model\n#     history = model.fit(x=X_train_fold,\n#                         y=Y_train_fold,\n#                         epochs=100,\n#                         batch_size=4,\n#                         validation_data=(X_val_fold, Y_val_fold),\n#                         callbacks=[ema, early_stopping],\n#                         verbose=2)\n    \n#     # Get the validation loss from the last epoch\n#     val_loss = min(history.history['val_loss'])\n#     val_losses.append(val_loss)\n#     histories.append(history)\n#     print()\n\n# # Calculate the mean validation loss\n# mean_val_loss = np.mean(val_losses)\n# print(\"Mean Validation Loss:\", mean_val_loss)\n\n\n\n\n# **Results**\n\n# REAL RESULTS\n\n# baseline no grouped KFolds: 0.4437254548072815\n# baseline with grouped KFolds: 0.5310284495353699\n# From now on everything will be with grouped KFolds\n# EMA: 0.5303183048963547\n# EMA + lr_decay_steps=100000 + LSTM1=128 + LSTM2=64 + Dropout_after_LSTM2=0.6: 0.5258100032806396\n# EMA + lr_decay_steps=100000 + LSTM1=128 + LSTM2=32 + Dropout_after_LSTM2=0.4: 0.5223950520157814\n\n\n# FAKE RESULTS:\n# group: 0.421 | 0.41956\n# with regularization everywhere: 0.6671039313077927\n# with reg=0.0001: 0.48\n# with reg=1e-5: 0.4328196793794632\n# without Dense layers of 16: 0.4203761890530586\n# reduce Dropout to 0.2: 0.415641151368618\n# dropout: 0.5, dense: relu +32, LSTM: 64: 0.44807666540145874 (large gap :> ) \n# With EMA: 0.4412180408835411 (keeped the large gaps)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Full Model Baseline\n# def create_model(input_shape=(1575,), embeddings_len=1024):\n    \n#     # Instances\n#     pre_trained_model_instance = PreTrainedModel(pre_trained_model, name=\"deberta_layer\")\n#     expand_dims_instance = layers.Lambda(lambda x: tf.expand_dims(tf.cast(x, dtype=tf.float32), axis=-1), name=f'expand_dims')\n#     mask_instance = layers.Lambda(lambda x: tf.multiply(x[0], x[1]), output_shape=(1575, embeddings_len,), name='masked_embeddings')\n#     avg_pooling_instance = layers.GlobalAveragePooling1D()\n#     reshape_instance1 = layers.Reshape((1, -1), name='reshape_layer1')\n#     reshape_instance2 = layers.Reshape((1, -1), name='reshape_layer2')\n#     dense_instance = layers.Dense(2, activation='linear')\n    \n#     # The NN starts from here\n    \n#     # Input layers\n#     input_ids = keras.Input(shape=input_shape, dtype='int32', name='input_ids')\n#     attention_mask = keras.Input(shape=input_shape, dtype='int32', name='attention_mask')\n#     head_mask = keras.Input(shape=input_shape, dtype='float32', name='head_mask')\n    \n#     # Create embeddings and get all hidden states\n#     deberta = pre_trained_model_instance(input_ids, attention_mask)\n    \n#     # Mask pooling all hidden states of pre-trained model\n#     pooled_hidden_states = []\n#     for i in range(len(deberta)):\n#         h_mask = expand_dims_instance(head_mask)\n#         masked_outputs = mask_instance([deberta[-i], h_mask])\n#         avg_pooling_layer = avg_pooling_instance(masked_outputs)\n#         reshape_layer = reshape_instance1(avg_pooling_layer)\n#         pooled_hidden_states.append(reshape_layer)\n        \n#     # Concatenate all the hidden states an forward pass through LSTM\n#     x = layers.Concatenate(axis=1)(pooled_hidden_states)\n#     x = layers.LSTM(embeddings_len, return_sequences=False)(x)\n    \n#     # Multi-sample Dropout\n#     x = layers.Dropout(0.1)(x)\n#     dropoutList = [reshape_instance2(dense_instance(layers.Dropout((i + 1) * 0.1)(x))) for i in range(5)]\n#     x = layers.Concatenate(axis=1)(dropoutList)\n    \n#     output_layer = layers.GlobalAveragePooling1D()(x)\n#     # output_layer = layers.Dense(2, activation='linear', name='output_layer')(x)\n    \n    \n#     model = keras.Model(inputs=[input_ids, attention_mask, head_mask], outputs=output_layer)\n#     for layer in model.layers:\n#         layer.trainable = True\n    \n#     opt = keras.optimizers.AdamW(learning_rate=lr_schedule, use_ema=True)\n#     model.compile(loss=mcrmse, optimizer=opt)\n#     return model, pre_trained_model_instance\n\n# # model, deberta_model = create_model()\n# # model.summary()\n\n# # model.load_weights(\"/kaggle/input/no-aug-model-weights/no_augmentation_model.weights.h5\")\n# # deberta_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from transformers import AutoConfig, TFAutoModelForSequenceClassification\n# model_config = AutoConfig.from_pretrained(\"microsoft/deberta-v3-large\", num_labels=2)\n# model_config.update({\n#     \"hidden_dropout_prob\": 0.,\n#     \"attention_probs_dropout_prob\": 0.,\n#     \"problem_type\": \"regression\",\n# })\n# model = TFAutoModelForSequenceClassification.from_pretrained('microsoft/deberta-v3-large', config=model_config)\n# tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-large')\n\n# # Debug to check if worked:\n# print(model.config.hidden_dropout_prob)\n# print(model.config.hidden_dropout_prob)\n# print(model.config.problem_type)\n# print(model.config.num_labels)\n\n# class DebertaRegressor(keras.Model):\n#     def __init__(self, model_path, trainable=False, num_layers_to_freeze=8, name=None, **kwargs):\n#         super().__init__(name=name, **kwargs)\n#         self.model_config = AutoConfig.from_pretrained(model_path, num_labels=2) \n#         self.model_config.update({\n#             \"hidden_dropout_prob\": 0.,\n#             \"attention_probs_dropout_prob\": 0.,\n#             \"problem_type\": \"regression\",\n#         })\n#         self.model = TFAutoModelForSequenceClassification.from_pretrained(model_path, config=self.model_config)\n#         self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n        \n#         # Dynamically create properties from pre-trained model\n# #         for prop_name, prop in inspect.getmembers(self.model):\n# #             if not prop_name.startswith('_') and not inspect.ismethod(prop):\n# #                 setattr(self.__class__, prop_name, prop)\n\n#     def call(self, input_ids, attention_mask):\n#         # Call the pre trained model and get the last hidden state\n#         return self.model(input_ids=input_ids, attention_mask=attention_mask).logits\n\n# # HyperParameters\n# init_lr = 0.00015\n# batch_size = 8\n# epochs = 3\n\n\n# def build_model(input_shape=(1575,), decay_steps=10000, warmup_steps=100):\n#     # deberta instance\n#     deberta = DebertaRegressor(\"microsoft/deberta-v3-large\")\n    \n#     input_ids = keras.Input(shape=input_shape, dtype='int32', name='input_ids')\n#     attention_mask = keras.Input(shape=input_shape, dtype='int32', name='attention_mask')\n#     output_layer = deberta(input_ids, attention_mask)\n    \n#     model = keras.Model(inputs=[input_ids, attention_mask], outputs=output_layer)\n#     lr_schedule = keras.optimizers.schedules.CosineDecay(initial_learning_rate=init_lr,\n#                                                             decay_steps=decay_steps,\n#                                                             warmup_target=init_lr,\n#                                                             warmup_steps=warmup_steps,\n#                                                            )\n#     opt = keras.optimizers.AdamW(learning_rate=lr_schedule)\n#     model.compile(loss=mcrmse, optimizer=opt)\n#     return model, deberta\n# # test_model = build_model()\n# # test_model.summary()\n\n# # Train full model with GroupKFolds\n\n# X = train[['text', 'prompt_question', 'prompt_text']]\n# y = train[['content', 'wording']].astype('float16')\n\n# gkf = GroupKFold(n_splits=4)\n# folds = gkf.split(X, y, groups=train['prompt_id'])\n\n# val_losses = []\n# histories = []\n\n# for i, (train_index, val_index) in enumerate(folds):\n#     print(f\"Fold {i}\")\n#     if i != 3:\n#         continue\n\n#     # X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n#     # y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n\n#     decay_steps = math.ceil((len(X_train_fold) / batch_size) * epochs) \n#     model, deberta = build_model(decay_steps=decay_steps)\n\n#     # X_train_fold = build_dataset(X_train_fold['text'], X_train_fold['prompt_question'], X_train_fold['prompt_text'], deberta.tokenizer)\n#     # X_val_fold = build_dataset(X_val_fold['text'], X_val_fold['prompt_question'], X_val_fold['prompt_text'], deberta.tokenizer)\n\n\n#     # early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n#     # ema = keras.callbacks.SwapEMAWeights(swap_on_epoch=True)\n\n#     # Checkpoint callback\n#     ckptcb = keras.callbacks.ModelCheckpoint(\n#         f\"full_model_fold_{i}\" + \".weights.h5\",\n#         monitor=\"val_loss\",\n#         save_best_only=True,\n#         save_weights_only=True,\n#         mode=\"min\",\n#     ) \n\n#     history = model.fit(x=X_train_fold[:2],\n#                             y=y_train_fold.values,\n#                             validation_data=(X_val_fold[:2], y_val_fold.values),\n#                             epochs=epochs,\n#                             batch_size=batch_size,\n#                             callbacks=[ckptcb],\n#                             verbose=1)\n\n#     # Get the validation loss from the last epoch\n#     val_loss = min(history.history['val_loss'])\n#     val_losses.append(val_loss)\n#     histories.append(history)\n#     print()\n\n# # Calculate the mean validation loss\n# mean_val_loss = np.mean(val_losses)\n# print(\"Mean Validation Loss:\", mean_val_loss)","metadata":{},"execution_count":null,"outputs":[]}]}