{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":53482,"databundleVersionId":6201832,"sourceType":"competition"},{"sourceId":8139549,"sourceType":"datasetVersion","datasetId":4812209},{"sourceId":8139552,"sourceType":"datasetVersion","datasetId":4812212},{"sourceId":8146152,"sourceType":"datasetVersion","datasetId":4817190},{"sourceId":8421200,"sourceType":"datasetVersion","datasetId":5013476},{"sourceId":8469314,"sourceType":"datasetVersion","datasetId":5049859}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":109.119668,"end_time":"2024-05-16T15:40:29.014408","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-05-16T15:38:39.894740","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"059a11eda62448da981f7b2667b94637":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d4e90cc3beb40b890ffd3978dfb22d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"150f7c2a80124dad8408945c7c4a0fce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15104f9159d1410eb85b6379bc0756c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff9e6813dd3d499f8c44902f3806b49c","IPY_MODEL_588ef8f9110e4ba8897785a7816b52a6","IPY_MODEL_afa499e764d4423fbc616d6a8de52fd0"],"layout":"IPY_MODEL_deefef886f9c43cf88f6f162100f2e3e"}},"1982a9459b644ddf93b0670b17ed6427":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b2c1961d94c4a07b162c8e1f1f4ea8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e281edfb4944800b70ca3e7b078cd13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f7d29516b7a46dcb0fa01415173e1df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"25126573d458497987981721450a08ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c8166010478471ebcfeaff488254cc3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ed7fd040a494b91bcb6b11bf17446a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c55a6f3b2d6453d92734e1c2c6ccf3d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f8ee3fcf5ed47f08eb3eeaff0647d5e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42cdc6d0d53e4ab298128b8581bf4c3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c8166010478471ebcfeaff488254cc3","placeholder":"​","style":"IPY_MODEL_059a11eda62448da981f7b2667b94637","value":" 2.46M/2.46M [00:00&lt;00:00, 3.68MB/s]"}},"464d8379cbd842b6b0c919aa12c237ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1982a9459b644ddf93b0670b17ed6427","placeholder":"​","style":"IPY_MODEL_a0ed8c5740e846b7912490fe3541991c","value":"spm.model: 100%"}},"57d07143c3b54fb2baad23f96e0874aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"588ef8f9110e4ba8897785a7816b52a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d4e90cc3beb40b890ffd3978dfb22d8","max":1736592160,"min":0,"orientation":"horizontal","style":"IPY_MODEL_150f7c2a80124dad8408945c7c4a0fce","value":1736592160}},"640eb7d806d7408ba3ba560fa99b9142":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73ed4c4fc9104779b8fdb3fc52e64f4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa4f2028d4be4adfb1389b240b2c7ee0","placeholder":"​","style":"IPY_MODEL_cd53dfa32e15440aadac97ed88dbec02","value":" 580/580 [00:00&lt;00:00, 52.0kB/s]"}},"76c12b9e7502419da6c5d8afae0b45ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eb63820b62d49ea9bc8059798aabfb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_464d8379cbd842b6b0c919aa12c237ad","IPY_MODEL_d006714a85f746a2a1485b6e1faf7003","IPY_MODEL_42cdc6d0d53e4ab298128b8581bf4c3a"],"layout":"IPY_MODEL_25126573d458497987981721450a08ae"}},"999bd4cca8c94c3a8c59da5cb58d8c2e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ae4657f98844aa686e0a73f6bb69972":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_efc7d8e9f3cc457f93faf7367ab86cd3","IPY_MODEL_f37802e035ff44d181776f86eabe948d","IPY_MODEL_a915e75f5ed847a7b44823aadb68b8e3"],"layout":"IPY_MODEL_9cc123d4a6da4ac9bf37029593171ca6"}},"9cc123d4a6da4ac9bf37029593171ca6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d8022fde15349cf92f52a24eac326ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0ed8c5740e846b7912490fe3541991c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a915e75f5ed847a7b44823aadb68b8e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_640eb7d806d7408ba3ba560fa99b9142","placeholder":"​","style":"IPY_MODEL_1e281edfb4944800b70ca3e7b078cd13","value":" 52.0/52.0 [00:00&lt;00:00, 4.37kB/s]"}},"aa1ceb8e11cc412ea3062b14dcb51319":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3852559827e4748844d3b2927447926","max":580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b2c1961d94c4a07b162c8e1f1f4ea8f","value":580}},"aa4f2028d4be4adfb1389b240b2c7ee0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad398d8a95ab459abdfa03879da117ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afa499e764d4423fbc616d6a8de52fd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8b1ba7cf2354528ab658faf56c8985f","placeholder":"​","style":"IPY_MODEL_c4ef64c1429c4d049c4b952e1906bf5e","value":" 1.74G/1.74G [00:41&lt;00:00, 42.6MB/s]"}},"b3852559827e4748844d3b2927447926":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba8f192523cf4f3d81fe72f0c6b16060":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4ef64c1429c4d049c4b952e1906bf5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cae13970055a44a09fbe31e19911087a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76c12b9e7502419da6c5d8afae0b45ab","placeholder":"​","style":"IPY_MODEL_2ed7fd040a494b91bcb6b11bf17446a7","value":"config.json: 100%"}},"cd53dfa32e15440aadac97ed88dbec02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cde68addf7004559a03c89e3c5cd5070":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d006714a85f746a2a1485b6e1faf7003":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba8f192523cf4f3d81fe72f0c6b16060","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57d07143c3b54fb2baad23f96e0874aa","value":2464616}},"deefef886f9c43cf88f6f162100f2e3e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8b1ba7cf2354528ab658faf56c8985f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efc7d8e9f3cc457f93faf7367ab86cd3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f8ee3fcf5ed47f08eb3eeaff0647d5e","placeholder":"​","style":"IPY_MODEL_cde68addf7004559a03c89e3c5cd5070","value":"tokenizer_config.json: 100%"}},"f37802e035ff44d181776f86eabe948d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c55a6f3b2d6453d92734e1c2c6ccf3d","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f7d29516b7a46dcb0fa01415173e1df","value":52}},"f37f807ded5e4af5a607d3a76b4de99f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cae13970055a44a09fbe31e19911087a","IPY_MODEL_aa1ceb8e11cc412ea3062b14dcb51319","IPY_MODEL_73ed4c4fc9104779b8fdb3fc52e64f4e"],"layout":"IPY_MODEL_9d8022fde15349cf92f52a24eac326ed"}},"ff9e6813dd3d499f8c44902f3806b49c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_999bd4cca8c94c3a8c59da5cb58d8c2e","placeholder":"​","style":"IPY_MODEL_ad398d8a95ab459abdfa03879da117ba","value":"tf_model.h5: 100%"}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-16T15:38:42.556819Z","iopub.status.busy":"2024-05-16T15:38:42.556494Z","iopub.status.idle":"2024-05-16T15:38:42.561206Z","shell.execute_reply":"2024-05-16T15:38:42.560454Z"},"papermill":{"duration":0.030666,"end_time":"2024-05-16T15:38:42.563061","exception":false,"start_time":"2024-05-16T15:38:42.532395","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport warnings\nimport logging\nimport pickle\nimport inspect\nimport os\nimport gc\n\n# disabling unnecceseray warnings\nwarnings.simplefilter(\"ignore\")\nlogging.disable(logging.ERROR)\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport tensorflow as tf\nfrom transformers import TFAutoModel, AutoTokenizer\nfrom tensorflow import keras\nfrom keras import layers\nimport datetime\nfrom keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\n\nkeras.mixed_precision.set_global_policy(\"mixed_float16\")\n\n# Limit the GPU memory growth using TensorFlow\nphysical_devices = tf.config.list_physical_devices('GPU')\ntf.config.experimental.set_memory_growth(physical_devices[0], True)\n# tf.config.experimental.set_memory_growth(physical_devices[1], True)\n\nimport random\n\n# Set random seeds\nrandom_seed = 42\nnp.random.seed(random_seed)\ntf.random.set_seed(random_seed)\nrandom.seed(random_seed)\nkeras.utils.set_random_seed(random_seed)\n\n!pip install autocorrect\nfrom autocorrect import Speller\nspell = Speller(lang='en', fast=True)\nspell('helo')","metadata":{"papermill":{"duration":33.079441,"end_time":"2024-05-16T15:39:15.664457","exception":false,"start_time":"2024-05-16T15:38:42.585016","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-23T17:28:28.194064Z","iopub.execute_input":"2024-05-23T17:28:28.194590Z","iopub.status.idle":"2024-05-23T17:29:01.969178Z","shell.execute_reply.started":"2024-05-23T17:28:28.194549Z","shell.execute_reply":"2024-05-23T17:29:01.968196Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting autocorrect\n  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.8/622.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: autocorrect\n  Building wheel for autocorrect (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622364 sha256=1322d80d72b7f3454d188bdfdb417964c0bc9bd21a3eb1929ca5505302b80b40\n  Stored in directory: /root/.cache/pip/wheels/b5/7b/6d/b76b29ce11ff8e2521c8c7dd0e5bfee4fb1789d76193124343\nSuccessfully built autocorrect\nInstalling collected packages: autocorrect\nSuccessfully installed autocorrect-2.6.1\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'held'"},"metadata":{}}]},{"cell_type":"code","source":"data_path = '/kaggle/input/commonlit-evaluate-student-summaries/'\n\n# prompts train\ntrain_pro = pd.read_csv(data_path + 'prompts_train.csv')\ntrain_pro.head(1)\n\n# summaries train\ntrain_sum = pd.read_csv(data_path + 'summaries_train.csv')\ntrain_sum.head(1)\n\ntrain = train_pro.merge(train_sum , on = \"prompt_id\")\ntrain.head(1)\n\n# prompts test\ntest_pro = pd.read_csv(data_path + 'prompts_test.csv')\ntest_pro.head(1)\n\n# summaries test\ntest_sum = pd.read_csv(data_path + 'summaries_test.csv')\ntest_sum.head(1)\ntest = test_pro.merge(test_sum , on = \"prompt_id\")\ntest.head()","metadata":{"papermill":{"duration":0.175105,"end_time":"2024-05-16T15:39:15.917548","exception":false,"start_time":"2024-05-16T15:39:15.742443","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-23T17:29:01.971447Z","iopub.execute_input":"2024-05-23T17:29:01.972064Z","iopub.status.idle":"2024-05-23T17:29:02.100150Z","shell.execute_reply.started":"2024-05-23T17:29:01.972028Z","shell.execute_reply":"2024-05-23T17:29:02.099280Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"  prompt_id                                    prompt_question prompt_title  \\\n0    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n\n                                         prompt_text    student_id  \\\n0  Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f   \n\n                                                text   content   wording  \n0  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>student_id</th>\n      <th>text</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>00791789cc1f</td>\n      <td>1 element of an ideal tragedy is that it shoul...</td>\n      <td>-0.210614</td>\n      <td>-0.471415</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Model name to load\nmodel_name =  \"microsoft/deberta-v3-large\"\n\n# Load DeBERTa / RoBERTa model and tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name)\npre_trained_model = TFAutoModel.from_pretrained(model_name)","metadata":{"papermill":{"duration":52.227164,"end_time":"2024-05-16T15:40:08.168031","exception":false,"start_time":"2024-05-16T15:39:15.940867","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-23T17:29:13.325228Z","iopub.execute_input":"2024-05-23T17:29:13.325989Z","iopub.status.idle":"2024-05-23T17:29:26.669737Z","shell.execute_reply.started":"2024-05-23T17:29:13.325957Z","shell.execute_reply":"2024-05-23T17:29:26.668665Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ee387e3c4594d85ab7d6af587656278"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccc861266a4840919364a9e69684334d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8c9134eaac343d4b03fea2a74687df2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tf_model.h5:   0%|          | 0.00/1.74G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6247f6587f8433987d30f8433759376"}},"metadata":{}}]},{"cell_type":"code","source":"# Auto correcting spellings of all summaries\nsep = f\" {tokenizer.sep_token} \"\n\nprefix1 = \"Think through this step by step: \"\nprefix2 = \"Pay attention to the content and wording: \"\n\ntrain[\"text\"] = train[\"text\"].apply(lambda x: spell(x))\ntrain['input'] = train['prompt_title'] + sep + prefix1 + train['prompt_question'] + sep + prefix2 + train['text']\ntrain['input'][0]","metadata":{"papermill":{"duration":9.133516,"end_time":"2024-05-16T15:40:17.326497","exception":false,"start_time":"2024-05-16T15:40:08.192981","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-23T17:29:29.745945Z","iopub.execute_input":"2024-05-23T17:29:29.746536Z","iopub.status.idle":"2024-05-23T17:29:38.951511Z","shell.execute_reply.started":"2024-05-23T17:29:29.746507Z","shell.execute_reply":"2024-05-23T17:29:38.950669Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'On Tragedy [SEP] Think through this step by step: Summarize at least 3 elements of an ideal tragedy, as described by Aristotle. [SEP] Pay attention to the content and wording: 1 element of an ideal tragedy is that it should be arranged on a complex plan.  Another element of an ideal tragedy is that it should only have one main issue. The last element of an ideal tragedy is that it should have a double thread plot and an opposite catastrophe for both good and bad.'"},"metadata":{}}]},{"cell_type":"code","source":"# Preprocessing features and labels\n\n# Tokenize text data\n\n# Change MAX_SUMMARY_LENGTH\nMAX_SUMMARY_LENGTH = 1500 + len(prefix1) + len(prefix2)\n\n# DEBERTA / RoBERTa Tokenizing\nX_train = tokenizer.batch_encode_plus(train['input'].tolist(),\n                                              add_special_tokens=True,\n                                              truncation=True,\n                                              padding='max_length',\n                                              return_tensors='tf',\n                                              max_length=MAX_SUMMARY_LENGTH,\n                                              return_attention_mask = True)\ndel X_train['token_type_ids']\n\nY_train = tf.constant(train[['content', 'wording']].values, dtype=tf.float32)","metadata":{"papermill":{"duration":6.221924,"end_time":"2024-05-16T15:40:23.962893","exception":false,"start_time":"2024-05-16T15:40:17.740969","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-23T17:29:38.952911Z","iopub.execute_input":"2024-05-23T17:29:38.953119Z","iopub.status.idle":"2024-05-23T17:29:45.303781Z","shell.execute_reply.started":"2024-05-23T17:29:38.953095Z","shell.execute_reply":"2024-05-23T17:29:45.302780Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Create head mask\nhead_mask = np.zeros(X_train['input_ids'].shape)\nfor i, summary in enumerate(X_train['input_ids'].numpy()):\n    use_full = False\n    first_sep_flag = True\n    for j, token in enumerate(summary):\n        if token == tokenizer.sep_token_id:\n            if first_sep_flag:\n                first_sep_flag = False\n            else:\n                use_full = not use_full  \n        head_mask[i][j] = (1 if use_full else 0) \nhead_mask = tf.constant(head_mask)\nhead_mask","metadata":{"papermill":{"duration":0.031859,"end_time":"2024-05-16T15:40:24.019759","exception":false,"start_time":"2024-05-16T15:40:23.987900","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-23T17:29:45.305222Z","iopub.execute_input":"2024-05-23T17:29:45.305436Z","iopub.status.idle":"2024-05-23T17:30:46.863219Z","shell.execute_reply.started":"2024-05-23T17:29:45.305411Z","shell.execute_reply":"2024-05-23T17:30:46.862424Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(7165, 1575), dtype=float64, numpy=\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])>"},"metadata":{}}]},{"cell_type":"code","source":"# def get_embeddings(input_ids, attention_mask, model_name):\n    \n#     # Forward pass through pre trained model\n#     outputs = pre_trained_model(input_ids=input_ids, attention_mask=attention_mask)\n    \n#     if model_name == 'roberta-large':\n#         return outputs['pooler_output']\n#     else:\n#         return outputs[0]\n\n# # Save roberta/deberta embeddings in the training set\n\n# batch_size = 10 # ten is the biggest batch possible (can try maybe 11)\n# num_samples = len(X_train['input_ids'])\n# num_batches = (num_samples + batch_size - 1) // batch_size\n# averaged_embeddings = []\n\n# for i in range(num_batches):\n#     start_idx = i * batch_size\n#     end_idx = min((i + 1) * batch_size, num_samples)\n#     inputs = X_train['input_ids'][start_idx: end_idx]\n#     masks = X_train['attention_mask'][start_idx: end_idx]\n    \n#     embeddings = get_embeddings(input_ids=inputs, attention_mask=masks, model_name=model_name)\n#     h_mask = tf.expand_dims(tf.cast(head_mask[start_idx: end_idx], dtype=tf.float32), axis=-1)\n#     masked_outputs = tf.multiply(embeddings, h_mask)\n#     pooled = (tf.reduce_mean(masked_outputs, axis=1)).numpy()\n#     averaged_embeddings.append(pooled)\n    \n#     if i % int(num_batches * 0.1) == 0:\n#         print(f\"Batch {i}/{num_batches}\")\n        \n#     del embeddings\n#     del masked_outputs\n#     del pooled\n#     del h_mask\n#     gc.collect()\n#     tf.keras.backend.clear_session()\n# # Write to a file    \n# concatenated_embeddings = np.concatenate(averaged_embeddings, axis=0)\n# with open('masked_pooled_deberta_embeddings.pkl', 'wb') as f:\n#     pickle.dump(concatenated_embeddings, f)","metadata":{"papermill":{"duration":0.032191,"end_time":"2024-05-16T15:40:24.076135","exception":false,"start_time":"2024-05-16T15:40:24.043944","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-16T16:05:06.471813Z","iopub.execute_input":"2024-05-16T16:05:06.472020Z","iopub.status.idle":"2024-05-16T16:05:06.477607Z","shell.execute_reply.started":"2024-05-16T16:05:06.471994Z","shell.execute_reply":"2024-05-16T16:05:06.476760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save file to output folder\n\n# DeBERTa \nfile_path = '/kaggle/input/pooled-deberta-embeddings/pooled_deberta_embeddings.csv'# from input folder\n\n# Load masked pooled Deberta embeddings\nwith open('/kaggle/input/masked-pooled-deberta-embeddings/mask_pooled_deberta_embeddings.pkl', 'rb') as f:\n    loaded_array = pickle.load(f)\n# Load embeddings\nX_train_preprocessed = pd.read_csv(file_path)\n\n\nX_train_preprocessed['embeddings'] = X_train_preprocessed['embeddings'].apply(lambda x: list(map(float, x.split(','))))\nX_train_preprocessed['masked_embeddings'] = loaded_array.tolist()\n# Save a csv file\n# df_to_save = df_with_embeddings['pooled_roberta_embedding'].apply(lambda x: ','.join(map(str, x)))\n# df_to_save.to_csv(file_path, index=False)","metadata":{"papermill":{"duration":0.032352,"end_time":"2024-05-16T15:40:24.229783","exception":false,"start_time":"2024-05-16T15:40:24.197431","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-23T17:30:50.432703Z","iopub.execute_input":"2024-05-23T17:30:50.432972Z","iopub.status.idle":"2024-05-23T17:30:53.350345Z","shell.execute_reply.started":"2024-05-23T17:30:50.432939Z","shell.execute_reply":"2024-05-23T17:30:53.349423Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# The loss function\ndef mcrmse(y_true, y_pred):\n    columnwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=0)\n    return tf.reduce_mean(tf.sqrt(columnwise_mse), axis=-1)\n\n# log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)","metadata":{"papermill":{"duration":0.032128,"end_time":"2024-05-16T15:40:24.400490","exception":false,"start_time":"2024-05-16T15:40:24.368362","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-23T17:30:53.372625Z","iopub.execute_input":"2024-05-23T17:30:53.372871Z","iopub.status.idle":"2024-05-23T17:30:53.384839Z","shell.execute_reply.started":"2024-05-23T17:30:53.372838Z","shell.execute_reply":"2024-05-23T17:30:53.384041Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# # NN with embeddings preprocessed\n# def create_model_preprocessed():\n#     input_shape = len(X_train_preprocessed['masked_embeddings'][0])\n\n#     input_layer = keras.Input(shape=(input_shape, ), dtype='float32')\n    \n#     layer_norm = layers.LayerNormalization(name='layer_norm1')(input_layer)\n    \n#     reshape_input_layer = layers.Reshape((1,input_shape), name='reshape_layer')(layer_norm)\n    \n#     LSTM_layer = layers.LSTM(512, return_sequences=True, name='LSTM_layer1', activation='linear')(reshape_input_layer)\n    \n#     layer_norm = layers.LayerNormalization(name='layer_norm2')(LSTM_layer)\n    \n#     act = layers.Activation(keras.activations.tanh, name='tanh1')(layer_norm)\n    \n#     LSTM_layer = layers.LSTM(32, return_sequences=False, name='LSTM_layer2', activation='linear',)(act)\n    \n#     layer_norm = layers.LayerNormalization(name='layer_norm3')(LSTM_layer)\n    \n#     act = layers.Activation(keras.activations.tanh, name='tanh2')(layer_norm)\n    \n#     hidden_layer = layers.Dense(16, activation='linear', name='dense_layer')(act)\n    \n#     dropout = layers.Dropout(0.3, name='dropout_layer')(hidden_layer)\n    \n#     # batch_norm = layers.BatchNormalization(name='batch_norm')(dropout)\n\n#     output_layer = layers.Dense(2, activation='linear', name='output_layer')(dropout)\n    \n#     model = keras.Model(inputs=input_layer, outputs=output_layer)\n\n#     for layer in model.layers:\n#         layer.trainable = True\n        \n    \n#     opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n#     model.compile(loss=mcrmse, optimizer=opt)\n    \n#     return model\n\n# model = create_model_preprocessed()\n# model.summary()","metadata":{"papermill":{"duration":0.033231,"end_time":"2024-05-16T15:40:24.458629","exception":false,"start_time":"2024-05-16T15:40:24.425398","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-23T15:04:29.003074Z","iopub.execute_input":"2024-05-23T15:04:29.003326Z","iopub.status.idle":"2024-05-23T15:04:29.111885Z","shell.execute_reply.started":"2024-05-23T15:04:29.003279Z","shell.execute_reply":"2024-05-23T15:04:29.110887Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":17,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 42\u001b[0m\n\u001b[1;32m     38\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mmcrmse, optimizer\u001b[38;5;241m=\u001b[39mopt)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m---> 42\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model_preprocessed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n","Cell \u001b[0;32mIn[17], line 3\u001b[0m, in \u001b[0;36mcreate_model_preprocessed\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model_preprocessed\u001b[39m():\n\u001b[0;32m----> 3\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mX_train_preprocessed\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmasked_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      5\u001b[0m     input_layer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(input_shape, ), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     layer_norm \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mLayerNormalization(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer_norm1\u001b[39m\u001b[38;5;124m'\u001b[39m)(input_layer)\n","\u001b[0;31mNameError\u001b[0m: name 'X_train_preprocessed' is not defined"],"ename":"NameError","evalue":"name 'X_train_preprocessed' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# Train prepocessed model (head only) without validation\n\n# Checkpoint callback\nckptcb = keras.callbacks.ModelCheckpoint(\n    \"best_model\" + \".weights.h5\",\n    monitor=\"loss\",\n    save_best_only=True,\n    save_weights_only=True,\n    mode=\"min\",\n)    \n\nhistory = model.fit(x=X_train_input,\n                    y=Y_train_np,\n                    epochs=25,\n                    batch_size=4,\n                    callbacks=[ckptcb],\n                    verbose=2)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T16:30:22.093953Z","iopub.execute_input":"2024-05-20T16:30:22.094604Z","iopub.status.idle":"2024-05-20T16:32:29.088424Z","shell.execute_reply.started":"2024-05-20T16:30:22.094572Z","shell.execute_reply":"2024-05-20T16:32:29.087716Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/25\n1792/1792 - 9s - 5ms/step - loss: 0.5971\nEpoch 2/25\n1792/1792 - 5s - 3ms/step - loss: 0.5268\nEpoch 3/25\n1792/1792 - 5s - 3ms/step - loss: 0.5059\nEpoch 4/25\n1792/1792 - 5s - 3ms/step - loss: 0.4832\nEpoch 5/25\n1792/1792 - 5s - 3ms/step - loss: 0.4767\nEpoch 6/25\n1792/1792 - 5s - 3ms/step - loss: 0.4666\nEpoch 7/25\n1792/1792 - 5s - 3ms/step - loss: 0.4664\nEpoch 8/25\n1792/1792 - 5s - 3ms/step - loss: 0.4670\nEpoch 9/25\n1792/1792 - 5s - 3ms/step - loss: 0.4622\nEpoch 10/25\n1792/1792 - 5s - 3ms/step - loss: 0.4635\nEpoch 11/25\n1792/1792 - 5s - 3ms/step - loss: 0.4655\nEpoch 12/25\n1792/1792 - 5s - 3ms/step - loss: 0.4639\nEpoch 13/25\n1792/1792 - 5s - 3ms/step - loss: 0.4643\nEpoch 14/25\n1792/1792 - 5s - 3ms/step - loss: 0.4645\nEpoch 15/25\n1792/1792 - 5s - 3ms/step - loss: 0.4645\nEpoch 16/25\n1792/1792 - 5s - 3ms/step - loss: 0.4671\nEpoch 17/25\n1792/1792 - 5s - 3ms/step - loss: 0.4667\nEpoch 18/25\n1792/1792 - 5s - 3ms/step - loss: 0.4660\nEpoch 19/25\n1792/1792 - 5s - 3ms/step - loss: 0.4649\nEpoch 20/25\n1792/1792 - 5s - 3ms/step - loss: 0.4628\nEpoch 21/25\n1792/1792 - 5s - 3ms/step - loss: 0.4651\nEpoch 22/25\n1792/1792 - 5s - 3ms/step - loss: 0.4636\nEpoch 23/25\n1792/1792 - 5s - 3ms/step - loss: 0.4644\nEpoch 24/25\n1792/1792 - 5s - 3ms/step - loss: 0.4644\nEpoch 25/25\n1792/1792 - 5s - 3ms/step - loss: 0.4648\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train prepocessed model (head only) with K folds\n\nX_train_input = np.array(X_train_preprocessed['masked_embeddings'].tolist())\nY_train = tf.constant(train[['content', 'wording']].values, dtype=tf.float32)\n\n# Initialize the KFold object\nkf = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n\n# Initialize an empty list to store the validation losses\nval_losses = []\nhistories = []\n\nY_train_np = Y_train.numpy()\n\n# Iterate over each fold\ni = 0\nfor train_index, val_index in kf.split(X_train_input, Y_train_np):\n    \n    print(f\"Fold {i + 1}\")\n    i += 1\n    \n    # Split data into training and validation sets\n    X_train_fold, X_val_fold = X_train_input[train_index], X_train_input[val_index]\n    Y_train_fold, Y_val_fold = Y_train_np[train_index], Y_train_np[val_index]\n    \n    # Create and compile your model\n    model = create_model()\n    \n    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    \n    # Train the model\n    \n    # Get the validation loss from the last epoch\n    val_loss = min(history.history['val_loss'])\n    val_losses.append(val_loss)\n    histories.append(history)\n    print()\n\n# Calculate the mean validation loss\nmean_val_loss = np.mean(val_losses)\nprint(\"Mean Validation Loss:\", mean_val_loss)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training and val losses across folds\nfor i, history in enumerate(histories):\n    train_losses = history.history['loss']\n    val_losses = history.history['val_loss']\n    epochs = range(1, len(train_losses) + 1)\n\n    # Plotting losses\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, train_losses, 'b', label='Training loss')\n    plt.plot(epochs, val_losses, 'r', label='Validation loss')\n    plt.title(f'Training and Validation Loss Fold {i + 1}')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# build our NN on top of Deberta\n\n# Create a layer that wraps the pre trained model to support Keras library\nclass PreTrainedModel(keras.Model):\n    def __init__(self, pre_trained_model, trainable=False, num_layers_to_freeze=0, name=None, **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.pre_trained_model = pre_trained_model\n        self.trainable = trainable\n        self.num_layers_to_freeze = num_layers_to_freeze\n        self.pre_trained_model.trainable = self.trainable\n\n        # if equal to -1 freeze all layers\n        if self.trainable:\n            self.pre_trained_model.trainable = self.trainable\n            if self.trainable:\n                for layer in self.pre_trained_model.layers[0].encoder.layer[:self.num_layers_to_freeze]:\n                    layer.trainable = False\n\n        # Dynamically create properties from pre-trained model\n        # for prop_name, prop in inspect.getmembers(self.pre_trained_model):\n        #    if not prop_name.startswith('_') and not inspect.ismethod(prop):\n        #        setattr(self.__class__, prop_name, prop)\n\n    def call(self, input_ids, attention_mask):\n        # Call the pre trained model and get the last hidden state\n        output = self.pre_trained_model(input_ids=input_ids, attention_mask=attention_mask)\n        return output[0]    ","metadata":{"execution":{"iopub.status.busy":"2024-05-23T17:30:53.385872Z","iopub.execute_input":"2024-05-23T17:30:53.386041Z","iopub.status.idle":"2024-05-23T17:30:53.396013Z","shell.execute_reply.started":"2024-05-23T17:30:53.386022Z","shell.execute_reply":"2024-05-23T17:30:53.395227Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"lr_schedule = tf.keras.optimizers.schedules.CosineDecay(0.00015, decay_steps=10000)\n\n# NN with embeddings preprocessed\ndef create_model_preprocessed():\n    input_shape = 1024 \n\n    input_layer = keras.Input(shape=(input_shape, ), dtype='float32')\n    \n    layer_norm = layers.LayerNormalization(name='layer_norm1')(input_layer)\n    \n    reshape_input_layer = layers.Reshape((1,input_shape), name='reshape_layer')(layer_norm)\n    \n    LSTM_layer = layers.LSTM(512, return_sequences=True, name='LSTM_layer1', activation='linear')(reshape_input_layer)\n    \n    layer_norm = layers.LayerNormalization(name='layer_norm2')(LSTM_layer)\n    \n    act = layers.Activation(keras.activations.tanh, name='tanh1')(layer_norm)\n    \n    LSTM_layer = layers.LSTM(32, return_sequences=False, name='LSTM_layer2', activation='linear',)(act)\n    \n    layer_norm = layers.LayerNormalization(name='layer_norm3')(LSTM_layer)\n    \n    act = layers.Activation(keras.activations.tanh, name='tanh2')(layer_norm)\n    \n    hidden_layer = layers.Dense(16, activation='linear', name='dense_layer')(act)\n    \n    dropout = layers.Dropout(0.3, name='dropout_layer')(hidden_layer)\n    \n    # batch_norm = layers.BatchNormalization(name='batch_norm')(dropout)\n\n    output_layer = layers.Dense(2, activation='linear', name='output_layer')(dropout)\n    \n    model = keras.Model(inputs=input_layer, outputs=output_layer)\n\n    for layer in model.layers:\n        layer.trainable = True\n        \n    \n    opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n    model.compile(loss=mcrmse, optimizer=opt)\n    \n    return model\n\nmodel_preprocessed = create_model_preprocessed()\nmodel_preprocessed.load_weights(\"/kaggle/input/model-weights-1/best_model.weights.h5\")\nmodel_preprocessed.summary()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T17:30:53.877269Z","iopub.execute_input":"2024-05-23T17:30:53.878073Z","iopub.status.idle":"2024-05-23T17:30:54.840931Z","shell.execute_reply.started":"2024-05-23T17:30:53.878040Z","shell.execute_reply":"2024-05-23T17:30:54.840115Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_norm1                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m2,048\u001b[0m │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reshape_layer (\u001b[38;5;33mReshape\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ LSTM_layer1 (\u001b[38;5;33mLSTM\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │     \u001b[38;5;34m3,147,776\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_norm2                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ tanh1 (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ LSTM_layer2 (\u001b[38;5;33mLSTM\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m69,760\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_norm3                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ tanh2 (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_layer (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_layer (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m34\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_norm1                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reshape_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ LSTM_layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,147,776</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_norm2                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ tanh1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ LSTM_layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">69,760</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_norm3                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ tanh2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,221,234\u001b[0m (12.29 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,221,234</span> (12.29 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,221,234\u001b[0m (12.29 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,221,234</span> (12.29 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"lr_schedule = tf.keras.optimizers.schedules.CosineDecay(0.00015, decay_steps=10000)\n\n# NN with embeddings preprocessed\ndef create_model(input_shape=(1575,), embeddings_len=1024):\n    pre_trained_model_instance = PreTrainedModel(pre_trained_model, name=\"deberta_layer\")\n\n    # Input layers\n    input_ids = keras.Input(shape=input_shape, dtype='int32', name='input_ids')\n    attention_mask = keras.Input(shape=input_shape, dtype='int32', name='attention_mask')\n    head_mask = keras.Input(shape=input_shape, dtype='float32', name='head_mask')\n    \n    # Create embeddings and mask pool them\n    deberta = pre_trained_model_instance(input_ids, attention_mask)\n    h_mask = layers.Lambda(lambda x: tf.expand_dims(tf.cast(x, dtype=tf.float32), axis=-1), name='expand_dims')(head_mask)\n    masked_outputs = layers.Lambda(lambda x: tf.multiply(x[0], x[1]), output_shape=(1575, 1024,), name='masked_embeddings')([deberta, h_mask])\n    avg_pooling = layers.GlobalAveragePooling1D()(masked_outputs)\n    \n    # Head of NN\n    layer_norm = layers.LayerNormalization(name='layer_norm1')(avg_pooling)\n\n    reshape_input_layer = layers.Reshape((1, embeddings_len), name='reshape_layer')(layer_norm)\n    \n    LSTM_layer = layers.LSTM(512, return_sequences=True, name='LSTM_layer1', activation='linear')(reshape_input_layer)\n    \n    layer_norm = layers.LayerNormalization(name='layer_norm2')(LSTM_layer)\n    \n    act = layers.Activation(keras.activations.tanh, name='tanh1')(layer_norm)\n    \n    LSTM_layer = layers.LSTM(32, return_sequences=False, name='LSTM_layer2', activation='linear',)(act)\n    \n    layer_norm = layers.LayerNormalization(name='layer_norm3')(LSTM_layer)\n    \n    act = layers.Activation(keras.activations.tanh, name='tanh2')(layer_norm)\n    \n    hidden_layer = layers.Dense(16, activation='linear', name='dense_layer')(act)\n    \n    dropout = layers.Dropout(0.3, name='dropout_layer')(hidden_layer)\n\n    output_layer = layers.Dense(2, activation='linear', name='output_layer')(dropout)\n    \n    model = keras.Model(inputs=[input_ids, attention_mask, head_mask], outputs=output_layer)\n\n    for layer in model.layers:\n        layer.trainable = True\n    \n    opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n    model.compile(loss=mcrmse, optimizer=opt)\n    \n    return model, pre_trained_model_instance\n\nmodel, deberta_model = create_model()\nmodel.summary()\n# deberta_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T17:30:58.847664Z","iopub.execute_input":"2024-05-23T17:30:58.850672Z","iopub.status.idle":"2024-05-23T17:31:35.374509Z","shell.execute_reply.started":"2024-05-23T17:30:58.850626Z","shell.execute_reply":"2024-05-23T17:31:35.373648Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_ids           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_mask      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ head_mask           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ deberta_layer       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│ (\u001b[38;5;33mPreTrainedModel\u001b[0m)   │ \u001b[38;5;34m1024\u001b[0m)             │            │ attention_mask[\u001b[38;5;34m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ expand_dims         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ head_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mLambda\u001b[0m)            │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ masked_embeddings   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ deberta_layer[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mLambda\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │ expand_dims[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ masked_embedding… │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_norm1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │      \u001b[38;5;34m2,048\u001b[0m │ global_average_p… │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_layer       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_norm1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ LSTM_layer1 (\u001b[38;5;33mLSTM\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │  \u001b[38;5;34m3,147,776\u001b[0m │ reshape_layer[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_norm2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m1,024\u001b[0m │ LSTM_layer1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ tanh1 (\u001b[38;5;33mActivation\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_norm2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ LSTM_layer2 (\u001b[38;5;33mLSTM\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │     \u001b[38;5;34m69,760\u001b[0m │ tanh1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_norm3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m64\u001b[0m │ LSTM_layer2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ tanh2 (\u001b[38;5;33mActivation\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_norm3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_layer (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ tanh2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_layer       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ output_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │         \u001b[38;5;34m34\u001b[0m │ dropout_layer[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_ids           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_mask      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ head_mask           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ deberta_layer       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PreTrainedModel</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ attention_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ expand_dims         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ head_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ masked_embeddings   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ deberta_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ masked_embedding… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_norm1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ global_average_p… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_layer       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_norm1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ LSTM_layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,147,776</span> │ reshape_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_norm2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ LSTM_layer1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ tanh1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_norm2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ LSTM_layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">69,760</span> │ tanh1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_norm3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ LSTM_layer2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ tanh2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_norm3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ tanh2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_layer       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ output_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span> │ dropout_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,221,234\u001b[0m (12.29 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,221,234</span> (12.29 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,221,234\u001b[0m (12.29 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,221,234</span> (12.29 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"deberta_layer\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"deberta_layer\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"# Transferring weights\nfor layer in model.layers:\n    if layer.name in model_preprocessed.layers:\n        layer.set_weights(model_preprocessed.get_layer(name=layer.name).get_weights())\n        layer.trainable = True","metadata":{"execution":{"iopub.status.busy":"2024-05-23T17:31:35.395480Z","iopub.execute_input":"2024-05-23T17:31:35.396219Z","iopub.status.idle":"2024-05-23T17:31:35.403236Z","shell.execute_reply.started":"2024-05-23T17:31:35.396193Z","shell.execute_reply":"2024-05-23T17:31:35.402475Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"Y_train = tf.constant(train[['content', 'wording']].values, dtype=tf.float32)\nY_train_np = Y_train.numpy()\n\n# Checkpoint callback\nckptcb = keras.callbacks.ModelCheckpoint(\n    \"best_model\" + \".weights.h5\",\n    monitor=\"loss\",\n    save_best_only=True,\n    save_weights_only=True,\n    mode=\"min\",\n)    \n\nhistory = model.fit(x=[X_train['input_ids'], X_train['attention_mask'], head_mask],\n                    y=Y_train_np,\n                    epochs=4,\n                    batch_size=4,\n                    callbacks=[ckptcb],\n                    verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T17:32:21.651742Z","iopub.execute_input":"2024-05-23T17:32:21.652007Z","iopub.status.idle":"2024-05-23T19:46:15.544014Z","shell.execute_reply.started":"2024-05-23T17:32:21.651981Z","shell.execute_reply":"2024-05-23T19:46:15.543210Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/4\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1716485616.464372     118 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1716485616.612908     118 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1791/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6366","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1716487631.936327     118 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2090s\u001b[0m 1s/step - loss: 0.6365\nEpoch 2/4\n\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1981s\u001b[0m 1s/step - loss: 0.5280\nEpoch 3/4\n\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1981s\u001b[0m 1s/step - loss: 0.4957\nEpoch 4/4\n\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1981s\u001b[0m 1s/step - loss: 0.4803\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('no_augmentation_model_final.h5')","metadata":{"execution":{"iopub.status.busy":"2024-05-23T19:57:55.125754Z","iopub.execute_input":"2024-05-23T19:57:55.126033Z","iopub.status.idle":"2024-05-23T19:57:55.330348Z","shell.execute_reply.started":"2024-05-23T19:57:55.126007Z","shell.execute_reply":"2024-05-23T19:57:55.329203Z"},"trusted":true},"execution_count":24,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mno_augmentation_model_final.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/h5py/_hl/group.py:183\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    180\u001b[0m         parent_path, name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    181\u001b[0m         group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_group(parent_path)\n\u001b[0;32m--> 183\u001b[0m dsid \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_new_dset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m dset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mDataset(dsid)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/h5py/_hl/dataset.py:163\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     sid \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(shape, maxshape)\n\u001b[0;32m--> 163\u001b[0m dset_id \u001b[38;5;241m=\u001b[39m \u001b[43mh5d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdcpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Empty)):\n\u001b[1;32m    166\u001b[0m     dset_id\u001b[38;5;241m.\u001b[39mwrite(h5s\u001b[38;5;241m.\u001b[39mALL, h5s\u001b[38;5;241m.\u001b[39mALL, data)\n","File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mh5py/h5d.pyx:137\u001b[0m, in \u001b[0;36mh5py.h5d.create\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unable to synchronously create dataset (name already exists)"],"ename":"ValueError","evalue":"Unable to synchronously create dataset (name already exists)","output_type":"error"}]},{"cell_type":"code","source":"test[\"text\"] = test[\"text\"].apply(lambda x: spell(x))\ntest['input'] = test['prompt_title'] + sep + prefix1 + test['prompt_question'] + sep + prefix2 + test['text']\ntest['input'][0]\n\n# Preprocessing features and labels\nX_test = tokenizer.batch_encode_plus(test['input'].tolist(),\n                                              add_special_tokens=True,\n                                              truncation=True,\n                                              padding='max_length',\n                                              return_tensors='tf',\n                                              max_length=MAX_SUMMARY_LENGTH,\n                                              return_attention_mask = True)\ndel X_test['token_type_ids']\n\n# Create head mask\nhead_mask_test = np.zeros(X_test['input_ids'].shape)\nfor i, summary in enumerate(X_test['input_ids'].numpy()):\n    use_full = False\n    first_sep_flag = True\n    for j, token in enumerate(summary):\n        if token == tokenizer.sep_token_id:\n            if first_sep_flag:\n                first_sep_flag = False\n            else:\n                use_full = not use_full\n        head_mask_test[i][j] = (1 if use_full else 0) \nhead_mask_test = tf.constant(head_mask_test)\n\ntest_data = {\n    'input_ids': X_test['input_ids'],\n    'attention_mask': X_test['attention_mask'],\n    'head_mask': head_mask_test,\n    'student_id': test['student_id'],\n}\ndef generate_predictions(model, test_data):\n    contents = []\n    wordings = []\n    ids = []\n    predictions = model.predict(x=[test_data['input_ids'], test_data['attention_mask'], test_data['head_mask']],\n                                batch_size=4)\n\n    for idx, output in enumerate(predictions):\n        # Assuming the first index corresponds to the content prediction\n        contents.append(output[0])\n        # Assuming the second index corresponds to the wording prediction\n        wordings.append(output[1])\n        ids.append(test_data['student_id'][idx])  # Assuming you have some kind of IDs for test samples\n    return ids, contents, wordings\n\nids, contents, wordings = generate_predictions(model, test_data)\n\nsubmission_df = pd.DataFrame({'student_id': ids,\n                              'content': contents,\n                              'wording': wordings})\n\nsubmission_df.to_csv(\"submission.csv\", index=False)\nsubmission_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}