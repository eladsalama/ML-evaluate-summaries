{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ec528014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "698dc729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autocorrect import Speller\n",
    "spell = Speller(lang='en', fast=True)\n",
    "spell('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a436c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pro_paths = [r\"C:\\Users\\salam\\Documents\\GitHub\\ML-evaluate-summaries\\data\\\"\",\n",
    "                   \"/Users/danielpalmor/VisualStudioProjects/ML-evaluate-summaries/ML-evaluate-summaries/data/\"]\n",
    "train_pro_path = train_pro_paths[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "40425ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLORING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3569d705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\nAs the sequel to what has already...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3b9047</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>814d6b</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\nThe Third Wave experiment took pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question  \\\n",
       "0    39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "1    3b9047  In complete sentences, summarize the structure...   \n",
       "2    814d6b  Summarize how the Third Wave developed over su...   \n",
       "3    ebad26  Summarize the various ways the factory would u...   \n",
       "\n",
       "                prompt_title  \\\n",
       "0                 On Tragedy   \n",
       "1  Egyptian Social Structure   \n",
       "2             The Third Wave   \n",
       "3    Excerpt from The Jungle   \n",
       "\n",
       "                                         prompt_text  \n",
       "0  Chapter 13 \\nAs the sequel to what has already...  \n",
       "1  Egyptian society was structured like a pyramid...  \n",
       "2  Background \\nThe Third Wave experiment took pl...  \n",
       "3  With one member trimming beef in a cannery, an...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pro = pd.read_csv(train_pro_path + \"prompts_train.csv\")\n",
    "train_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3f754b82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>ff7c7e70df07</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They used all sorts of chemical concoctions to...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>ffc34d056498</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The lowest classes are slaves and farmers slav...</td>\n",
       "      <td>-0.308448</td>\n",
       "      <td>0.048171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>ffd1576d2e1b</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>they sorta made people start workin...</td>\n",
       "      <td>-1.408180</td>\n",
       "      <td>-0.493603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>ffe4a98093b2</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>An ideal tragety has three elements that make ...</td>\n",
       "      <td>-0.393310</td>\n",
       "      <td>0.627128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>fffbccfd8a08</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>The meat would smell sour but the would \"rub i...</td>\n",
       "      <td>1.771596</td>\n",
       "      <td>0.547742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7165 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        student_id prompt_id  \\\n",
       "0     000e8c3c7ddb    814d6b   \n",
       "1     0020ae56ffbf    ebad26   \n",
       "2     004e978e639e    3b9047   \n",
       "3     005ab0199905    3b9047   \n",
       "4     0070c9e7af47    814d6b   \n",
       "...            ...       ...   \n",
       "7160  ff7c7e70df07    ebad26   \n",
       "7161  ffc34d056498    3b9047   \n",
       "7162  ffd1576d2e1b    3b9047   \n",
       "7163  ffe4a98093b2    39c16e   \n",
       "7164  fffbccfd8a08    ebad26   \n",
       "\n",
       "                                                   text   content   wording  \n",
       "0     The third wave was an experimentto see how peo...  0.205683  0.380538  \n",
       "1     They would rub it up with soda to make the sme... -0.548304  0.506755  \n",
       "2     In Egypt, there were many occupations and soci...  3.128928  4.231226  \n",
       "3     The highest class was Pharaohs these people we... -0.210614 -0.471415  \n",
       "4     The Third Wave developed  rapidly because the ...  3.272894  3.219757  \n",
       "...                                                 ...       ...       ...  \n",
       "7160  They used all sorts of chemical concoctions to...  0.205683  0.380538  \n",
       "7161  The lowest classes are slaves and farmers slav... -0.308448  0.048171  \n",
       "7162             they sorta made people start workin... -1.408180 -0.493603  \n",
       "7163  An ideal tragety has three elements that make ... -0.393310  0.627128  \n",
       "7164  The meat would smell sour but the would \"rub i...  1.771596  0.547742  \n",
       "\n",
       "[7165 rows x 5 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sum = pd.read_csv(train_pro_path + \"summaries_train.csv\")\n",
    "train_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f3ea730b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000ffffff</td>\n",
       "      <td>abc123</td>\n",
       "      <td>Example text 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111eeeeee</td>\n",
       "      <td>def789</td>\n",
       "      <td>Example text 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222222cccccc</td>\n",
       "      <td>abc123</td>\n",
       "      <td>Example text 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333333dddddd</td>\n",
       "      <td>def789</td>\n",
       "      <td>Example text 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id            text\n",
       "0  000000ffffff    abc123  Example text 1\n",
       "1  111111eeeeee    def789  Example text 2\n",
       "2  222222cccccc    abc123  Example text 3\n",
       "3  333333dddddd    def789  Example text 4"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sum = pd.read_csv(train_pro_path + \"summaries_test.csv\")\n",
    "test_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "06eed977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abc123</td>\n",
       "      <td>Summarize...</td>\n",
       "      <td>Example Title 1</td>\n",
       "      <td>Heading\\nText...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def789</td>\n",
       "      <td>Summarize...</td>\n",
       "      <td>Example Title 2</td>\n",
       "      <td>Heading\\nText...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id prompt_question     prompt_title       prompt_text\n",
       "0    abc123    Summarize...  Example Title 1  Heading\\nText...\n",
       "1    def789    Summarize...  Example Title 2  Heading\\nText..."
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pro = pd.read_csv(train_pro_path + \"prompts_test.csv\")\n",
    "test_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d059d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will need to take a portion of the train data as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "da3b2e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>student_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\nAs the sequel to what has already...</td>\n",
       "      <td>00791789cc1f</td>\n",
       "      <td>1 element of an ideal tragedy is that it shoul...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\nAs the sequel to what has already...</td>\n",
       "      <td>0086ef22de8f</td>\n",
       "      <td>The three elements of an ideal tragedy are:  H...</td>\n",
       "      <td>-0.970237</td>\n",
       "      <td>-0.417058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\nAs the sequel to what has already...</td>\n",
       "      <td>0094589c7a22</td>\n",
       "      <td>Aristotle states that an ideal tragedy should ...</td>\n",
       "      <td>-0.387791</td>\n",
       "      <td>-0.584181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\nAs the sequel to what has already...</td>\n",
       "      <td>00cd5736026a</td>\n",
       "      <td>One element of an Ideal tragedy is having a co...</td>\n",
       "      <td>0.088882</td>\n",
       "      <td>-0.594710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\nAs the sequel to what has already...</td>\n",
       "      <td>00d98b8ff756</td>\n",
       "      <td>The 3 ideal of tragedy is how complex you need...</td>\n",
       "      <td>-0.687288</td>\n",
       "      <td>-0.460886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff37545b2805</td>\n",
       "      <td>In paragraph two, they would use pickle meat a...</td>\n",
       "      <td>1.520355</td>\n",
       "      <td>-0.292990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff4ed38ef099</td>\n",
       "      <td>in the first paragraph  it says \"either can it...</td>\n",
       "      <td>-1.204574</td>\n",
       "      <td>-1.169784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff53b94f7ce0</td>\n",
       "      <td>They would have piles of filthy meat on the fl...</td>\n",
       "      <td>0.328739</td>\n",
       "      <td>-1.053294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff7c7e70df07</td>\n",
       "      <td>They used all sorts of chemical concoctions to...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>fffbccfd8a08</td>\n",
       "      <td>The meat would smell sour but the would \"rub i...</td>\n",
       "      <td>1.771596</td>\n",
       "      <td>0.547742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7165 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prompt_id                                    prompt_question  \\\n",
       "0       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "1       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "2       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "3       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "4       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "...        ...                                                ...   \n",
       "7160    ebad26  Summarize the various ways the factory would u...   \n",
       "7161    ebad26  Summarize the various ways the factory would u...   \n",
       "7162    ebad26  Summarize the various ways the factory would u...   \n",
       "7163    ebad26  Summarize the various ways the factory would u...   \n",
       "7164    ebad26  Summarize the various ways the factory would u...   \n",
       "\n",
       "                 prompt_title  \\\n",
       "0                  On Tragedy   \n",
       "1                  On Tragedy   \n",
       "2                  On Tragedy   \n",
       "3                  On Tragedy   \n",
       "4                  On Tragedy   \n",
       "...                       ...   \n",
       "7160  Excerpt from The Jungle   \n",
       "7161  Excerpt from The Jungle   \n",
       "7162  Excerpt from The Jungle   \n",
       "7163  Excerpt from The Jungle   \n",
       "7164  Excerpt from The Jungle   \n",
       "\n",
       "                                            prompt_text    student_id  \\\n",
       "0     Chapter 13 \\nAs the sequel to what has already...  00791789cc1f   \n",
       "1     Chapter 13 \\nAs the sequel to what has already...  0086ef22de8f   \n",
       "2     Chapter 13 \\nAs the sequel to what has already...  0094589c7a22   \n",
       "3     Chapter 13 \\nAs the sequel to what has already...  00cd5736026a   \n",
       "4     Chapter 13 \\nAs the sequel to what has already...  00d98b8ff756   \n",
       "...                                                 ...           ...   \n",
       "7160  With one member trimming beef in a cannery, an...  ff37545b2805   \n",
       "7161  With one member trimming beef in a cannery, an...  ff4ed38ef099   \n",
       "7162  With one member trimming beef in a cannery, an...  ff53b94f7ce0   \n",
       "7163  With one member trimming beef in a cannery, an...  ff7c7e70df07   \n",
       "7164  With one member trimming beef in a cannery, an...  fffbccfd8a08   \n",
       "\n",
       "                                                   text   content   wording  \n",
       "0     1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415  \n",
       "1     The three elements of an ideal tragedy are:  H... -0.970237 -0.417058  \n",
       "2     Aristotle states that an ideal tragedy should ... -0.387791 -0.584181  \n",
       "3     One element of an Ideal tragedy is having a co...  0.088882 -0.594710  \n",
       "4     The 3 ideal of tragedy is how complex you need... -0.687288 -0.460886  \n",
       "...                                                 ...       ...       ...  \n",
       "7160  In paragraph two, they would use pickle meat a...  1.520355 -0.292990  \n",
       "7161  in the first paragraph  it says \"either can it... -1.204574 -1.169784  \n",
       "7162  They would have piles of filthy meat on the fl...  0.328739 -1.053294  \n",
       "7163  They used all sorts of chemical concoctions to...  0.205683  0.380538  \n",
       "7164  The meat would smell sour but the would \"rub i...  1.771596  0.547742  \n",
       "\n",
       "[7165 rows x 8 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train_pro.merge(train_sum , on = \"prompt_id\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f4d6f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f76224d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8def7260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disabling unnecceseray warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.disable(logging.ERROR)\n",
    "#os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c67b0378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Set random seeds\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3294ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta = TFRobertaModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c2c539ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing on a single entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "60ecd5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.742898  , -0.62355506]], dtype=float32)>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = train['text'][0]\n",
    "tokens = tokenizer(input_text, return_tensors='tf')\n",
    "outputs = roberta(tokens)[0]\n",
    "last_hidden_state = np.array(outputs).mean(axis = 1)\n",
    "\n",
    "model = keras.Sequential([tf.keras.layers.Flatten(), \n",
    "                          tf.keras.layers.Dense(2, activation='linear')])\n",
    "\n",
    "dense_output = model(last_hidden_state)\n",
    "dense_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4b6648ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (1, 768)                  0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (1, 2)                    1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1538 (6.01 KB)\n",
      "Trainable params: 1538 (6.01 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "14d9d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the features and labels\n",
    "\n",
    "# Information about the X_train and Y_train after the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5fbe812b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       On Tragedy </s> Summarize at least 3 elements ...\n",
       "1       On Tragedy </s> Summarize at least 3 elements ...\n",
       "2       On Tragedy </s> Summarize at least 3 elements ...\n",
       "3       On Tragedy </s> Summarize at least 3 elements ...\n",
       "4       On Tragedy </s> Summarize at least 3 elements ...\n",
       "                              ...                        \n",
       "7160    Excerpt from The Jungle </s> Summarize the var...\n",
       "7161    Excerpt from The Jungle </s> Summarize the var...\n",
       "7162    Excerpt from The Jungle </s> Summarize the var...\n",
       "7163    Excerpt from The Jungle </s> Summarize the var...\n",
       "7164    Excerpt from The Jungle </s> Summarize the var...\n",
       "Name: input, Length: 7165, dtype: object"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep = \" \" + tokenizer.sep_token + \" \"\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: spell(x))\n",
    "train['input'] = train['prompt_title'] + sep + train['prompt_question'] + sep + train['text']\n",
    "train['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "58c0cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text data\n",
    "MAX_TOKEN_LENGTH  = int(train['input'].apply(len).mean())\n",
    "token_encodings = tokenizer.batch_encode_plus(train['input'].tolist(),\n",
    "                                              add_special_tokens=True,\n",
    "                                              truncation=True, \n",
    "                                              padding=True, \n",
    "                                              return_tensors='tf', \n",
    "                                              max_length=MAX_TOKEN_LENGTH,\n",
    "                                              return_attention_mask = True)\n",
    "\n",
    "# get all input_ids and attention_masks\n",
    "input_ids = token_encodings['input_ids']\n",
    "attention_masks = token_encodings['attention_mask']\n",
    "\n",
    "X_train = tf.convert_to_tensor([tf.concat([inputs, masks], axis=-1)\n",
    "                                for inputs, masks in zip(input_ids, attention_masks)])\n",
    "\n",
    "Y_train = tf.constant(train[['content', 'wording']].values, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "aa6771fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train element:\n",
      "tf.Tensor([   0 4148 2393 ...    0    0    0], shape=(1136,), dtype=int32)\n",
      "\n",
      "Y_train element:\n",
      "tf.Tensor([-0.21061394 -0.47141483], shape=(2,), dtype=float32)\n",
      "\n",
      "X_train shape: (7165, 1136)\n",
      "Y_train shape: (7165, 2)\n"
     ]
    }
   ],
   "source": [
    "# Examples of the features and labels\n",
    "print(\"X_train element:\")\n",
    "print(X_train[0])\n",
    "print()\n",
    "print(\"Y_train element:\")\n",
    "print(Y_train[0])\n",
    "print()\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"Y_train shape: {Y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "545955ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Building the keras neural network\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8d2b02d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)        [(None, 1134)]               0         []                            \n",
      "                                                                                                  \n",
      " ro_ber_ta_input_layer_8 (R  [(None, 567),                0         ['input_9[0][0]']             \n",
      " oBERTaInputLayer)            (None, 567)]                                                        \n",
      "                                                                                                  \n",
      " tf_roberta_model_1 (TFRobe  multiple                     1246456   ['ro_ber_ta_input_layer_8[0][0\n",
      " rtaModel)                                                32        ]',                           \n",
      "                                                                     'ro_ber_ta_input_layer_8[0][1\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_8  (None, 768)                  0         ['tf_roberta_model_1[4][0]']  \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 256)                  196864    ['global_average_pooling1d_8[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 256)                  1024      ['dense_16[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, 128)                  32896     ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 128)                  512       ['dense_17[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, 2)                    258       ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 124877186 (476.37 MB)\n",
      "Trainable params: 230786 (901.51 KB)\n",
      "Non-trainable params: 124646400 (475.49 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a layer that will transform the input to a valid roberta input\n",
    "class RoBERTaInputLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        # Split the input tensor along the last dimension\n",
    "        split1 = inputs[:, :MAX_TOKEN_LENGTH]\n",
    "        split2 = inputs[:, MAX_TOKEN_LENGTH:]\n",
    "        return [split1, split2]\n",
    "\n",
    "\n",
    "# Define keras neural network with Functional API\n",
    "    \n",
    "# Explanation of the Functional API: \n",
    "# For every layer we specify between parentheses at the end of the line the previous layer which will be the input.\n",
    "    \n",
    "input_layer = keras.Input(shape=(2 * MAX_TOKEN_LENGTH), dtype='int32')\n",
    "\n",
    "roberta_input_layer = RoBERTaInputLayer()(input_layer)\n",
    "\n",
    "roberta_output = roberta(roberta_input_layer[0], roberta_input_layer[1])['last_hidden_state']\n",
    "\n",
    "global_avg_pooling = layers.GlobalAveragePooling1D()(roberta_output)\n",
    "\n",
    "hidden_layer1 = layers.Dense(256, activation='linear')(global_avg_pooling)\n",
    "batch_norm1 = layers.BatchNormalization()(hidden_layer1)\n",
    "\n",
    "hidden_layer2 = layers.Dense(128, activation='linear')(batch_norm1)\n",
    "batch_norm2 = layers.BatchNormalization()(hidden_layer2)\n",
    "\n",
    "output_layer = layers.Dense(2, activation='linear')(batch_norm2)\n",
    "\n",
    "# Define the model\n",
    "model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Make roberta params untrainable\n",
    "for layer in model.layers[:-5]:\n",
    "  if layer.trainable == False:\n",
    "    continue\n",
    "  layer.trainable = False \n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ebf1b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "17910f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 - 93s - loss: 1.2222 - MCRMSE: 1.1055 - val_loss: 2.3551 - val_MCRMSE: 1.5346 - 93s/epoch - 93s/step\n",
      "Epoch 2/5\n",
      "1/1 - 66s - loss: 3.1622 - MCRMSE: 1.7783 - val_loss: 2.1113 - val_MCRMSE: 1.4530 - 66s/epoch - 66s/step\n",
      "Epoch 3/5\n",
      "1/1 - 67s - loss: 2.8362 - MCRMSE: 1.6841 - val_loss: 1.7233 - val_MCRMSE: 1.3128 - 67s/epoch - 67s/step\n",
      "Epoch 4/5\n",
      "1/1 - 61s - loss: 1.9732 - MCRMSE: 1.4047 - val_loss: 1.5649 - val_MCRMSE: 1.2510 - 61s/epoch - 61s/step\n",
      "Epoch 5/5\n",
      "1/1 - 65s - loss: 1.3864 - MCRMSE: 1.1775 - val_loss: 1.5998 - val_MCRMSE: 1.2648 - 65s/epoch - 65s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEpoch 1/5\\n1/1 - 80s - loss: 0.7473 - mae: 0.6926 - val_loss: 2.1400 - val_mae: 1.3103 - 80s/epoch - 80s/step\\nEpoch 2/5\\n1/1 - 64s - loss: 0.7145 - mae: 0.6683 - val_loss: 2.0922 - val_mae: 1.3106 - 64s/epoch - 64s/step\\nEpoch 3/5\\n1/1 - 60s - loss: 0.6948 - mae: 0.6460 - val_loss: 2.0498 - val_mae: 1.3105 - 60s/epoch - 60s/step\\nEpoch 4/5\\n1/1 - 60s - loss: 0.6714 - mae: 0.6237 - val_loss: 2.0126 - val_mae: 1.3106 - 60s/epoch - 60s/step\\nEpoch 5/5\\n1/1 - 57s - loss: 0.6631 - mae: 0.6064 - val_loss: 1.9801 - val_mae: 1.3105 - 57s/epoch - 57s/step\\n\\n'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model (add loss, optimizer, metrics)\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/\n",
    "\n",
    "def MCRMSE(y_true, y_pred):\n",
    "    column_losses = tf.reduce_mean(tf.square(y_true - y_pred), axis=0)\n",
    "    return tf.sqrt(tf.reduce_mean(column_losses))\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[MCRMSE]\n",
    ")\n",
    "\n",
    "num_of_samples = 10\n",
    "\n",
    "# Train the model\n",
    "model.fit(x=X_train[:num_of_samples],\n",
    "          y=Y_train[:num_of_samples],\n",
    "          validation_split=0.2,\n",
    "          epochs=5,\n",
    "          batch_size=16,\n",
    "          callbacks=[tensorboard_callback],\n",
    "          verbose=2)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Epoch 1/5\n",
    "1/1 - 80s - loss: 0.7473 - mae: 0.6926 - val_loss: 2.1400 - val_mae: 1.3103 - 80s/epoch - 80s/step\n",
    "Epoch 2/5\n",
    "1/1 - 64s - loss: 0.7145 - mae: 0.6683 - val_loss: 2.0922 - val_mae: 1.3106 - 64s/epoch - 64s/step\n",
    "Epoch 3/5\n",
    "1/1 - 60s - loss: 0.6948 - mae: 0.6460 - val_loss: 2.0498 - val_mae: 1.3105 - 60s/epoch - 60s/step\n",
    "Epoch 4/5\n",
    "1/1 - 60s - loss: 0.6714 - mae: 0.6237 - val_loss: 2.0126 - val_mae: 1.3106 - 60s/epoch - 60s/step\n",
    "Epoch 5/5\n",
    "1/1 - 57s - loss: 0.6631 - mae: 0.6064 - val_loss: 1.9801 - val_mae: 1.3105 - 57s/epoch - 57s/step\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0b114d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 28606), started 1:02:26 ago. (Use '!kill 28606' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-35a240ae5af30553\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-35a240ae5af30553\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "87e266ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 2), dtype=float32, numpy=\n",
       "array([[ 0.1836427 , -0.90790826],\n",
       "       [ 0.14288285, -0.91260374],\n",
       "       [ 0.23615369, -0.9612537 ],\n",
       "       [ 0.1906682 , -0.9618801 ],\n",
       "       [ 0.13323921, -0.8964913 ],\n",
       "       [ 0.16604379, -0.8585125 ]], dtype=float32)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run manually the model on a some features to see the output.\n",
    "num_of_features = 6\n",
    "X_train[:num_of_features]\n",
    "model(X_train[:num_of_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d06705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tokenize text data\n",
    "# train_encodings = tokenizer.batch_encode_plus(train['text'].tolist(),\n",
    "#                                               truncation=True, padding=True)\n",
    "\n",
    "# # Create TensorFlow dataset\n",
    "# train_df = tf.data.Dataset.from_tensor_slices(({'input_ids': train_encodings['input_ids'],\n",
    "#                                                 'attention_mask': train_encodings['attention_mask']},\n",
    "#                                                {'content': train['content'].tolist(),\n",
    "#                                                 'wording': train['wording'].tolist()}))\n",
    "# train_df = train_df.take(5)\n",
    "\n",
    "# # Define Keras model\n",
    "# model = keras.Sequential([roberta,\n",
    "#                           tf.keras.layers.GlobalAveragePooling1D(),\n",
    "#                           tf.keras.layers.Flatten(), \n",
    "#                           tf.keras.layers.Dense(2, activation='linear')])\n",
    "\n",
    "# # Compile the model (add loss, optimizer, metrics)\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(train_df, epochs=5, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c98aada",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c8d86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tf.Tensor(\n",
      "[    0   134  7510     9    41  5631  6906    16    14    24   197    28\n",
      " 12121    15    10  2632   563     4  1437  2044  7510     9    41  5631\n",
      "  6906    16    14    24   197   129    33    65  1049   696     4    20\n",
      "    94  7510     9    41  5631  6906    16    14    24   197    33    10\n",
      "  1457 15019  6197     8    41  5483 21421    13   258   205     8  1099\n",
      "     4     2     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1], shape=(512,), dtype=int32)\n",
      "Attention mask: tf.Tensor(\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(512,), dtype=int32)\n",
      "Content: tf.Tensor(-0.21061394, shape=(), dtype=float32)\n",
      "Wording: tf.Tensor(-0.47141483, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# for input_ids, attention_mask, content, wording in train_df:\n",
    "#     print(\"Input IDs:\", input_ids)\n",
    "#     print(\"Attention mask:\", attention_mask)\n",
    "#     print(\"Content:\", content)\n",
    "#     print(\"Wording:\", wording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70fed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tokenize text data\n",
    "# train_encodings = tokenizer.batch_encode_plus(train['text'].tolist(),\n",
    "#                                               truncation=True, padding=True)\n",
    "\n",
    "# # Create TensorFlow dataset\n",
    "# train_df = tf.data.Dataset.from_tensor_slices(({'input_ids': train_encodings['input_ids'],\n",
    "#                                                 'attention_mask': train_encodings['attention_mask']},\n",
    "#                                                {'content': train['content'].tolist(),\n",
    "#                                                 'wording': train['wording'].tolist()}))\n",
    "# train_df = train_df.take(5)\n",
    "\n",
    "# # Define Keras model\n",
    "# input_ids = tf.keras.Input(shape=(512,), dtype='int32', name='input_ids')\n",
    "# attention_mask = tf.keras.Input(shape=(512,), dtype='int32', name='attention_mask')\n",
    "\n",
    "# roberta_output = roberta(input_ids, attention_mask=attention_mask)[0]  # Accessing the output of the Roberta model\n",
    "\n",
    "# # Flatten and dense layers\n",
    "# flatten_output = tf.keras.layers.Flatten()(roberta_output)\n",
    "# dense_output = tf.keras.layers.Dense(2, activation='linear')(flatten_output)\n",
    "\n",
    "# model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=dense_output)\n",
    "\n",
    "# # Compile the model (add loss, optimizer, metrics)\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(train_df, epochs=5, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedc6a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7165"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeeaea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1 element of an ideal tragedy is that it shoul...\n",
       "1       The three elements of an ideal tragedy are:  H...\n",
       "2       Aristotle states that an ideal tragedy should ...\n",
       "3       One element of an Ideal tragedy is having a co...\n",
       "4       The 3 ideal of tragedy is how complex you need...\n",
       "                              ...                        \n",
       "7160    In paragraph two, they would use pickle meat a...\n",
       "7161    in the first paragraph  it says \"either can it...\n",
       "7162    They would have piles of filthy meat on the fl...\n",
       "7163    They used all sorts of chemical concoctions to...\n",
       "7164    The meat would smell sour but the would \"rub i...\n",
       "Name: text, Length: 7165, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f347253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3737779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b54182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df2fccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bcf7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4095eecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
